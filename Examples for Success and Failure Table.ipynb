{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import transformers_bert_completions, load_splits, load_models\n",
    "from utils_model_sampling import sample_across_models, beta_utils\n",
    "\n",
    "from yyy_analysis import examples_figure\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "\n",
    "import childespy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configuration\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make this config regenerate controlled later\n",
    "\n",
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"').iloc[0]['id']\n",
    "\n",
    "regenerate = False\n",
    "this_path = join(config.prov_csv_dir, 'pvd_utt_glosses.csv')\n",
    "\n",
    "if regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, type from utterance where corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv(this_path, index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv(this_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono = load_splits.load_phono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>transcript_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997717</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997717</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997718</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>ɑə</td>\n",
       "      <td>ɑə</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997718</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997719</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wɑn</td>\n",
       "      <td>wɑnt</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997719</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997720</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>də</td>\n",
       "      <td>tu</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997720</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wid</td>\n",
       "      <td>ɹid</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997721</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997722</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997722</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gloss actual_phonology_no_dia model_phonology_no_dia  \\\n",
       "997717  I want to read                                                  \n",
       "997718  I want to read                      ɑə                     ɑə   \n",
       "997719  I want to read                     wɑn                   wɑnt   \n",
       "997720  I want to read                      də                     tu   \n",
       "997721  I want to read                     wid                    ɹid   \n",
       "997722  I want to read                                                  \n",
       "\n",
       "        utterance_id  bert_token_id  utterance_order  transcript_id  \n",
       "997717      16928243         997717              310          42336  \n",
       "997718      16928243         997718              310          42336  \n",
       "997719      16928243         997719              310          42336  \n",
       "997720      16928243         997720              310          42336  \n",
       "997721      16928243         997721              310          42336  \n",
       "997722      16928243         997722              310          42336  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_idx = 16928243\n",
    "\n",
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == success_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transcript_id = 42336 # Corresponds to the success_idx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find new test examples - successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed this notebook to use the +/- 20 context newly generated versions.\n",
    "\n",
    "# Written to match load_models.query_model_title\n",
    "default_args = {\n",
    "    'split' : 'all',\n",
    "    'dataset' : 'all', \n",
    "    'is_tags' : False,\n",
    "    'context_num' : 20,\n",
    "}\n",
    "\n",
    "childes_all_title = load_models.query_model_title(model_type = 'childes', **default_args)\n",
    "adult_all_title = load_models.query_model_title(model_type = 'adult', **default_args)\n",
    "unigram_title = 'CHILDES Unigram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model CHILDES Unigram...\n",
      "Processing beta value 1 of 10\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Running model CHILDES BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Processing beta value 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model Adult BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Processing beta value 1 of 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CDL + Context +/- 20 is needed\n",
    "# BERT + Context +/- 20 is needed\n",
    "# Childes on train data.\n",
    "\n",
    "# How to load properly with sample across models?\n",
    "which_models = [\n",
    "    ('all', 'all', False, 0, 'data_unigram'),\n",
    "    ('all', 'all', False, 20, 'childes'),\n",
    "    ('all', 'all', False, 20, 'adult'),\n",
    "]\n",
    "\n",
    "raw_scores_across_models = examples_figure.get_scores_across_models(success_idx, which_models, True)\n",
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>highest_posterior_words</th>\n",
       "      <th>highest_posterior_probabilities</th>\n",
       "      <th>highest_prior_words</th>\n",
       "      <th>highest_prior_probabilities</th>\n",
       "      <th>prior_probability</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>CHILDES BERT without tags, , +-20 utts context</td>\n",
       "      <td>read see watch hear look know eat be weed do</td>\n",
       "      <td>0.755326884804619 0.2255594917587144 0.0071594...</td>\n",
       "      <td>read see play look know watch try do go write</td>\n",
       "      <td>0.6819752 0.20365484 0.02005186 0.0146201 0.01...</td>\n",
       "      <td>0.681975</td>\n",
       "      <td>read</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model  \\\n",
       "997721  CHILDES BERT without tags, , +-20 utts context   \n",
       "\n",
       "                             highest_posterior_words  \\\n",
       "997721  read see watch hear look know eat be weed do   \n",
       "\n",
       "                          highest_posterior_probabilities  \\\n",
       "997721  0.755326884804619 0.2255594917587144 0.0071594...   \n",
       "\n",
       "                                  highest_prior_words  \\\n",
       "997721  read see play look know watch try do go write   \n",
       "\n",
       "                              highest_prior_probabilities  prior_probability  \\\n",
       "997721  0.6819752 0.20365484 0.02005186 0.0146201 0.01...           0.681975   \n",
       "\n",
       "       token  \n",
       "997721  read  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'read (0.68) see (0.2) play (0.02) look (0.01) know (0.01) watch (0.01) try (0.0) do (0.0) go (0.0) write (0.0)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read (0.76) see (0.23) watch (0.01) hear (0.0) look (0.0) know (0.0) eat (0.0) be (0.0) weed (0.0) do (0.0)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "\n",
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read (0.49) see (0.28) play (0.04) know (0.04) look (0.02) go (0.01) watch (0.01) help (0.01) try (0.01) talk (0.01)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == adult_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read (0.61) see (0.35) watch (0.01) hear (0.01) know (0.0) be (0.0) look (0.0) eat (0.0) weed (0.0) go (0.0)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>highest_posterior_words</th>\n",
       "      <th>highest_posterior_probabilities</th>\n",
       "      <th>highest_prior_words</th>\n",
       "      <th>highest_prior_probabilities</th>\n",
       "      <th>prior_probability</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>Adult BERT without tags, , +-20 utts context</td>\n",
       "      <td>read see watch hear know be look eat weed go</td>\n",
       "      <td>0.6111245106575145 0.3457097600504063 0.012493...</td>\n",
       "      <td>read see play know look go watch help try talk</td>\n",
       "      <td>0.48782247 0.27595848 0.036773972 0.036336947 ...</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>read</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "997721  Adult BERT without tags, , +-20 utts context   \n",
       "\n",
       "                             highest_posterior_words  \\\n",
       "997721  read see watch hear know be look eat weed go   \n",
       "\n",
       "                          highest_posterior_probabilities  \\\n",
       "997721  0.6111245106575145 0.3457097600504063 0.012493...   \n",
       "\n",
       "                                   highest_prior_words  \\\n",
       "997721  read see play know look go watch help try talk   \n",
       "\n",
       "                              highest_prior_probabilities  prior_probability  \\\n",
       "997721  0.48782247 0.27595848 0.036773972 0.036336947 ...           0.487822   \n",
       "\n",
       "       token  \n",
       "997721  read  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>highest_posterior_words</th>\n",
       "      <th>highest_posterior_probabilities</th>\n",
       "      <th>highest_prior_words</th>\n",
       "      <th>highest_prior_probabilities</th>\n",
       "      <th>prior_probability</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHILDES Unigram</td>\n",
       "      <td>we and need one what would he me here see</td>\n",
       "      <td>0.22214807950129137 0.07648990509019489 0.0701...</td>\n",
       "      <td>i a the yeah no it you and that this</td>\n",
       "      <td>0.04253891500819406 0.03258178351349858 0.0279...</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>read</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model                    highest_posterior_words  \\\n",
       "3  CHILDES Unigram  we and need one what would he me here see   \n",
       "\n",
       "                     highest_posterior_probabilities  \\\n",
       "3  0.22214807950129137 0.07648990509019489 0.0701...   \n",
       "\n",
       "                    highest_prior_words  \\\n",
       "3  i a the yeah no it you and that this   \n",
       "\n",
       "                         highest_prior_probabilities  prior_probability token  \n",
       "3  0.04253891500819406 0.03258178351349858 0.0279...           0.001048  read  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == unigram_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i (0.04) a (0.03) the (0.03) yeah (0.03) no (0.03) it (0.03) you (0.02) and (0.02) that (0.02) this (0.01)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we (0.22) and (0.08) need (0.07) one (0.04) what (0.03) would (0.03) he (0.03) me (0.03) here (0.02) see (0.02)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162628</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928069</td>\n",
       "      <td>300</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162639</th>\n",
       "      <td>a ballet</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928081</td>\n",
       "      <td>301</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162656</th>\n",
       "      <td>is Jasmine a ballerina</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928098</td>\n",
       "      <td>302</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162670</th>\n",
       "      <td>yeah</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928113</td>\n",
       "      <td>303</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162686</th>\n",
       "      <td>oh I didn't know that</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928129</td>\n",
       "      <td>304</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162710</th>\n",
       "      <td>I ready now yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928154</td>\n",
       "      <td>305</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162730</th>\n",
       "      <td>whoa</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928174</td>\n",
       "      <td>306</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162744</th>\n",
       "      <td>yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928189</td>\n",
       "      <td>307</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162760</th>\n",
       "      <td>yyy yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928205</td>\n",
       "      <td>308</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162779</th>\n",
       "      <td>you want mamma let's see</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928225</td>\n",
       "      <td>309</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162797</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928243</td>\n",
       "      <td>310</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162814</th>\n",
       "      <td>okay mommy's gonna pick out a book</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928261</td>\n",
       "      <td>311</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     gloss  transcript_id        id  \\\n",
       "162628                             Jasmine          42336  16928069   \n",
       "162639                            a ballet          42336  16928081   \n",
       "162656              is Jasmine a ballerina          42336  16928098   \n",
       "162670                                yeah          42336  16928113   \n",
       "162686               oh I didn't know that          42336  16928129   \n",
       "162710                     I ready now yyy          42336  16928154   \n",
       "162730                                whoa          42336  16928174   \n",
       "162744                                 yyy          42336  16928189   \n",
       "162760                             yyy yyy          42336  16928205   \n",
       "162779            you want mamma let's see          42336  16928225   \n",
       "162797                      I want to read          42336  16928243   \n",
       "162814  okay mommy's gonna pick out a book          42336  16928261   \n",
       "\n",
       "        utterance_order target_child_name speaker_code         type  \n",
       "162628              300              Lily          MOT  declarative  \n",
       "162639              301              Lily          CHI  declarative  \n",
       "162656              302              Lily          MOT     question  \n",
       "162670              303              Lily          CHI  declarative  \n",
       "162686              304              Lily          MOT  declarative  \n",
       "162710              305              Lily          CHI  declarative  \n",
       "162730              306              Lily          MOT  declarative  \n",
       "162744              307              Lily          CHI  declarative  \n",
       "162760              308              Lily          CHI  declarative  \n",
       "162779              309              Lily          MOT  declarative  \n",
       "162797              310              Lily          CHI  declarative  \n",
       "162814              311              Lily          MOT  declarative  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to visualize utt_glosses -- how to do this? What is the dependency?\n",
    "# Is this a providence one or?\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == target_transcript_id) &\n",
    "                (utt_glosses.utterance_order.isin(range(310-10, 310+2)))] # Note to self: changed the range here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New extraction section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model CHILDES Unigram...\n",
      "Processing beta value 1 of 10\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Running model CHILDES BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Processing beta value 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model Adult BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Processing beta value 1 of 10\n"
     ]
    }
   ],
   "source": [
    "yyy_idx = 16813515\n",
    "\n",
    "raw_scores_across_models = examples_figure.get_scores_across_models(yyy_idx, which_models, False)\n",
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>transcript_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289678</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16813515</td>\n",
       "      <td>289678</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289679</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>ju</td>\n",
       "      <td>ju</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289679</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289680</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>meək</td>\n",
       "      <td>meək</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289680</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289681</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>jɜ</td>\n",
       "      <td>jɑɹ</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289681</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>fɜt</td>\n",
       "      <td>*</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289682</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289683</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16813515</td>\n",
       "      <td>289683</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    gloss actual_phonology_no_dia model_phonology_no_dia  \\\n",
       "289678  you make your yyy                                                  \n",
       "289679  you make your yyy                      ju                     ju   \n",
       "289680  you make your yyy                    meək                   meək   \n",
       "289681  you make your yyy                      jɜ                    jɑɹ   \n",
       "289682  you make your yyy                     fɜt                      *   \n",
       "289683  you make your yyy                                                  \n",
       "\n",
       "        utterance_id  bert_token_id  utterance_order  transcript_id  \n",
       "289678      16813515         289678              112          42253  \n",
       "289679      16813515         289679              112          42253  \n",
       "289680      16813515         289680              112          42253  \n",
       "289681      16813515         289681              112          42253  \n",
       "289682      16813515         289682              112          42253  \n",
       "289683      16813515         289683              112          42253  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == yyy_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'own (0.48) bet (0.09) cut (0.05) bed (0.04) shot (0.03) wish (0.03) guess (0.03) call (0.02) choice (0.02) move (0.02)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == childes_all_title)][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'own (0.25) choice (0.24) point (0.04) bed (0.03) call (0.03) guess (0.03) wish (0.02) choices (0.02) move (0.02) mistake (0.02)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == adult_all_title)][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'own (0.32) bet (0.2) bed (0.04) call (0.04) cut (0.04) guess (0.04) wish (0.03) shot (0.03) choice (0.03) move (0.03)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i (0.04) a (0.03) the (0.03) yeah (0.03) no (0.03) it (0.03) you (0.02) and (0.02) that (0.02) this (0.01)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == unigram_title)][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it (0.14) that (0.1) what (0.06) not (0.04) get (0.03) got (0.03) put (0.03) fit (0.03) feet (0.02) for (0.02)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50658</th>\n",
       "      <td>then we won't be able to put them back into th...</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813459</td>\n",
       "      <td>109</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50679</th>\n",
       "      <td>do you want ta put some beans in your eggs and...</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813482</td>\n",
       "      <td>110</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50697</th>\n",
       "      <td>no</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813501</td>\n",
       "      <td>111</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50710</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813515</td>\n",
       "      <td>112</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50723</th>\n",
       "      <td>can I make one</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813529</td>\n",
       "      <td>113</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50745</th>\n",
       "      <td>no</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813554</td>\n",
       "      <td>114</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   gloss  transcript_id  \\\n",
       "50658  then we won't be able to put them back into th...          42253   \n",
       "50679  do you want ta put some beans in your eggs and...          42253   \n",
       "50697                                                 no          42253   \n",
       "50710                                  you make your yyy          42253   \n",
       "50723                                     can I make one          42253   \n",
       "50745                                                 no          42253   \n",
       "\n",
       "             id  utterance_order target_child_name speaker_code         type  \n",
       "50658  16813459              109              Alex          MOT  declarative  \n",
       "50679  16813482              110              Alex          MOT     question  \n",
       "50697  16813501              111              Alex          CHI  declarative  \n",
       "50710  16813515              112              Alex          CHI  declarative  \n",
       "50723  16813529              113              Alex          MOT     question  \n",
       "50745  16813554              114              Alex          MOT  declarative  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses.loc[(utt_glosses.transcript_id == 42253) &\n",
    "                (utt_glosses.utterance_order.isin(range(112-3, 112+3)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
