{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/home/stephan/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstalling childesr version 0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/childesr_0.2.3.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 22865 bytes (22 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 22 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmplowbbA/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "time: 3.38 ms (started: 2022-01-28 16:47:15 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import transformers_bert_completions, load_splits, load_models\n",
    "from utils_model_sampling import sample_across_models, hyperparameter_utils\n",
    "\n",
    "from yyy_analysis import examples_figure\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "import childespy\n",
    "%load_ext autotime\n",
    "%load_ext line_profiler\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.03 ms (started: 2022-01-28 16:47:15 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import configuration\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.28 ms (started: 2022-01-28 16:47:15 -08:00)\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" #hangs as of 1/26 if GPU is enabled on workstation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.13 s (started: 2022-01-28 16:47:15 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Make this config regenerate controlled later\n",
    "\n",
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"', db_version = \"2020.1\").iloc[0]['id']\n",
    "\n",
    "regenerate = False\n",
    "this_path = join(config.prov_csv_dir, 'pvd_utt_glosses.csv')\n",
    "\n",
    "if regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, type from utterance where corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv(this_path, index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv(this_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phonology and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.74 s (started: 2022-01-28 16:47:18 -08:00)\n"
     ]
    }
   ],
   "source": [
    "all_tokens_phono = load_splits.load_phono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>transcript_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997717</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997717</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997718</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>aə</td>\n",
       "      <td>aə</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997718</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997719</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wɑn</td>\n",
       "      <td>wɑnt</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997719</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997720</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>də</td>\n",
       "      <td>tu</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997720</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wid</td>\n",
       "      <td>ɹid</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997721</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997722</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997722</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gloss actual_phonology_no_dia model_phonology_no_dia  \\\n",
       "997717  I want to read                                                  \n",
       "997718  I want to read                      aə                     aə   \n",
       "997719  I want to read                     wɑn                   wɑnt   \n",
       "997720  I want to read                      də                     tu   \n",
       "997721  I want to read                     wid                    ɹid   \n",
       "997722  I want to read                                                  \n",
       "\n",
       "        utterance_id  bert_token_id  utterance_order  transcript_id  \n",
       "997717      16928243         997717              310          42336  \n",
       "997718      16928243         997718              310          42336  \n",
       "997719      16928243         997719              310          42336  \n",
       "997720      16928243         997720              310          42336  \n",
       "997721      16928243         997721              310          42336  \n",
       "997722      16928243         997722              310          42336  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.7 ms (started: 2022-01-28 16:47:25 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_idx = 16928243\n",
    "\n",
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == success_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 378 µs (started: 2022-01-28 16:47:25 -08:00)\n"
     ]
    }
   ],
   "source": [
    "target_transcript_id = 42336 # Corresponds to the success_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162628</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928069</td>\n",
       "      <td>300</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162639</th>\n",
       "      <td>a ballet</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928081</td>\n",
       "      <td>301</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162656</th>\n",
       "      <td>is Jasmine a ballerina</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928098</td>\n",
       "      <td>302</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162670</th>\n",
       "      <td>yeah</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928113</td>\n",
       "      <td>303</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162686</th>\n",
       "      <td>oh I didn't know that</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928129</td>\n",
       "      <td>304</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162710</th>\n",
       "      <td>I ready now yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928154</td>\n",
       "      <td>305</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162730</th>\n",
       "      <td>whoa</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928174</td>\n",
       "      <td>306</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162744</th>\n",
       "      <td>yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928189</td>\n",
       "      <td>307</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162760</th>\n",
       "      <td>yyy yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928205</td>\n",
       "      <td>308</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162779</th>\n",
       "      <td>you want mamma let's see</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928225</td>\n",
       "      <td>309</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162797</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928243</td>\n",
       "      <td>310</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162814</th>\n",
       "      <td>okay mommy's gonna pick out a book</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928261</td>\n",
       "      <td>311</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     gloss  transcript_id        id  \\\n",
       "162628                             Jasmine          42336  16928069   \n",
       "162639                            a ballet          42336  16928081   \n",
       "162656              is Jasmine a ballerina          42336  16928098   \n",
       "162670                                yeah          42336  16928113   \n",
       "162686               oh I didn't know that          42336  16928129   \n",
       "162710                     I ready now yyy          42336  16928154   \n",
       "162730                                whoa          42336  16928174   \n",
       "162744                                 yyy          42336  16928189   \n",
       "162760                             yyy yyy          42336  16928205   \n",
       "162779            you want mamma let's see          42336  16928225   \n",
       "162797                      I want to read          42336  16928243   \n",
       "162814  okay mommy's gonna pick out a book          42336  16928261   \n",
       "\n",
       "        utterance_order target_child_name speaker_code         type  \n",
       "162628              300              Lily          MOT  declarative  \n",
       "162639              301              Lily          CHI  declarative  \n",
       "162656              302              Lily          MOT     question  \n",
       "162670              303              Lily          CHI  declarative  \n",
       "162686              304              Lily          MOT  declarative  \n",
       "162710              305              Lily          CHI  declarative  \n",
       "162730              306              Lily          MOT  declarative  \n",
       "162744              307              Lily          CHI  declarative  \n",
       "162760              308              Lily          CHI  declarative  \n",
       "162779              309              Lily          MOT  declarative  \n",
       "162797              310              Lily          CHI  declarative  \n",
       "162814              311              Lily          MOT  declarative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.8 ms (started: 2022-01-28 16:47:25 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Broader context of sentences\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == target_transcript_id) &\n",
    "                (utt_glosses.utterance_order.isin(range(310-10, 310+2)))] # Note to self: changed the range here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Prior and Posterior Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.24 ms (started: 2022-01-28 17:26:22 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Changed this notebook to use the +/- 20 context newly generated versions.\n",
    "\n",
    "# Written to match load_models.query_model_title\n",
    "default_args = {\n",
    "    'split' : 'all',\n",
    "    'dataset' : 'all', \n",
    "    'is_tags' : False,\n",
    "    'context_num' : 20,\n",
    "}\n",
    "\n",
    "childes_all_title = load_models.query_model_title(model_type = 'childes', **default_args)\n",
    "adult_all_title = load_models.query_model_title(model_type = 'adult', **default_args)\n",
    "unigram_title = 'CHILDES Unigram'\n",
    "flat_title = 'Flat Unigram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.load_models' from '/home/stephan/notebooks/nicole/child-directed-listening/utils/load_models.py'>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.1 ms (started: 2022-01-28 17:59:16 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(examples_figure)\n",
    "imp.reload(transformers_bert_completions)\n",
    "imp.reload(sample_across_models)\n",
    "imp.reload(load_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.71 ms (started: 2022-01-28 17:59:18 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# CDL + Context +/- 20 is needed\n",
    "# BERT + Context +/- 20 is needed\n",
    "# Childes on train data.\n",
    "\n",
    "# How to load properly with sample across models?\n",
    "which_models = [\n",
    "    ('all', 'all', False, 0, 'data_unigram'),\n",
    "    ('all', 'all', False, 20, 'childes'),\n",
    "    ('all', 'all', False, 20, 'adult'),\n",
    "    ('all', 'all', False, 0, 'flat_unigram'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model CHILDES Unigram...\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Running model CHILDES BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model Adult BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "Running model Flat Unigram...\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "time: 45.4 s (started: 2022-01-28 17:59:19 -08:00)\n"
     ]
    }
   ],
   "source": [
    "raw_scores_across_models = examples_figure.get_scores_across_models(success_idx, which_models, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 763 µs (started: 2022-01-28 16:48:44 -08:00)\n"
     ]
    }
   ],
   "source": [
    "#%lprun -f wfst.get_wfst_distance_matrix raw_scores_across_models = examples_figure.get_scores_across_models(success_idx, which_models, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.1 ms (started: 2022-01-28 18:00:07 -08:00)\n"
     ]
    }
   ],
   "source": [
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.75 ms (started: 2022-01-28 18:00:08 -08:00)\n"
     ]
    }
   ],
   "source": [
    "scores_across_models = scores_across_models.loc[scores_across_models.likelihood_type == 'levdist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['levdist'], dtype=object)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.44 ms (started: 2022-01-28 18:00:09 -08:00)\n"
     ]
    }
   ],
   "source": [
    "np.unique(scores_across_models.likelihood_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>highest_posterior_words</th>\n",
       "      <th>highest_posterior_probabilities</th>\n",
       "      <th>highest_prior_words</th>\n",
       "      <th>highest_prior_probabilities</th>\n",
       "      <th>prior_probability</th>\n",
       "      <th>token</th>\n",
       "      <th>likelihood_type</th>\n",
       "      <th>prior_rank</th>\n",
       "      <th>posterior_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>CHILDES BERT without tags, , +-20 utts context</td>\n",
       "      <td>see read watch hear eat go be me dad look</td>\n",
       "      <td>0.593986775150996 0.28323569047071767 0.018986...</td>\n",
       "      <td>see go play look read know watch write mommy do</td>\n",
       "      <td>0.4728042 0.0909064 0.031111874 0.022768175 0....</td>\n",
       "      <td>0.018506</td>\n",
       "      <td>read</td>\n",
       "      <td>levdist</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model  \\\n",
       "997721  CHILDES BERT without tags, , +-20 utts context   \n",
       "\n",
       "                          highest_posterior_words  \\\n",
       "997721  see read watch hear eat go be me dad look   \n",
       "\n",
       "                          highest_posterior_probabilities  \\\n",
       "997721  0.593986775150996 0.28323569047071767 0.018986...   \n",
       "\n",
       "                                    highest_prior_words  \\\n",
       "997721  see go play look read know watch write mommy do   \n",
       "\n",
       "                              highest_prior_probabilities  prior_probability  \\\n",
       "997721  0.4728042 0.0909064 0.031111874 0.022768175 0....           0.018506   \n",
       "\n",
       "       token likelihood_type  prior_rank  posterior_rank  \n",
       "997721  read         levdist           4             1.0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.3 ms (started: 2022-01-28 18:00:11 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token','likelihood_type','prior_rank','posterior_rank']]\n",
    "success_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDL+Context Prior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'see (0.47) go (0.09) play (0.03) look (0.02) read (0.02) know (0.02) watch (0.02) write (0.01) mommy (0.01) do (0.01)'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.8 ms (started: 2022-01-28 18:00:14 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "print('CDL+Context Prior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDL+Context Posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'see (0.59) read (0.28) watch (0.02) hear (0.02) eat (0.01) go (0.01) be (0.01) me (0.0) dad (0.0) look (0.0)'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.3 ms (started: 2022-01-28 18:00:16 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "print('CDL+Context Posterior')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT+Context Prior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'read (0.49) see (0.28) play (0.04) know (0.04) look (0.02) go (0.01) watch (0.01) help (0.01) try (0.01) talk (0.01)'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.1 ms (started: 2022-01-28 18:00:18 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == adult_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "\n",
    "print('BERT+Context Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT+Context Posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'read (0.9503) see (0.0441) watch (0.0016) hear (0.0007) know (0.0005) be (0.0003) look (0.0002) eat (0.0002) weed (0.0002) go (0.0002)'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.4 ms (started: 2022-01-28 18:00:19 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "print('BERT+Context Posterior')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],4))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHILDES-1Gram Prior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i (0.04) a (0.03) the (0.03) yeah (0.03) no (0.03) it (0.03) you (0.02) and (0.02) that (0.02) this (0.01)'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.7 ms (started: 2022-01-28 18:00:21 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == unigram_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token', 'prior_rank', 'posterior_rank']]\n",
    "#print(success_example)\n",
    "print('CHILDES-1Gram Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHILDES-1gram Posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'we (0.2) the (0.08) and (0.07) need (0.06) read (0.04) one (0.04) what (0.03) would (0.03) he (0.03) me (0.02)'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.3 ms (started: 2022-01-28 18:00:23 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "print('CHILDES-1gram Posterior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniformPrior Prior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'stalks (0.0) rarely (0.0) harbor (0.0) dust (0.0) josh (0.0) milk (0.0) leon (0.0) pitch (0.0) blake (0.0) girlfriend (0.0)'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25 ms (started: 2022-01-28 18:00:25 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == flat_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "print('UniformPrior Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniformPrior Posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'weed (0.18) deed (0.01) week (0.01) feed (0.01) reed (0.01) seed (0.01) weak (0.01) wheat (0.01) wood (0.01) weeds (0.01)'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.2 ms (started: 2022-01-28 18:00:27 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "print('UniformPrior Posterior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.load_models' from '/home/stephan/notebooks/nicole/child-directed-listening/utils/load_models.py'>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.8 ms (started: 2022-01-28 18:00:30 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(examples_figure)\n",
    "imp.reload(transformers_bert_completions)\n",
    "imp.reload(sample_across_models)\n",
    "imp.reload(load_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model CHILDES Unigram...\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Running model CHILDES BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model Adult BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "Running model Flat Unigram...\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "time: 42.5 s (started: 2022-01-28 18:00:31 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_idx = 16813515\n",
    "\n",
    "raw_scores_across_models = examples_figure.get_scores_across_models(yyy_idx, which_models, False)\n",
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>transcript_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289678</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16813515</td>\n",
       "      <td>289678</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289679</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>ju</td>\n",
       "      <td>ju</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289679</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289680</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>meək</td>\n",
       "      <td>meək</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289680</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289681</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>jɜ</td>\n",
       "      <td>jɑɹ</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289681</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>fɜt</td>\n",
       "      <td>*</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289682</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289683</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16813515</td>\n",
       "      <td>289683</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    gloss actual_phonology_no_dia model_phonology_no_dia  \\\n",
       "289678  you make your yyy                                                  \n",
       "289679  you make your yyy                      ju                     ju   \n",
       "289680  you make your yyy                    meək                   meək   \n",
       "289681  you make your yyy                      jɜ                    jɑɹ   \n",
       "289682  you make your yyy                     fɜt                      *   \n",
       "289683  you make your yyy                                                  \n",
       "\n",
       "        utterance_id  bert_token_id  utterance_order  transcript_id  \n",
       "289678      16813515         289678              112          42253  \n",
       "289679      16813515         289679              112          42253  \n",
       "289680      16813515         289680              112          42253  \n",
       "289681      16813515         289681              112          42253  \n",
       "289682      16813515         289682              112          42253  \n",
       "289683      16813515         289683              112          42253  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.7 ms (started: 2022-01-28 18:01:17 -08:00)\n"
     ]
    }
   ],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == yyy_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>highest_posterior_words</th>\n",
       "      <th>highest_posterior_probabilities</th>\n",
       "      <th>highest_prior_words</th>\n",
       "      <th>highest_prior_probabilities</th>\n",
       "      <th>prior_probability</th>\n",
       "      <th>token</th>\n",
       "      <th>likelihood_type</th>\n",
       "      <th>posterior_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>CHILDES BERT without tags, , +-20 utts context</td>\n",
       "      <td>own hat feet bed food foot mess cat tea lot</td>\n",
       "      <td>0.24153853581354678 0.1188293613752251 0.05656...</td>\n",
       "      <td>own house bed dinner mouth breakfast hand name...</td>\n",
       "      <td>0.20277847 0.07381966 0.038039044 0.03174672 0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>levdist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model  \\\n",
       "289682  CHILDES BERT without tags, , +-20 utts context   \n",
       "\n",
       "                            highest_posterior_words  \\\n",
       "289682  own hat feet bed food foot mess cat tea lot   \n",
       "\n",
       "                          highest_posterior_probabilities  \\\n",
       "289682  0.24153853581354678 0.1188293613752251 0.05656...   \n",
       "\n",
       "                                      highest_prior_words  \\\n",
       "289682  own house bed dinner mouth breakfast hand name...   \n",
       "\n",
       "                              highest_prior_probabilities  prior_probability  \\\n",
       "289682  0.20277847 0.07381966 0.038039044 0.03174672 0...                NaN   \n",
       "\n",
       "       token likelihood_type  posterior_rank  \n",
       "289682   NaN         levdist             NaN  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.8 ms (started: 2022-01-28 18:01:19 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) & (scores_across_models.likelihood_type == 'levdist')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token','likelihood_type','posterior_rank']]\n",
    "yyy_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'own (0.2) house (0.07) bed (0.04) dinner (0.03) mouth (0.02) breakfast (0.02) hand (0.01) name (0.01) mess (0.01) tea (0.01)'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.3 ms (started: 2022-01-28 18:01:22 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'own (0.24) hat (0.12) feet (0.06) bed (0.05) food (0.04) foot (0.03) mess (0.02) cat (0.02) tea (0.02) lot (0.01)'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.5 ms (started: 2022-01-28 18:01:23 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'own (0.25) choice (0.24) point (0.04) bed (0.03) call (0.03) guess (0.03) wish (0.02) choices (0.02) move (0.02) mistake (0.02)'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.2 ms (started: 2022-01-28 18:01:41 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == adult_all_title ) & (scores_across_models.likelihood_type == 'levdist')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'own (0.32) bet (0.2) bed (0.04) call (0.04) cut (0.04) guess (0.04) wish (0.03) shot (0.03) choice (0.03) move (0.03)'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.2 ms (started: 2022-01-28 18:01:43 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i (0.04) a (0.03) the (0.03) yeah (0.03) no (0.03) it (0.03) you (0.02) and (0.02) that (0.02) this (0.01)'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.9 ms (started: 2022-01-28 18:01:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == unigram_title) & (scores_across_models.likelihood_type == 'levdist')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it (0.14) that (0.1) what (0.06) not (0.04) get (0.03) got (0.03) put (0.03) fit (0.03) feet (0.02) for (0.02)'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.7 ms (started: 2022-01-28 18:01:50 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50658</th>\n",
       "      <td>then we won't be able to put them back into th...</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813459</td>\n",
       "      <td>109</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50679</th>\n",
       "      <td>do you want ta put some beans in your eggs and...</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813482</td>\n",
       "      <td>110</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50697</th>\n",
       "      <td>no</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813501</td>\n",
       "      <td>111</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50710</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813515</td>\n",
       "      <td>112</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50723</th>\n",
       "      <td>can I make one</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813529</td>\n",
       "      <td>113</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50745</th>\n",
       "      <td>no</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813554</td>\n",
       "      <td>114</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   gloss  transcript_id  \\\n",
       "50658  then we won't be able to put them back into th...          42253   \n",
       "50679  do you want ta put some beans in your eggs and...          42253   \n",
       "50697                                                 no          42253   \n",
       "50710                                  you make your yyy          42253   \n",
       "50723                                     can I make one          42253   \n",
       "50745                                                 no          42253   \n",
       "\n",
       "             id  utterance_order target_child_name speaker_code         type  \n",
       "50658  16813459              109              Alex          MOT  declarative  \n",
       "50679  16813482              110              Alex          MOT     question  \n",
       "50697  16813501              111              Alex          CHI  declarative  \n",
       "50710  16813515              112              Alex          CHI  declarative  \n",
       "50723  16813529              113              Alex          MOT     question  \n",
       "50745  16813554              114              Alex          MOT  declarative  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.6 ms (started: 2022-01-28 18:01:51 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Get the surrounding context\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == 42253) &\n",
    "                (utt_glosses.utterance_order.isin(range(112-3, 112+3)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
