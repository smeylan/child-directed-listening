{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/home/stephan/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstalling childesr version 0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/childesr_0.2.2.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 20614 bytes (20 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 20 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpgTdJKR/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import transformers_bert_completions, load_splits, load_models\n",
    "from utils_model_sampling import sample_across_models, hyperparameter_utils\n",
    "\n",
    "from yyy_analysis import examples_figure\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "\n",
    "import childespy\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configuration\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make this config regenerate controlled later\n",
    "\n",
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"', db_version = \"2020.1\").iloc[0]['id']\n",
    "\n",
    "regenerate = False\n",
    "this_path = join(config.prov_csv_dir, 'pvd_utt_glosses.csv')\n",
    "\n",
    "if regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, type from utterance where corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv(this_path, index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv(this_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono = load_splits.load_phono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>transcript_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997717</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997717</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997718</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>aə</td>\n",
       "      <td>aə</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997718</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997719</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wɑn</td>\n",
       "      <td>wɑnt</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997719</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997720</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>də</td>\n",
       "      <td>tu</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997720</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wid</td>\n",
       "      <td>ɹid</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997721</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997722</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997722</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gloss actual_phonology_no_dia model_phonology_no_dia  \\\n",
       "997717  I want to read                                                  \n",
       "997718  I want to read                      aə                     aə   \n",
       "997719  I want to read                     wɑn                   wɑnt   \n",
       "997720  I want to read                      də                     tu   \n",
       "997721  I want to read                     wid                    ɹid   \n",
       "997722  I want to read                                                  \n",
       "\n",
       "        utterance_id  bert_token_id  utterance_order  transcript_id  \n",
       "997717      16928243         997717              310          42336  \n",
       "997718      16928243         997718              310          42336  \n",
       "997719      16928243         997719              310          42336  \n",
       "997720      16928243         997720              310          42336  \n",
       "997721      16928243         997721              310          42336  \n",
       "997722      16928243         997722              310          42336  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_idx = 16928243\n",
    "\n",
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == success_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transcript_id = 42336 # Corresponds to the success_idx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find new test examples - successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed this notebook to use the +/- 20 context newly generated versions.\n",
    "\n",
    "# Written to match load_models.query_model_title\n",
    "default_args = {\n",
    "    'split' : 'all',\n",
    "    'dataset' : 'all', \n",
    "    'is_tags' : False,\n",
    "    'context_num' : 20,\n",
    "}\n",
    "\n",
    "childes_all_title = load_models.query_model_title(model_type = 'childes', **default_args)\n",
    "adult_all_title = load_models.query_model_title(model_type = 'adult', **default_args)\n",
    "unigram_title = 'CHILDES Unigram'\n",
    "flat_title = 'Flat Unigram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils_model_sampling.sample_across_models' from '/home/stephan/notebooks/nicole/child-directed-listening/utils_model_sampling/sample_across_models.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(examples_figure)\n",
    "imp.reload(transformers_bert_completions)\n",
    "imp.reload(sample_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model CHILDES BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/nicole/child-directed-listening/cdl_env/lib/python3.6/site-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end[0,2] = ''\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end[0,3] = ''\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end[0,4] = ''\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py:253: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[[1]] = -1 * np.log(1)\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/cdl_env/lib/python3.6/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lambda value 1 of 20\n",
      "In get_posteriors\n",
      "> \u001b[0;32m/home/stephan/notebooks/nicole/child-directed-listening/utils/transformers_bert_completions.py\u001b[0m(610)\u001b[0;36mget_posteriors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    608 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    609 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 610 \u001b[0;31m    \u001b[0mlikelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscaling_value\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlevdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    611 \u001b[0;31m    \u001b[0munnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'priors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    612 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  scaling_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CDL + Context +/- 20 is needed\n",
    "# BERT + Context +/- 20 is needed\n",
    "# Childes on train data.\n",
    "\n",
    "# How to load properly with sample across models?\n",
    "which_models = [\n",
    "    #('all', 'all', False, 0, 'data_unigram'),\n",
    "    ('all', 'all', False, 20, 'childes'),\n",
    "    #('all', 'all', False, 20, 'adult'),\n",
    "    #('all', 'all', False, 0, 'flat_unigram'),\n",
    "]\n",
    "\n",
    "raw_scores_across_models = examples_figure.get_scores_across_models(success_idx, which_models, True)\n",
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_across_models = scores_across_models.loc[scores_across_models.likelihood_type == 'wfst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token','likelihood_type']]\n",
    "success_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! why are the highest prior probability words the same as the highest \n",
    "# posterior probability ones?\n",
    "#!!! is there something weird going on here with the lambda value\n",
    "# priors should remain similar to what we saw before -- the numbers here are different \n",
    "# from both earlier posteriors and priors\n",
    "# [O] is the best lambda value one that fully discounts the likelihood? Yep\n",
    "# [ ] why would it be different than the BERT+Context model? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "print('CDL+Context Prior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "print('CDL+Context Posterior')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ ] Very strange that the two above would be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == adult_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "\n",
    "print('BERT+Context Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "print('BERT+Context Prior')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],4))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == unigram_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "print('CHILDES-1Gram Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "print('CHILDES-1gram Posterior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == flat_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "print('UniformPrior Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "print('UniformPrior Posterior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broader context of sentences\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == target_transcript_id) &\n",
    "                (utt_glosses.utterance_order.isin(range(310-10, 310+2)))] # Note to self: changed the range here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_idx = 16813515\n",
    "\n",
    "raw_scores_across_models = examples_figure.get_scores_across_models(yyy_idx, which_models, False)\n",
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == yyy_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token','likelihood_type']]\n",
    "yyy_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == adult_all_title ) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == unigram_title) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the surrounding context\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == 42253) &\n",
    "                (utt_glosses.utterance_order.isin(range(112-3, 112+3)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
