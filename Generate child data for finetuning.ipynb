{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6/21/21 Adapted from the original Generalized Phonological Comparison file from Dr. Meylan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "import childespy\n",
    "import numpy as np\n",
    "import os\n",
    "import imp\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "phono_data_path = 'csv/phono_data.csv'\n",
    "\n",
    "# This takes a long time to run\n",
    "\n",
    "# This query is NOT the same as the original Generalized Phonology one\n",
    "# It adds the restriction that speaker code must be in MOT, FAT, or CHI\n",
    "# It removes the restriction on non-empty phonologies\n",
    "# I also add and remove fields so that the fields match those in \"Generate data to fine-tune a BERT model\"\n",
    "\n",
    "\n",
    "# utterance_order and type are not available in the phono data? Why?\n",
    "\n",
    "if (not os.path.exists(phono_data_path)) or regenerate:\n",
    "    \n",
    "    # 'id' seems to be automatically present \n",
    "    # Removed the \"type\" and \"utterance order\" arguments.\n",
    "    \n",
    "    phono = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, transcript_id, \\\n",
    "    token_order, corpus_name, collection_name, language from token where speaker_code in (\"MOT\", \"FAT\",\"CHI\")', db_version = \"2020.1\")\n",
    "    # cache this phonological information locally\n",
    "    phono.to_csv(phono_data_path, index=False)\n",
    "else:\n",
    "    phono = pd.read_csv(phono_data_path, keep_default_na=False, na_values=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(914135, 12)\n"
     ]
    }
   ],
   "source": [
    "# remove cases where one is not set\n",
    "excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "phono = phono.loc[~(phono.model_phonology.isin(excludes) |  phono.actual_phonology.isin(excludes))]\n",
    "\n",
    "print(phono.shape)\n",
    "chi_phono = phono.loc[(phono.speaker_code == 'CHI') & (phono.target_child_age < (365*5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chi_phono.loc[(chi_phono.collection_name == \"Eng-NA\") & (chi_phono.target_child_age > 40*30.5)]\\\n",
    ".to_csv('csv/EngNAOver40months.csv', index=False)\n",
    "# not a model mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>target_child_age</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>token_order</th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162470</th>\n",
       "      <td>yyy</td>\n",
       "      <td>Naima</td>\n",
       "      <td>609.7500</td>\n",
       "      <td>CHI</td>\n",
       "      <td>hɛhɪ</td>\n",
       "      <td>*vv</td>\n",
       "      <td>42409</td>\n",
       "      <td>17015713</td>\n",
       "      <td>1</td>\n",
       "      <td>Providence</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162478</th>\n",
       "      <td>I</td>\n",
       "      <td>Julia</td>\n",
       "      <td>693.6250</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ə</td>\n",
       "      <td>a</td>\n",
       "      <td>41544</td>\n",
       "      <td>16650674</td>\n",
       "      <td>1</td>\n",
       "      <td>Goad</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162479</th>\n",
       "      <td>a</td>\n",
       "      <td>Sonya</td>\n",
       "      <td>826.8125</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ðæ</td>\n",
       "      <td>a</td>\n",
       "      <td>41587</td>\n",
       "      <td>16659604</td>\n",
       "      <td>1</td>\n",
       "      <td>Goad</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162480</th>\n",
       "      <td>I</td>\n",
       "      <td>Julia</td>\n",
       "      <td>1192.0625</td>\n",
       "      <td>CHI</td>\n",
       "      <td>aj</td>\n",
       "      <td>a</td>\n",
       "      <td>41569</td>\n",
       "      <td>16658519</td>\n",
       "      <td>1</td>\n",
       "      <td>Goad</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162481</th>\n",
       "      <td>I</td>\n",
       "      <td>Julia</td>\n",
       "      <td>1192.0625</td>\n",
       "      <td>CHI</td>\n",
       "      <td>aj</td>\n",
       "      <td>a</td>\n",
       "      <td>41569</td>\n",
       "      <td>16659995</td>\n",
       "      <td>1</td>\n",
       "      <td>Goad</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gloss target_child_name  target_child_age speaker_code  \\\n",
       "162470   yyy             Naima          609.7500          CHI   \n",
       "162478     I             Julia          693.6250          CHI   \n",
       "162479     a             Sonya          826.8125          CHI   \n",
       "162480     I             Julia         1192.0625          CHI   \n",
       "162481     I             Julia         1192.0625          CHI   \n",
       "\n",
       "       actual_phonology model_phonology  transcript_id  utterance_id  \\\n",
       "162470             hɛhɪ             *vv          42409      17015713   \n",
       "162478                ə               a          41544      16650674   \n",
       "162479               ðæ               a          41587      16659604   \n",
       "162480               aj               a          41569      16658519   \n",
       "162481               aj               a          41569      16659995   \n",
       "\n",
       "        token_order corpus_name collection_name language  \n",
       "162470            1  Providence          Eng-NA      eng  \n",
       "162478            1        Goad          Eng-NA      eng  \n",
       "162479            1        Goad          Eng-NA      eng  \n",
       "162480            1        Goad          Eng-NA      eng  \n",
       "162481            1        Goad          Eng-NA      eng  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "en_chi_phono = chi_phono.loc[chi_phono.collection_name == 'Eng-NA']\n",
    "en_chi_phono.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data using \"Generate finetuned\" notebook code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naima samples 98585\n",
      "Lily samples 74467\n",
      "Alex samples 37041\n",
      "William samples 30014\n",
      "Ethan samples 27280\n",
      "Violet samples 26349\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Julia samples 23112\n",
      "Trevor samples 14029\n",
      "Sean samples 8741\n",
      "Sonya samples 7781\n",
      "E samples 3332\n",
      "T42 samples 147\n",
      "Select: ['Naima', 'Lily', 'Alex', 'William', 'Ethan', 'Violet']\n"
     ]
    }
   ],
   "source": [
    "# Select which children to analyze -- I select the children with most data available\n",
    "\n",
    "child_valid_samples = {}\n",
    "\n",
    "for child in child_names:\n",
    "    tcd = en_chi_phono[en_chi_phono['target_child_name'] == child].copy()\n",
    "    tcd['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in tcd.gloss]\n",
    "    \n",
    "    tcd = tcd.loc[~tcd.contains_error]\n",
    "    child_valid_samples[child] = tcd.shape[0]\n",
    "    \n",
    "child_freq_sorted = sorted(child_valid_samples, key = lambda k : child_valid_samples[k])[::-1]\n",
    "\n",
    "for idx, c in enumerate(child_freq_sorted):\n",
    "    print(c, 'samples', child_valid_samples[c])\n",
    "    if idx == 5: print('-----'*20)\n",
    "\n",
    "num_children = 6\n",
    "select_children = child_freq_sorted[:num_children]\n",
    "\n",
    "print('Select:', select_children)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from utils import data_gen\n",
    "importlib.reload(data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "this_base_dir = 'data/child'\n",
    "child_names = list(set(en_chi_phono['target_child_name']))\n",
    "\n",
    "for child in child_names:\n",
    "    \n",
    "    child_data = en_chi_phono[en_chi_phono['target_child_name'] == child].copy()\n",
    "    \n",
    "    # Need to select 400 successes as val for now -- this is done internally in exec_split_gen\n",
    "    # Will save their training/validation txt as expected\n",
    "    this_split_glosses_df, this_tok_freq, this_chi_tok_freq = data_gen.exec_split_gen(child_data, 'child', child,\n",
    "                                                                                      this_base_dir, verbose = False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
