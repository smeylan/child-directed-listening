{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6/21/21 Adapted from the original Generalized Phonological Comparison file from Dr. Meylan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "import childespy\n",
    "import numpy as np\n",
    "import os\n",
    "import imp\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "import itertools\n",
    "\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "\n",
    "from utils import split_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n",
      "R[write to console]: Error in .local(conn, statement, ...) : \n",
      "  could not run statement: Unknown column 'type' in 'field list'\n",
      "\n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in .local(conn, statement, ...) : \n  could not run statement: Unknown column 'type' in 'field list'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-82fa2115ce24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     phono = childespy.get_sql_query('select gloss, target_child_name, type, utterance_order, target_child_age, \\\n\u001b[1;32m     21\u001b[0m     \u001b[0mspeaker_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     token_order, corpus_name, collection_name, language from token where speaker_code in (\"MOT\", \"FAT\",\"CHI\")', db_version = \"2020.1\")\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# cache this phonological information locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mphono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphono_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/childespy/childespy.py\u001b[0m in \u001b[0;36mget_sql_query\u001b[0;34m(sql_query_string, connection, db_version, db_args)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0mdb_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_r_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0mr_sql_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchildesr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     \u001b[0mr_sql_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_df_to_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_sql_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mr_sql_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_sql_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_r_to_py\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         return (super(SignatureTranslatedFunction, self)\n\u001b[0;32m--> 198\u001b[0;31m                 .__call__(*args, **kwargs))\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy2rpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_res_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cdata_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m                     error_occured))\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_occured\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geterrmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in .local(conn, statement, ...) : \n  could not run statement: Unknown column 'type' in 'field list'\n"
     ]
    }
   ],
   "source": [
    "# Note: I used regenerate = False for the refactor, because it took too long for the query to complete.\n",
    "\n",
    "regenerate = True\n",
    "phono_data_path = 'csv/phono_data.csv'\n",
    "\n",
    "# This takes a long time to run\n",
    "\n",
    "# This query is NOT the same as the original Generalized Phonology one\n",
    "# It adds the restriction that speaker code must be in MOT, FAT, or CHI\n",
    "# It removes the restriction on non-empty phonologies\n",
    "# I also add and remove fields so that the fields match those in \"Generate data to fine-tune a BERT model\"\n",
    "\n",
    "# utterance_order and type are not available in the phono data? Why?\n",
    "\n",
    "if (not os.path.exists(phono_data_path)) or regenerate:\n",
    "    \n",
    "    # 'id' seems to be automatically present \n",
    "    # Removed the \"type\" and \"utterance order\" arguments.\n",
    "    \n",
    "    phono = childespy.get_sql_query('select gloss, target_child_name, type, utterance_order, target_child_age, \\\n",
    "    speaker_code, transcript_id, \\\n",
    "    token_order, corpus_name, collection_name, language from token where speaker_code in (\"MOT\", \"FAT\",\"CHI\")', db_version = \"2020.1\")\n",
    "    # cache this phonological information locally\n",
    "    phono.to_csv(phono_data_path, index=False)\n",
    "else:\n",
    "    phono = pd.read_csv(phono_data_path, keep_default_na=False, na_values=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162470     Providence\n",
      "174090     Providence\n",
      "174091     Providence\n",
      "174092     Providence\n",
      "184210     Providence\n",
      "              ...    \n",
      "1075982    Providence\n",
      "1075983    Providence\n",
      "1076052    Providence\n",
      "1076059    Providence\n",
      "1076077    Providence\n",
      "Name: corpus_name, Length: 98591, dtype: object\n",
      "184149     Providence\n",
      "184207     Providence\n",
      "184208     Providence\n",
      "184209     Providence\n",
      "184295     Providence\n",
      "              ...    \n",
      "1076075    Providence\n",
      "1076076    Providence\n",
      "1076109    Providence\n",
      "1076110    Providence\n",
      "1076113    Providence\n",
      "Name: corpus_name, Length: 74468, dtype: object\n",
      "174060     Providence\n",
      "174061     Providence\n",
      "174062     Providence\n",
      "174063     Providence\n",
      "184140     Providence\n",
      "              ...    \n",
      "1076104    Providence\n",
      "1076105    Providence\n",
      "1076106    Providence\n",
      "1076107    Providence\n",
      "1076108    Providence\n",
      "Name: corpus_name, Length: 37043, dtype: object\n",
      "184150     Providence\n",
      "184151     Providence\n",
      "184152     Providence\n",
      "184153     Providence\n",
      "184154     Providence\n",
      "              ...    \n",
      "1076079    Providence\n",
      "1076083    Providence\n",
      "1076111    Providence\n",
      "1076114    Providence\n",
      "1076115    Providence\n",
      "Name: corpus_name, Length: 30014, dtype: object\n",
      "174064     Providence\n",
      "174065     Providence\n",
      "174066     Providence\n",
      "174067     Providence\n",
      "174068     Providence\n",
      "              ...    \n",
      "1076070    Providence\n",
      "1076071    Providence\n",
      "1076072    Providence\n",
      "1076073    Providence\n",
      "1076074    Providence\n",
      "Name: corpus_name, Length: 27291, dtype: object\n",
      "184226     Providence\n",
      "184227     Providence\n",
      "184228     Providence\n",
      "184229     Providence\n",
      "184230     Providence\n",
      "              ...    \n",
      "1075984    Providence\n",
      "1075985    Providence\n",
      "1075986    Providence\n",
      "1075987    Providence\n",
      "1076078    Providence\n",
      "Name: corpus_name, Length: 26352, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for name in ['Naima', 'Lily', 'Alex', 'William', 'Ethan', 'Violet']:\n",
    "    print(phono[phono['target_child_name'] == name]['corpus_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(914135, 12)\n"
     ]
    }
   ],
   "source": [
    "# remove cases where one is not set\n",
    "excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "phono = phono.loc[~(phono.model_phonology.isin(excludes) |  phono.actual_phonology.isin(excludes))]\n",
    "\n",
    "print(phono.shape)\n",
    "chi_phono = phono.loc[(phono.speaker_code == 'CHI') & (phono.target_child_age < (365*5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chi_phono.loc[(chi_phono.collection_name == \"Eng-NA\") & (chi_phono.target_child_age > 40*30.5)]\\\n",
    ".to_csv('csv/EngNAOver40months.csv', index=False)\n",
    "# not a model mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>target_child_age</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>token_order</th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162470</th>\n",
       "      <td>yyy</td>\n",
       "      <td>Naima</td>\n",
       "      <td>609.7500</td>\n",
       "      <td>CHI</td>\n",
       "      <td>hɛhɪ</td>\n",
       "      <td>*vv</td>\n",
       "      <td>42409</td>\n",
       "      <td>17015713</td>\n",
       "      <td>1</td>\n",
       "      <td>Providence</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162478</th>\n",
       "      <td>I</td>\n",
       "      <td>Julia</td>\n",
       "      <td>693.6250</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ə</td>\n",
       "      <td>a</td>\n",
       "      <td>41544</td>\n",
       "      <td>16650674</td>\n",
       "      <td>1</td>\n",
       "      <td>Goad</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162479</th>\n",
       "      <td>a</td>\n",
       "      <td>Sonya</td>\n",
       "      <td>826.8125</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ðæ</td>\n",
       "      <td>a</td>\n",
       "      <td>41587</td>\n",
       "      <td>16659604</td>\n",
       "      <td>1</td>\n",
       "      <td>Goad</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162480</th>\n",
       "      <td>I</td>\n",
       "      <td>Julia</td>\n",
       "      <td>1192.0625</td>\n",
       "      <td>CHI</td>\n",
       "      <td>aj</td>\n",
       "      <td>a</td>\n",
       "      <td>41569</td>\n",
       "      <td>16658519</td>\n",
       "      <td>1</td>\n",
       "      <td>Goad</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162481</th>\n",
       "      <td>I</td>\n",
       "      <td>Julia</td>\n",
       "      <td>1192.0625</td>\n",
       "      <td>CHI</td>\n",
       "      <td>aj</td>\n",
       "      <td>a</td>\n",
       "      <td>41569</td>\n",
       "      <td>16659995</td>\n",
       "      <td>1</td>\n",
       "      <td>Goad</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gloss target_child_name  target_child_age speaker_code  \\\n",
       "162470   yyy             Naima          609.7500          CHI   \n",
       "162478     I             Julia          693.6250          CHI   \n",
       "162479     a             Sonya          826.8125          CHI   \n",
       "162480     I             Julia         1192.0625          CHI   \n",
       "162481     I             Julia         1192.0625          CHI   \n",
       "\n",
       "       actual_phonology model_phonology  transcript_id  utterance_id  \\\n",
       "162470             hɛhɪ             *vv          42409      17015713   \n",
       "162478                ə               a          41544      16650674   \n",
       "162479               ðæ               a          41587      16659604   \n",
       "162480               aj               a          41569      16658519   \n",
       "162481               aj               a          41569      16659995   \n",
       "\n",
       "        token_order corpus_name collection_name language  \n",
       "162470            1  Providence          Eng-NA      eng  \n",
       "162478            1        Goad          Eng-NA      eng  \n",
       "162479            1        Goad          Eng-NA      eng  \n",
       "162480            1        Goad          Eng-NA      eng  \n",
       "162481            1        Goad          Eng-NA      eng  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "en_chi_phono = chi_phono.loc[chi_phono.collection_name == 'Eng-NA']\n",
    "en_chi_phono.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data using \"Generate finetuned\" notebook code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naima samples 98585\n",
      "Lily samples 74467\n",
      "Alex samples 37041\n",
      "William samples 30014\n",
      "Ethan samples 27280\n",
      "Violet samples 26349\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Julia samples 23112\n",
      "Trevor samples 14029\n",
      "Sean samples 8741\n",
      "Sonya samples 7781\n",
      "E samples 3332\n",
      "T42 samples 147\n",
      "Select: ['Naima', 'Lily', 'Alex', 'William', 'Ethan', 'Violet']\n"
     ]
    }
   ],
   "source": [
    "# Select which children to analyze -- I select the children with most data available\n",
    "\n",
    "child_valid_samples = {}\n",
    "\n",
    "for child in set(en_chi_phono['target_child_name']):\n",
    "    tcd = en_chi_phono[en_chi_phono['target_child_name'] == child].copy()\n",
    "    tcd['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in tcd.gloss]\n",
    "    \n",
    "    tcd = tcd.loc[~tcd.contains_error]\n",
    "    child_valid_samples[child] = tcd.shape[0]\n",
    "    \n",
    "child_freq_sorted = sorted(child_valid_samples, key = lambda k : child_valid_samples[k])[::-1]\n",
    "\n",
    "for idx, c in enumerate(child_freq_sorted):\n",
    "    print(c, 'samples', child_valid_samples[c])\n",
    "    if idx == 5: print('-----'*20)\n",
    "\n",
    "num_children = 6\n",
    "select_children = child_freq_sorted[:num_children]\n",
    "\n",
    "print('Select:', select_children)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning split gen call: child Naima\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8a7aa963914d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     this_split_glosses_df, this_tok_freq, this_chi_tok_freq = split_gen.exec_split_gen(child_data, 'child', child,\n\u001b[0;32m---> 16\u001b[0;31m                                                                                       this_base_dir, verbose = False)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-directed-listening/utils/split_gen.py\u001b[0m in \u001b[0;36mexec_split_gen\u001b[0;34m(raw_data, split_name, dataset_name, base_dir, verbose)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;31m# Note: yyy uses \".\" as the default punct val. Splits use \"None\" as the default punct val.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mcleaned_utt_glosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_utt_glosses_for_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mtok_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchi_tok_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_utt_glosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-directed-listening/utils/split_gen.py\u001b[0m in \u001b[0;36mprep_utt_glosses_for_split\u001b[0;34m(data, fill_punct_val, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cell 233 output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_glosses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cell 269'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgloss_with_punct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-directed-listening/utils/split_gen.py\u001b[0m in \u001b[0;36mclean_glosses\u001b[0;34m(data, fill_punct_val, verbose)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Cell 237\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     data['punct'] = [punct_for_type[x] if x in punct_for_type else fill_punct_val\n\u001b[0;32m--> 122\u001b[0;31m                         for x in data.type ]\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cell 238'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "this_base_dir = 'data/new_splits'\n",
    "\n",
    "if not os.path.exists(this_base_dir):\n",
    "    os.makedirs(this_base_dir)\n",
    "    \n",
    "child_names = list(set(en_chi_phono['target_child_name']))\n",
    "\n",
    "for child in select_children:\n",
    "    \n",
    "    child_data = en_chi_phono[en_chi_phono['target_child_name'] == child].copy()\n",
    "    \n",
    "    # Need to select 400 successes as val for now -- this is done internally in exec_split_gen\n",
    "    # Will save their training/validation txt as expected\n",
    "    \n",
    "    this_split_glosses_df, this_tok_freq, this_chi_tok_freq = split_gen.exec_split_gen(child_data, 'child', child,\n",
    "                                                                                      this_base_dir, verbose = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the generated data properly\n",
    "\n",
    "from utils import load_splits\n",
    "child_data = load_splits.load_splits_folder_text('child', os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) no communicative failures in the final text file, anywhere\n",
    "# -- a communicative failure is the occurence of xxx or yyy anywhere in the dataset\n",
    "\n",
    "# 2) all of the data composes to form the original dataset \n",
    "# 3) all of the data appears once in any dataset\n",
    "# 4) all of the data within a child's dataset belongs to that child."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
