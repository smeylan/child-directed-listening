{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import childespy\n",
    "import numpy as np\n",
    "import spellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training and Valdiation for Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the North American and British English adult and child utterances without xxx or yyy\n",
    "#concatenate them at the the transcript level\n",
    "#hold out 20% for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>data_source</th>\n",
       "      <th>collection_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Valian</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Bernstein</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>Clark</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>PetersonMcCabe</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>221</td>\n",
       "      <td>Wells</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>222</td>\n",
       "      <td>Gathburn</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>223</td>\n",
       "      <td>Nuffield</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>224</td>\n",
       "      <td>Lara</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>225</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id            name collection_name data_source  collection_id\n",
       "1    32          Garvey          Eng-NA     CHILDES              2\n",
       "2    33          Valian          Eng-NA     CHILDES              2\n",
       "3    34       Bernstein          Eng-NA     CHILDES              2\n",
       "4    35           Clark          Eng-NA     CHILDES              2\n",
       "5    36  PetersonMcCabe          Eng-NA     CHILDES              2\n",
       "..  ...             ...             ...         ...            ...\n",
       "57  221           Wells          Eng-UK     CHILDES             12\n",
       "58  222        Gathburn          Eng-UK     CHILDES             12\n",
       "59  223        Nuffield          Eng-UK     CHILDES             12\n",
       "60  224            Lara          Eng-UK     CHILDES             12\n",
       "61  225         Belfast          Eng-UK     CHILDES             12\n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora = childespy.get_sql_query('select * from corpus where \\\n",
    "collection_name in (\"Eng-NA\", \"Eng-UK\") and data_source = \"CHILDES\"')\n",
    "corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'collection_name', 'data_source', 'collection_id'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "childes_datasets = \",\".join([str(x) for x in corpora.collection_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regenerate = True\n",
    "if regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, target_child_name, target_child_age, type from utterance where collection_name in (\"Eng-NA\", \"Eng-UK\") \\\n",
    "    and collection_id in ('+childes_datasets+') and speaker_code in (\"MOT\", \"FAT\",\"CHI\")' , db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv('csv/utt_glosses.csv', index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv('csv/utt_glosses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1234AB',\n",
       " '4269LP',\n",
       " '4269LP10',\n",
       " '4269LP11',\n",
       " '4269LP18',\n",
       " '4269LP7',\n",
       " '4271WC',\n",
       " '4273WC',\n",
       " '4273WC10',\n",
       " '4273WC24',\n",
       " '427WC10',\n",
       " '427WC11',\n",
       " '4310AM11',\n",
       " '4310AM24',\n",
       " '4310AM7',\n",
       " '4452CM',\n",
       " '4452CM11',\n",
       " '4452CM24',\n",
       " '4592HVG10mos',\n",
       " '4592HVG11mos',\n",
       " '4592HVG7mos',\n",
       " '4619WC',\n",
       " '4619WZ10',\n",
       " '4619WZ11',\n",
       " '4619WZ7',\n",
       " '4629AB',\n",
       " '4629AB10',\n",
       " '4629AB11',\n",
       " '4629AB24',\n",
       " '4641CC11',\n",
       " '4641CC24',\n",
       " '4641CC7',\n",
       " '4650KS',\n",
       " '4650KS10',\n",
       " '4650KS11',\n",
       " '4650KS24',\n",
       " '4664AM',\n",
       " '4664AM7',\n",
       " '4687NH',\n",
       " '4687NH24mos',\n",
       " '4697JK10',\n",
       " '4697JK11',\n",
       " '4697JK24',\n",
       " '4697JK7',\n",
       " '47081B7',\n",
       " '4708IB10mos',\n",
       " '4708IB11mos',\n",
       " '4708IB24',\n",
       " '4724LM10',\n",
       " '4724LM24mos',\n",
       " '4724LM7',\n",
       " '4724LM7mos',\n",
       " '4731SA',\n",
       " '4734ES',\n",
       " '4734ES7',\n",
       " '4737NA7',\n",
       " '474311mos',\n",
       " '4743NA10',\n",
       " '4743NA11',\n",
       " '4743NA24',\n",
       " '4767JC',\n",
       " '4767JC11',\n",
       " '4801RB',\n",
       " '4801RB10',\n",
       " '4801RB11',\n",
       " '4802JP',\n",
       " '4802JP10',\n",
       " '4802JP11',\n",
       " '4802JP7',\n",
       " '4814BS',\n",
       " '4814BS24',\n",
       " '4825GG',\n",
       " '4854MP11mos',\n",
       " '4854MP24mos',\n",
       " '4854MP7mos',\n",
       " '4858CM10',\n",
       " '4858CM11',\n",
       " '4858CM7',\n",
       " '4866AC',\n",
       " '4866AC10',\n",
       " '4866AC11',\n",
       " '4866AC7',\n",
       " '4903LS',\n",
       " '4903LS10',\n",
       " '4903LS24',\n",
       " '4903LS7',\n",
       " '4929MM10mos',\n",
       " '4929MM11mos',\n",
       " '4929MM24mos',\n",
       " '4929MM7mos',\n",
       " '4946RC',\n",
       " '4946RC10mos',\n",
       " '4946RC7mos',\n",
       " '49910LM7',\n",
       " '4997LM24',\n",
       " '4997LM7',\n",
       " '5013LA',\n",
       " '5013LA10',\n",
       " '5013LA11',\n",
       " '5013LA24',\n",
       " '5013LA7',\n",
       " '5039MB',\n",
       " '5039MB10',\n",
       " '5039MB11',\n",
       " '5039MB7',\n",
       " '5057MD11',\n",
       " '5057MS',\n",
       " '5057MS10',\n",
       " '5057MS11',\n",
       " '5057MS18',\n",
       " '5057MS18mos',\n",
       " '5066WT10',\n",
       " '5066WT11',\n",
       " '5066WT24',\n",
       " '5066WT7',\n",
       " '5073AC',\n",
       " '5073AC24',\n",
       " '5111CG',\n",
       " '5111CG24',\n",
       " '5118PM10',\n",
       " '5118PM24',\n",
       " '5118PM7',\n",
       " '5193HB',\n",
       " '5196AV18',\n",
       " '5196AV18mos',\n",
       " '5196AVH7',\n",
       " '5196AVI',\n",
       " '5196AVI11',\n",
       " '5196AVI24',\n",
       " '5224EZS10mos',\n",
       " '5224EZS11',\n",
       " '5224EZS24',\n",
       " '5224EZS7',\n",
       " '5244RE10mos',\n",
       " '5244RE11',\n",
       " '5244RE18',\n",
       " '5244RE24',\n",
       " '5244RE7',\n",
       " '5244SE10mos',\n",
       " '5244SE11',\n",
       " '5244SE18',\n",
       " '5244SE24',\n",
       " '5244SE7',\n",
       " '5266EC',\n",
       " '5266EC10',\n",
       " '5266EC18',\n",
       " '5266EC7',\n",
       " '5303CW',\n",
       " '5303CW11',\n",
       " '5303CW24',\n",
       " '5303CW7',\n",
       " '5346GG10',\n",
       " '5346GG11',\n",
       " '5346GG24mos',\n",
       " '5346GG7',\n",
       " '5365DL',\n",
       " '5365DL24mos',\n",
       " '5365DL7',\n",
       " '5440JJ10',\n",
       " '5440JJ11mos',\n",
       " '5440JJ24mos',\n",
       " '5440JJ7mos',\n",
       " '5443AO11',\n",
       " '5443AO24mos',\n",
       " '5443AO7',\n",
       " '5449NG10',\n",
       " '5449NG11',\n",
       " '5449NG24',\n",
       " '5449NG7',\n",
       " '5474ES11',\n",
       " '5474ES24',\n",
       " '5474ES7',\n",
       " '5482DF',\n",
       " '5482DF11',\n",
       " '5482DF7',\n",
       " '5540LD10',\n",
       " '5540LD11',\n",
       " '5540LD24',\n",
       " '5540LD7',\n",
       " '5543EF',\n",
       " '5543EF11',\n",
       " '5543EF18',\n",
       " '5543EF7',\n",
       " '5550VS',\n",
       " '5550VS10',\n",
       " '5550VS11',\n",
       " '5550VS18',\n",
       " '5550VS7',\n",
       " '5561AC',\n",
       " '5561AC10',\n",
       " '5561AC11',\n",
       " '5561AC18mos',\n",
       " '5561AC7',\n",
       " '5563DB',\n",
       " '5563DB10mos',\n",
       " '5563DB11mos',\n",
       " '5563DB18',\n",
       " '5563DB24',\n",
       " '5563DB7mos',\n",
       " '5571FW',\n",
       " '5571FW10mos',\n",
       " '5571FW11',\n",
       " '5571FW7',\n",
       " '5574IH',\n",
       " '5585ME',\n",
       " '5593SH',\n",
       " '5593SH10',\n",
       " '5593SH24',\n",
       " '5593SH7',\n",
       " '5609DW',\n",
       " '5623AT',\n",
       " '5623AT11',\n",
       " '5630WS',\n",
       " '5630WS11mos',\n",
       " '5630WS18mos',\n",
       " '5630WS7mos',\n",
       " '5661AP',\n",
       " '5661AP11mos',\n",
       " '5661AP7',\n",
       " '5694MC',\n",
       " '5694MC10',\n",
       " '5694MC11',\n",
       " '5694MC18',\n",
       " '5694MC7',\n",
       " '5707RT',\n",
       " '5707RT11mos',\n",
       " '5707RT18mos',\n",
       " '5707RT7mos',\n",
       " '5733LBE',\n",
       " '5733LE',\n",
       " '5777FC',\n",
       " '5777FCH11',\n",
       " '5777FCH7',\n",
       " '5794ES',\n",
       " '5794ES19mos',\n",
       " '5820CP',\n",
       " '5820CP10',\n",
       " '5837AK11mos',\n",
       " '5837AK24mos',\n",
       " '5837AK7mos',\n",
       " '5837JK',\n",
       " '5859ME',\n",
       " '5859ME10',\n",
       " '5859ME11mos',\n",
       " '5859ME7',\n",
       " '5878SC',\n",
       " '5878SC11',\n",
       " '5878SC24',\n",
       " '5878SC7',\n",
       " '5903AE',\n",
       " '5903AE10',\n",
       " '5903AE11mos',\n",
       " '5923MW18',\n",
       " '5928RL',\n",
       " '5928RL18',\n",
       " '5928RL7',\n",
       " '5929LD11mos',\n",
       " '5929LD24',\n",
       " '5929LD7',\n",
       " '5936SR',\n",
       " '5936SR18',\n",
       " '5936SR24mos',\n",
       " '5936SR7',\n",
       " '5949DL10mos',\n",
       " '5949DL24mos',\n",
       " '5949DL7mos',\n",
       " '5954ML11',\n",
       " '5954ML24mos',\n",
       " '5954ML7',\n",
       " '5959DL',\n",
       " '5965PC',\n",
       " '5965PC18',\n",
       " '5977QJ11',\n",
       " '5977QJ24',\n",
       " '5977QJ7',\n",
       " '6043AM',\n",
       " '6047JC',\n",
       " '6047JC11mos',\n",
       " '6047JC7',\n",
       " '6071WB10',\n",
       " '6071WB24',\n",
       " '6071WB24mos',\n",
       " '6071WB7',\n",
       " '6206MP',\n",
       " '6206MP18mos',\n",
       " '6314AK',\n",
       " '6314AK10',\n",
       " '6314AK11',\n",
       " '6314AK24',\n",
       " '6314AK7',\n",
       " '6337NK',\n",
       " '6337NK11',\n",
       " '6337NK24',\n",
       " '6453HS',\n",
       " '6453HS10',\n",
       " '6453HS11',\n",
       " '6453HS7',\n",
       " '6454MB',\n",
       " '6454MB11',\n",
       " '6454MB7',\n",
       " '6483TM24mos',\n",
       " '6493TM11',\n",
       " '6493TM24mos',\n",
       " '6493TM7',\n",
       " '6510LC',\n",
       " '6510LC11',\n",
       " '6510LC7',\n",
       " '6598JM',\n",
       " '6598JM7',\n",
       " '6626SW',\n",
       " '6626SW11mos',\n",
       " '6626SW24mos',\n",
       " '6630TM',\n",
       " '6630TM10mos',\n",
       " '6630TM11',\n",
       " '6630TM24',\n",
       " '6630TM7',\n",
       " '6691MW',\n",
       " '6691MW11mos',\n",
       " '6691MW24mos',\n",
       " '6691MW7mos',\n",
       " '6757JC',\n",
       " '6785KS',\n",
       " '6785KS10mos',\n",
       " '6785KS24mos',\n",
       " '6785KS7',\n",
       " '6815KG10',\n",
       " '6815KG11',\n",
       " '6815KG24',\n",
       " '6815KG7',\n",
       " '6818AP',\n",
       " '6818AP11mos',\n",
       " '6825MT',\n",
       " '6825MT24',\n",
       " '6826LD',\n",
       " '6826LD24',\n",
       " '6878SK',\n",
       " '6878SK10',\n",
       " '6878SK11',\n",
       " '6878SK24',\n",
       " '6878SK7',\n",
       " '7013VD',\n",
       " '7013VD10',\n",
       " '7013VD11',\n",
       " '7013VD7',\n",
       " '7018NB',\n",
       " '7018NB11',\n",
       " '7061AS10',\n",
       " '7061AS11mos',\n",
       " '7061AS18',\n",
       " '7061AS24',\n",
       " '7061AS7',\n",
       " '7075MB11',\n",
       " '7075MB24mos',\n",
       " '7075MB7',\n",
       " '7099EH',\n",
       " '7099EH10',\n",
       " '7099EH7',\n",
       " '7119CM11mos',\n",
       " '7119CM24',\n",
       " '7119CM7mos',\n",
       " '7120CB',\n",
       " '7120CB11mos',\n",
       " '7120CB18mos',\n",
       " '7120CB24mos',\n",
       " '7120CB7mos',\n",
       " '7162MB10mos',\n",
       " '7162MB11',\n",
       " '7162MB24',\n",
       " '7162MB7',\n",
       " '7183TB',\n",
       " '7183TB10mos',\n",
       " '7183TB11',\n",
       " '7183TB7',\n",
       " '7222MD10mos',\n",
       " '7222MD11mos',\n",
       " '7222MD24mos',\n",
       " '7222MD7mos',\n",
       " '7236FB10mos',\n",
       " '7236FB11mos',\n",
       " '7236FB18mos',\n",
       " '7236FB24mos',\n",
       " '7236FB7mos',\n",
       " '7251TR',\n",
       " '7252PD10mos',\n",
       " '7252PD11mos',\n",
       " '7252PD24mos',\n",
       " '7252PD7',\n",
       " '7300AP10',\n",
       " '7300AP11',\n",
       " '7300AP24',\n",
       " '7300AP7',\n",
       " '7419EB10mos',\n",
       " '7419EB11',\n",
       " '7419EB24mos',\n",
       " '7419EB7',\n",
       " '7444IJ11',\n",
       " '7444IJ24mos',\n",
       " '7444IJ7',\n",
       " '7534EM',\n",
       " '7534EM10mos',\n",
       " '7534EM18mos',\n",
       " '7534EM24mos',\n",
       " '7553JT',\n",
       " '7553JT11',\n",
       " '7553JT18',\n",
       " '7553JT24mos',\n",
       " '7553JT7mos',\n",
       " '7658LT',\n",
       " '7658LT10mos',\n",
       " '7658LT24mos',\n",
       " '7658LT7mos',\n",
       " '7660HK10mos',\n",
       " '7660HK24mos',\n",
       " '7814NB11mos',\n",
       " '7814NB18moschildmos',\n",
       " '7814NB24moschild',\n",
       " '7814NB7mos',\n",
       " 'AJ',\n",
       " 'Aaron',\n",
       " 'Abby',\n",
       " 'Abe',\n",
       " 'Abigail',\n",
       " 'Adam',\n",
       " 'Adele_M',\n",
       " 'Aimee',\n",
       " 'Alexander',\n",
       " 'Alexandra',\n",
       " 'Alfred',\n",
       " 'Alice',\n",
       " 'Alisha',\n",
       " 'Allen',\n",
       " 'Amanda',\n",
       " 'Amelia',\n",
       " 'Amy',\n",
       " 'Andre',\n",
       " 'Andrew',\n",
       " 'Andrew_H',\n",
       " 'Andy',\n",
       " 'Anna',\n",
       " 'Anne',\n",
       " 'Anthony',\n",
       " 'April',\n",
       " 'Aran',\n",
       " 'Ari',\n",
       " 'Ashley',\n",
       " 'Astra',\n",
       " 'Barbara',\n",
       " 'Barry',\n",
       " 'Barry_M',\n",
       " 'Bash',\n",
       " 'Baxter',\n",
       " 'Becky',\n",
       " 'Ben',\n",
       " 'Benjamin',\n",
       " 'Benjamin_B',\n",
       " 'Benny',\n",
       " 'Bess',\n",
       " 'Beth',\n",
       " 'Betty',\n",
       " 'Bill',\n",
       " 'Bob',\n",
       " 'Bobby',\n",
       " 'Bonnie',\n",
       " 'Brad',\n",
       " 'Brandice',\n",
       " 'Brandie',\n",
       " 'Brandon',\n",
       " 'Bree',\n",
       " 'Brenda',\n",
       " 'Brent',\n",
       " 'Brett',\n",
       " 'Brian',\n",
       " 'Brianne',\n",
       " 'Brook',\n",
       " 'Brooke',\n",
       " 'Brooklyn',\n",
       " 'Bryce',\n",
       " 'CHI',\n",
       " 'Camden',\n",
       " 'Candice',\n",
       " 'Carl',\n",
       " 'Carl_J',\n",
       " 'Carlos',\n",
       " 'Carly_M',\n",
       " 'Carol',\n",
       " 'Carter',\n",
       " 'Casey',\n",
       " 'Cassie',\n",
       " 'Catherine',\n",
       " 'Charlie',\n",
       " 'Charreece',\n",
       " 'Chip',\n",
       " 'Chris',\n",
       " 'Chrissy',\n",
       " 'Christian',\n",
       " 'Christina',\n",
       " 'Christine',\n",
       " 'Christopher',\n",
       " 'Chrystal',\n",
       " 'Chuck',\n",
       " 'Chunjee',\n",
       " 'Cindy',\n",
       " 'Claire_H',\n",
       " 'Claire_K',\n",
       " 'Claire_M',\n",
       " 'Claire_P',\n",
       " 'Clara',\n",
       " 'Clark_R',\n",
       " 'Colin',\n",
       " 'Conner',\n",
       " 'Connor',\n",
       " 'Conor',\n",
       " 'Corey',\n",
       " 'Corinna',\n",
       " 'Corrina',\n",
       " 'Courtney',\n",
       " 'Craig_A',\n",
       " 'Craig_F',\n",
       " 'Cyrene',\n",
       " 'DJ',\n",
       " 'Dale',\n",
       " 'Daniel',\n",
       " 'Daniel_C',\n",
       " 'Danielle',\n",
       " 'Darren',\n",
       " 'David',\n",
       " 'David_O',\n",
       " 'Debbie',\n",
       " 'Denise',\n",
       " 'Derwood',\n",
       " 'Desiree',\n",
       " 'Dexter',\n",
       " 'Diane',\n",
       " 'Dillon',\n",
       " 'Dimitris',\n",
       " 'Dominic',\n",
       " 'Donald',\n",
       " 'Donisha',\n",
       " 'Doug',\n",
       " 'Ebony',\n",
       " 'Ed',\n",
       " 'Eddie',\n",
       " 'Effie',\n",
       " 'Eileen',\n",
       " 'Elan',\n",
       " 'Elana',\n",
       " 'Eleanor',\n",
       " 'Eleanora',\n",
       " 'Elena',\n",
       " 'Elizabeth',\n",
       " 'Ella',\n",
       " 'Ellen',\n",
       " 'Elspeth',\n",
       " 'Emily',\n",
       " 'Emma',\n",
       " 'Emma_M',\n",
       " 'Eric',\n",
       " 'Erica',\n",
       " 'Erin',\n",
       " 'Ethan',\n",
       " 'Eugene',\n",
       " 'Evan',\n",
       " 'Eve',\n",
       " 'Faye',\n",
       " 'Frances',\n",
       " 'Frank',\n",
       " 'Fraser',\n",
       " 'GRC',\n",
       " 'Gabriel',\n",
       " 'Gail',\n",
       " 'Garreth_L',\n",
       " 'Gary',\n",
       " 'Gavin',\n",
       " 'Gavin_P',\n",
       " 'Gemma_P',\n",
       " 'Geoffrey',\n",
       " 'George',\n",
       " 'Gerald',\n",
       " 'Gerard_T',\n",
       " 'Gia',\n",
       " 'Gina',\n",
       " 'Gloria',\n",
       " 'Graham',\n",
       " 'Greg',\n",
       " 'Guy',\n",
       " 'Hank',\n",
       " 'Hannah',\n",
       " 'Harriet',\n",
       " 'Heather',\n",
       " 'Heather_G',\n",
       " 'Helen',\n",
       " 'Henry',\n",
       " 'Ian',\n",
       " 'Iris',\n",
       " 'Isadora',\n",
       " 'Ivy',\n",
       " 'JR',\n",
       " 'Jack',\n",
       " 'Jacob_Abernathy',\n",
       " 'Jake',\n",
       " 'James',\n",
       " 'Jamie',\n",
       " 'Jane',\n",
       " 'Janna',\n",
       " 'Jarret',\n",
       " 'Jarrett',\n",
       " 'Jas',\n",
       " 'Jase',\n",
       " 'Jason',\n",
       " 'Jaylen',\n",
       " 'Jaylyn',\n",
       " 'Jeb',\n",
       " 'Jeff',\n",
       " 'Jeffrey',\n",
       " 'Jenessa',\n",
       " 'Jennifer',\n",
       " 'Jennifer_B',\n",
       " 'Jennifer_D',\n",
       " 'Jenny',\n",
       " 'Jeremiah',\n",
       " 'Jeremy',\n",
       " 'Jesse',\n",
       " 'Jessica',\n",
       " 'Jill',\n",
       " 'Jillian',\n",
       " 'Jim',\n",
       " 'Jimmy',\n",
       " 'Jmarkey',\n",
       " 'Joanna',\n",
       " 'Joel',\n",
       " 'Joey',\n",
       " 'JohannaB',\n",
       " 'JohannaF',\n",
       " 'John',\n",
       " 'John_L',\n",
       " 'Johnnie',\n",
       " 'Johnny',\n",
       " 'Jon',\n",
       " 'Jonah',\n",
       " 'Jonathan',\n",
       " 'Jordon',\n",
       " 'Joseph',\n",
       " 'Josh',\n",
       " 'Julia',\n",
       " 'Julie_B',\n",
       " 'June',\n",
       " 'Justin',\n",
       " 'Justine',\n",
       " 'Karen',\n",
       " 'Karl_B',\n",
       " 'Kate',\n",
       " 'Katherine',\n",
       " 'Kathleen',\n",
       " 'Kathy',\n",
       " 'Katie',\n",
       " 'Katie_Fisher',\n",
       " 'Katie_R',\n",
       " 'Katy',\n",
       " 'Katy_A',\n",
       " 'Kay',\n",
       " 'Kayode',\n",
       " 'Keisha',\n",
       " 'Keith',\n",
       " 'Keith_A',\n",
       " 'Kemarr',\n",
       " 'Kent',\n",
       " 'Kerry_L',\n",
       " 'Kevin',\n",
       " 'Kevin_C',\n",
       " 'Kim',\n",
       " 'Kimberly',\n",
       " 'Kip',\n",
       " 'Kirstey_E',\n",
       " 'Kirstie_K',\n",
       " 'Kirsty',\n",
       " 'Kolilan',\n",
       " 'Kristen',\n",
       " 'Kristin',\n",
       " 'Krystal',\n",
       " 'Kyle',\n",
       " 'LEA',\n",
       " 'LaMont',\n",
       " 'LaShod',\n",
       " 'Lara',\n",
       " 'Laura',\n",
       " 'Laura_Aurie',\n",
       " 'Laurel',\n",
       " 'Laurie',\n",
       " 'Lee',\n",
       " 'Lee_H',\n",
       " 'Lena',\n",
       " 'Lew',\n",
       " 'Liam',\n",
       " 'Lincoln',\n",
       " 'Linda',\n",
       " 'Lindsay',\n",
       " 'Lindsey',\n",
       " 'Lindsey_S',\n",
       " 'Lisa',\n",
       " 'Lisa_H',\n",
       " 'Liz',\n",
       " 'Lorena',\n",
       " 'Louise',\n",
       " 'Louise_M',\n",
       " 'Lucy',\n",
       " 'Lynette',\n",
       " 'Maggie',\n",
       " 'Malik',\n",
       " 'Mami',\n",
       " 'Mandi',\n",
       " 'Mandy',\n",
       " 'Marcus',\n",
       " 'Margaret',\n",
       " 'Margot',\n",
       " 'Marie',\n",
       " 'Marjorie',\n",
       " 'Mark',\n",
       " 'Mark_K',\n",
       " 'Martin',\n",
       " 'Mary',\n",
       " 'Matt',\n",
       " 'Matthew',\n",
       " 'Matthew_B',\n",
       " 'Matthew_C',\n",
       " 'Matty',\n",
       " 'Max',\n",
       " 'May',\n",
       " 'Meewha',\n",
       " 'Megan',\n",
       " 'Meghan',\n",
       " 'Melanie',\n",
       " 'Melina',\n",
       " 'Melissa',\n",
       " 'Melvin',\n",
       " 'Meredith',\n",
       " 'Mia',\n",
       " 'Micah',\n",
       " 'Michael',\n",
       " 'Michael_D',\n",
       " 'Michael_H',\n",
       " 'Michelle',\n",
       " 'Mike',\n",
       " 'Miranda',\n",
       " 'Mirra',\n",
       " 'Mohammed',\n",
       " 'Molly',\n",
       " 'Morgan',\n",
       " 'Naimen',\n",
       " 'Nan',\n",
       " 'Nancy',\n",
       " 'Nanette',\n",
       " 'Naomi',\n",
       " 'Nat',\n",
       " 'Natalie',\n",
       " 'Nathan',\n",
       " 'Nathaniel',\n",
       " 'Ned',\n",
       " 'Neil',\n",
       " 'Neville',\n",
       " 'Nicola',\n",
       " 'Nicola_L',\n",
       " 'Nicolas',\n",
       " 'Nicole',\n",
       " 'Nicolette',\n",
       " 'Nikki',\n",
       " 'Nina',\n",
       " 'Nina_M',\n",
       " None,\n",
       " 'Nora',\n",
       " 'Norman',\n",
       " 'Ole',\n",
       " 'Oliver',\n",
       " 'Olivia',\n",
       " 'Patricia',\n",
       " 'Patrick',\n",
       " 'Paul',\n",
       " 'Paul_C',\n",
       " 'Paul_X',\n",
       " 'Paula',\n",
       " 'Penny',\n",
       " 'Pete',\n",
       " 'Peter',\n",
       " 'Petruvna',\n",
       " 'Philip',\n",
       " 'Rachael',\n",
       " 'Rachel',\n",
       " 'Rachel_X',\n",
       " 'Rashawnda',\n",
       " 'Rebecca',\n",
       " 'Remi',\n",
       " 'Renee',\n",
       " 'Rhiannon',\n",
       " 'Richard',\n",
       " 'Richard_G',\n",
       " 'Rick',\n",
       " 'Robbie',\n",
       " 'Robert',\n",
       " 'Roger',\n",
       " 'Roland',\n",
       " 'Roman',\n",
       " 'Ronald',\n",
       " 'Ronny',\n",
       " 'Rory',\n",
       " 'Rosie',\n",
       " 'Ross',\n",
       " 'Rufus',\n",
       " 'Ruth',\n",
       " 'Ryan',\n",
       " 'Sally',\n",
       " 'Sam',\n",
       " 'Samantha',\n",
       " 'Sandra',\n",
       " 'Sara',\n",
       " 'Sarah',\n",
       " 'Sarah_F',\n",
       " 'Scott',\n",
       " 'Scott_R',\n",
       " 'Sean',\n",
       " 'Sebastian',\n",
       " 'Seth',\n",
       " 'Shadja',\n",
       " 'Shaw',\n",
       " 'Shawna',\n",
       " 'She',\n",
       " 'Shea',\n",
       " 'Sheila',\n",
       " 'Shell',\n",
       " 'Shem',\n",
       " 'Simon',\n",
       " 'Sissy',\n",
       " 'Sofia',\n",
       " 'Stella',\n",
       " 'Stephen',\n",
       " 'Stephen_R',\n",
       " 'Steve',\n",
       " 'Steven',\n",
       " 'Stuart',\n",
       " 'Stuart_B',\n",
       " 'Student',\n",
       " 'Sue',\n",
       " 'Summer',\n",
       " 'Susan',\n",
       " 'Susanna',\n",
       " 'Susie',\n",
       " 'TJ',\n",
       " 'Tabitha',\n",
       " 'Tabitha_Sims',\n",
       " 'Taisha',\n",
       " 'Tameka',\n",
       " 'Tania',\n",
       " 'Tara',\n",
       " 'Tarsha',\n",
       " 'Tatum',\n",
       " 'Temetrius',\n",
       " 'Terran',\n",
       " 'Theo',\n",
       " 'Theresa',\n",
       " 'Thomas',\n",
       " 'Tim',\n",
       " 'Timothy',\n",
       " 'Todd',\n",
       " 'Tom',\n",
       " 'Tommy',\n",
       " 'Tonisha',\n",
       " 'Tony',\n",
       " 'Tow',\n",
       " 'Tracy',\n",
       " 'Travis',\n",
       " 'Trene',\n",
       " 'Trenice',\n",
       " 'Trevor',\n",
       " 'Trina',\n",
       " 'Trisha',\n",
       " 'Tristan',\n",
       " 'Tristen',\n",
       " 'Troy',\n",
       " 'Ty',\n",
       " 'Tyhisha',\n",
       " 'Tyler',\n",
       " 'Tyrese',\n",
       " 'Ursula',\n",
       " 'Valerie',\n",
       " 'Vas',\n",
       " 'Vas_Coleman',\n",
       " 'Veronica',\n",
       " 'Vicki',\n",
       " 'Victor',\n",
       " 'Victoria',\n",
       " 'Victoria_B',\n",
       " 'Vincent',\n",
       " 'Von',\n",
       " 'Walter',\n",
       " 'Wanda',\n",
       " 'Warren',\n",
       " 'Wayne',\n",
       " 'Wendy',\n",
       " 'Will',\n",
       " 'William',\n",
       " 'Willie',\n",
       " 'Xavia',\n",
       " 'Xavier',\n",
       " 'Yvonne',\n",
       " 'Zachary',\n",
       " 'Zackary',\n",
       " 'Zane',\n",
       " 'Zeke',\n",
       " 'Zoe',\n",
       " 'mos'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(utt_glosses.target_child_name) # Note it doesn't have the child's name anymore -- do you need to split early?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4205071, 6)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3959952, 7)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any with xxx or yyy\n",
    "utt_glosses['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in utt_glosses.gloss]\n",
    "utt_glosses = utt_glosses.loc[~utt_glosses.contains_error]\n",
    "utt_glosses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gloss(gloss):\n",
    "    return(str(gloss).replace('+',' ').replace('_',' '))\n",
    "\n",
    "utt_glosses.gloss = [fix_gloss(x) for x in utt_glosses.gloss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "declarative                   2828187\n",
       "question                       903625\n",
       "imperative_emphatic            114118\n",
       "trail off                       63230\n",
       "interruption                    16870\n",
       "missing CA terminator           14430\n",
       "self interruption               11307\n",
       "quotation next line              5903\n",
       "interruption question             877\n",
       "quotation precedes                756\n",
       "trail off question                504\n",
       "self interruption question        125\n",
       "broken for coding                  17\n",
       "no break TCU continuation           3\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_for_type = {\n",
    "    'question':'?',\n",
    "    'declarative':'.',\n",
    "    'interruption':'!',\n",
    "    'trail off':'...',\n",
    "    'trail off question':'?',\n",
    "    'imperative_emphatic':'!' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses['punct'] = [punct_for_type[x] if x in punct_for_type else None\n",
    "                        for x in utt_glosses.type ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gloss              now we need this\n",
       "transcript_id                  3261\n",
       "id                           279663\n",
       "utterance_order                   1\n",
       "speaker_code                    CHI\n",
       "type                      trail off\n",
       "contains_error                False\n",
       "punct                           ...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses['speaker_code_simple'] = ['[CHI]' if x == 'CHI' else '[CGV]'\n",
    "    for x in utt_glosses.speaker_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses = utt_glosses.loc[[x is not None for x in utt_glosses.punct]]\n",
    "utt_glosses['gloss_with_punct'] = [x['speaker_code_simple'] + ' '+ x['gloss'].lower() + x['punct'] for x in utt_glosses.to_dict('records')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                          [CHI] now we need this...\n",
       "2                        [CHI] we need we you don't.\n",
       "3    [CHI] need a pocketbook because i'm the mother.\n",
       "4                               [CHI] i'm i'm the...\n",
       "6         [CHI] now you can watch now wait a minute.\n",
       "Name: gloss_with_punct, dtype: object"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses.head(5).gloss_with_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the unigram counts for tokens and remap any problematic ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses['tokens'] = [str(x).lower().split(' ') for x in utt_glosses.gloss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [y for x in utt_glosses['tokens'] for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_frequencies = pd.Series(all_tokens).value_counts().reset_index()\n",
    "all_token_frequencies.columns = ['word','count']\n",
    "all_token_frequencies.to_csv('data/vocab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check what we are missing: filter to ones outside of a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = spellchecker.SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_frequencies['in_dict'] = [len(spell.unknown([x])) == 0  for  x in all_token_frequencies.word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>in_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>148011</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>mhm</td>\n",
       "      <td>28524</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>hm</td>\n",
       "      <td>23665</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>www</td>\n",
       "      <td>18965</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>mm</td>\n",
       "      <td>14499</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56860</th>\n",
       "      <td>hayahe</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56862</th>\n",
       "      <td>brmmmtssss</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56863</th>\n",
       "      <td>adudududududududu</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56864</th>\n",
       "      <td>ghooghoo</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56865</th>\n",
       "      <td>eieiiuh</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25838 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word   count  in_dict\n",
       "16                        148011    False\n",
       "92                   mhm   28524    False\n",
       "113                   hm   23665    False\n",
       "127                  www   18965    False\n",
       "157                   mm   14499    False\n",
       "...                  ...     ...      ...\n",
       "56860             hayahe       1    False\n",
       "56862         brmmmtssss       1    False\n",
       "56863  adudududududududu       1    False\n",
       "56864           ghooghoo       1    False\n",
       "56865            eieiiuh       1    False\n",
       "\n",
       "[25838 rows x 3 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_token_frequencies.loc[all_token_frequencies['in_dict'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" mhm hm www mm uhhuh needta uhoh jwww purdie n b s sposta t mummie zzz c uhuh d firstname useta hadta m jwww's ahhah p willn't r mr w shh tv h mrs g l nappie dimitra mm-hm aah f k uhhum purdie's awww afternoon lwww swww aran pottie choos ssh no-no cwww j lastname v fraser's neenaw hunhunh cromer pingu th x dwww botbot mwww wh q ummhm mkay z awoh sukie dada's ewww marky's sh duplo tweenies enne dadaw mummy'll nuhhuh rwww twww chih gwww grr beepbeep didsbury beeba ch kalie zorg afterwards jeannine's pennys tellie miffy baaee didldow uh-huh baura bwww stockport firstname's grrr kwww ntuu puttaputta mummie's unhunh dollie ribena ninight weener hunm pippo brr mm-mm peeppeep awww's dimitra's strawberrys teletubby kokowk bowwow gagaa puppys ss umhum batterys psh brumbrum dr pingu's jj hwww paddington mooshas goggins nwww sss lorrys morgie st nuuw pickyaup koolaid babyschool carle dipsy's aislinn swww's dodie jaylen pwww bzz toybox eensie babaa aladar tisha aaron aguh weensie ewww's sainsburys baaee's zita maisy's band-aid teddys brrm dadada moosh snipsnips bangadrumtime playdough gonga smily comed derwood lala's peekababy poohbear tomatos ooaa mieow eeat daet morag bouncie seuss owww dollys upsidedown wodar licken mumma heehee rrr woofwoof byebyes wanta psst horsie's peepo tsk tr jenell hmm nac frostie tadi butterflys macdonald's pippin's wakie uhh brisco maisie's uguh moomooshas pilchard's nin's peepbo lwww's clarabel pss calpol lalight cockadoodledoo whoowhoo phss ribbet badji tiddles wibble cadabra gwww's babar beebaa maisey ross's talkaphone diandros dabee swingswing jenko ms kayode doggys weetabix gr comere diandra dingalingaling brrrm bealby aitchoo poppop shishi bodger brm hmhm nere rwww's brrr moomilk cromer's mummum brek cwww's moomoo granma loxy whad nenaw ahphsss dwww's ahphss bunnys ruhf tweenie br kah noddy's nomi's beebabeeba winky's peeppo alrightie lellow timms dyeisha gluck ditn clipclop dey're streetname piggys pssh daisys fiigh brittney huhuh snotsnot badada pooh's tellytubbies bathtime urler daddad elana sukie's policecar ughoh trafford heehaw ewoks tikatika woosh dadadada beebah aa millisandy pipit deir playdoh cellotape playdays dadda's bramwell chk burnage wiggily broombroom uwww diplodocus asda rolly-polly bzzz pitterpatter teletubbie googey dougall band-aids mwuh bringed greggy grocerys rr incy twww's bibbie bika boneen uah potatohead pl weist quackquack yoohoo malta scritch pavarotti peam kh duhm nonno pbth snoopy's swiper blup bickie tinkey whiskas uhs co-op tunde mumm galloppy huggle ackack pf lanzarotte sindy nn noahs storytime roo's ringring kids' iwww squirrelie sweetpeas gween biup tubbie brokened humsah jellys tshirt brrmm miaw wead plattford bl brummbrumm cakie babydolls lenita ankylosaurus neenah um- feetman neenor urr hhh osc winkey chugga elephants's racketyboom ts com'ere mckayla macwhinney pway amye x-ray maltesers morgie's olliga kaking scarry pj tyrannadon kwww's ugah mwww's lullah ladybird's tnt wincey baebae gonegone ema ribit eggie doed mogli fitzie yike pooppoop psshh dins tubbies rockrock hendrika lalalight roadgrader baw der's cmere cherrys kipper's teppy pinkerbell perri eeyore's robbin s- reverand olwin toptie anudder wannoo dyllis bumbo lilys ihiy graeme's toffer glugglug kirsty ditiduck carwashed cl gonkey sc mouf toesies douie agah tesco's mothercare ehh oowah budleyley tummys tiggy tweettweet teddybears tch carcar booboon huggie dotdot fwww uppie mommys miffy's phsss anoder memee clarabell chickenlicken zita's woa tressa mmmm mot's fizzie incey glig sp cockadoo eyeore cr puddleduck gwampa pitterpat beebas binkie pennie toottoot babas mmm sockies babygro adadada kenobi brmm binkies meike guah huhu bdr afwww teradon mormor pottage mooshaboosh mamama emmitt morg wellfleet appul sockie milkie majorca ericka tyrannasaurus melissi papadums dinosorter snuggy year-old fwee budleyleys plattford's dedede vasie m's aoife cricter chewies messpot kaaee beeu gramma's kuhz shem's kissie kittys wahwahwah platford rrrr oughtoh feeled blitzen passy shopman soopers glossop kitkat deedee's klandat dadadadada airpwane giya naila lakey anna'll sainsbury isabell baalamb edger markie vimto salley ahh impy teethies mummmumm tummyache taperecorder noo's stegasaurus eeee i- hwww's purd botbots dollie's binbag hatu cootchykoo noonoos afternoons bwww's sn winned battersby pairplane pandy buba boingy purds babye glugglugglug poddy readybrek wau crayoning walkwalk peanuh gullivers yuckies tupty tellytubby teeshirt cj ballie scania ashworth rinny petto kahl sqwark sunshining bbc weh blanketie pansys legoland kaylia hanabata a- hosepipes whingy jac tato snotsnots uheh bingbong hh toothie gumpy looby mosasaurus paf twittwoo whassat mootie twuck drakey noonoo fr andrena wup froggie's bisto alissa poping tsh noos poy ojo limme yeahhuh de're oompapa cesca mikie wantuh pjs peeka gagi nyla babybel camed gobot swimmed furby cattery surfboarding appledumpling bogdos cadburys burny aminals bumpa feeties dja babykins bathie gluck's agu wompa pshh bitatin zig-zag amira fittis playschool sabato rarr weady bumpety chuffchuff dumpty's rachael's yook bertie's cb ruldolph lae awound ds shushus bummie mondale pwease rarara mummie'll lekker rydan frostie's deetoo jp plip mitra mmkay parcs swingie lalas greenbeans pating pher gepetto pwww's dora's mcginty clickclick eeaw balooga doz fuh kanga's lollys judie gonk sticklebricks disneyworld purpley agether alfie's beebaabeebaa adah mantlepiece peanus upsa wwww jolly's sealie nanna's squamy duhduhduh bababa fruitshoot flopsy maryse tweenys one're dada'll doodledoo tshh pappap ahahah wigh clk aladin wayland sm jack-o-lantern malenda vwww ferdie raa oooooo woowoo andrex delma's putta mopsy doid hankey wock dadaw's come'ere aeae pr wellys noodly gingells grannys tweetie weeow tv's bubu papu cornfalkes adada ssss nadi beilbie gallopy balmex someping drrun cbbc pacie cecelia ueh sl zuggle tatoes eheh boomp ugeh beanice wye terrapin gunkies busam boys' pth tla qwynnie aminal kix heman wiggleworm cwash aneen greatgrandma yick blandsworth shooshoo kn buttie rolo mcgregor's frys goggin pishie santie fozzy decky gulliver's aten uh-uh hiho wawawa girls' jess's dairylea swingset kk gribbet nuttin sayla matoes quik else're cici vavavap chugchug rmm pinnochio phh deliverys cweam morag's pku nwww's szörp brycie emmy's nawnee oohoo fl yuli reva theetje twy fairys delias eeai giggler lexy corney tw lynne's crosseyed hetti psss megablocks lamplady droved owww's bithothay booboop postbag backways papups poppys yipes bilbey snowdon leigha macclesfield derz dakota's rachi myumm allj wecord rightie popple mornit suitsuit minoru protocerotops beefburger keewee yiy kaa dalmation visitting tic-tac-toe biscos araffe arrgh tiggywinkle loddy baloo's rolly-pollies samara's weist's parkin purditer ghetti uhah buhm gertinor badi clippety thoughted wokka byebaby daetz jenell's lucka eieio\""
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(all_token_frequencies.loc[all_token_frequencies['in_dict'] == False].head(1000).word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Re-order by transcript and token order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses_sorted = utt_glosses.sort_values(by=['transcript_id', 'utterance_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "      <th>contains_error</th>\n",
       "      <th>punct</th>\n",
       "      <th>speaker_code_simple</th>\n",
       "      <th>gloss_with_punct</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>look</td>\n",
       "      <td>3260</td>\n",
       "      <td>279700</td>\n",
       "      <td>2</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] look.</td>\n",
       "      <td>[look]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>can I have some</td>\n",
       "      <td>3260</td>\n",
       "      <td>279707</td>\n",
       "      <td>4</td>\n",
       "      <td>CHI</td>\n",
       "      <td>question</td>\n",
       "      <td>False</td>\n",
       "      <td>?</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] can i have some?</td>\n",
       "      <td>[can, i, have, some]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>is this</td>\n",
       "      <td>3260</td>\n",
       "      <td>279716</td>\n",
       "      <td>6</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] is this.</td>\n",
       "      <td>[is, this]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>don't call me Karen because I'm not Karen</td>\n",
       "      <td>3260</td>\n",
       "      <td>279730</td>\n",
       "      <td>10</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] don't call me karen because i'm not karen.</td>\n",
       "      <td>[don't, call, me, karen, because, i'm, not, ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I'm Amy</td>\n",
       "      <td>3260</td>\n",
       "      <td>279735</td>\n",
       "      <td>11</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] i'm amy.</td>\n",
       "      <td>[i'm, amy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        gloss  transcript_id      id  \\\n",
       "12                                       look           3260  279700   \n",
       "15                            can I have some           3260  279707   \n",
       "18                                    is this           3260  279716   \n",
       "22  don't call me Karen because I'm not Karen           3260  279730   \n",
       "24                                    I'm Amy           3260  279735   \n",
       "\n",
       "    utterance_order speaker_code         type  contains_error punct  \\\n",
       "12                2          CHI  declarative           False     .   \n",
       "15                4          CHI     question           False     ?   \n",
       "18                6          CHI  declarative           False     .   \n",
       "22               10          CHI  declarative           False     .   \n",
       "24               11          CHI  declarative           False     .   \n",
       "\n",
       "   speaker_code_simple                                  gloss_with_punct  \\\n",
       "12               [CHI]                                       [CHI] look.   \n",
       "15               [CHI]                            [CHI] can i have some?   \n",
       "18               [CHI]                                    [CHI] is this.   \n",
       "22               [CHI]  [CHI] don't call me karen because i'm not karen.   \n",
       "24               [CHI]                                    [CHI] i'm amy.   \n",
       "\n",
       "                                               tokens  \n",
       "12                                             [look]  \n",
       "15                               [can, i, have, some]  \n",
       "18                                         [is, this]  \n",
       "22  [don't, call, me, karen, because, i'm, not, ka...  \n",
       "24                                         [i'm, amy]  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3926534, 11)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses_sorted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754\n"
     ]
    }
   ],
   "source": [
    "# select 20 % of the transcripts for training\n",
    "transcript_inventory = np.unique(utt_glosses_sorted.transcript_id)\n",
    "validation_indices = np.random.choice(transcript_inventory, \n",
    "    int(np.round(len(transcript_inventory) / 5)))\n",
    "print(len(validation_indices))\n",
    "utt_glosses_sorted['partition'] = 'train'\n",
    "utt_glosses_sorted.loc[utt_glosses_sorted.transcript_id.isin(validation_indices), \n",
    "    'partition'] = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train         3204912\n",
       "validation     721622\n",
       "Name: partition, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses_sorted.partition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/stephan/notebooks/child-directed-listening'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses_sorted.loc[utt_glosses_sorted.partition =='validation'] \\\n",
    "          [['gloss_with_punct']].to_csv('data/validation.txt', index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses_sorted.loc[utt_glosses_sorted.partition =='train'] \\\n",
    "          [['gloss_with_punct']].to_csv('data/train.txt', index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run run_mlm_finetune_on_childes.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ ] Put on OpenMind for GPU usage -- nope, vagrant totall broken\n",
    "# [X] Confirm that I can do a hello word for MLM training\n",
    "    https://github.com/huggingface/transformers/tree/master/examples/language-modeling\n",
    "# [ ] replace the training and testing datasets with things from CHILDES\n",
    "# [ ] can the yielded model be used with the existing query code? transformers vs. torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "      <th>contains_error</th>\n",
       "      <th>punct</th>\n",
       "      <th>speaker_code_simple</th>\n",
       "      <th>gloss_with_punct</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now we need this</td>\n",
       "      <td>3261</td>\n",
       "      <td>279663</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>trail off</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] now we need this...</td>\n",
       "      <td>[now, we, need, this]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we need we you don't</td>\n",
       "      <td>3261</td>\n",
       "      <td>279666</td>\n",
       "      <td>2</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] we need we you don't.</td>\n",
       "      <td>[we, need, we, you, don't]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need a pocketbook because I'm the mother</td>\n",
       "      <td>3261</td>\n",
       "      <td>279668</td>\n",
       "      <td>3</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] need a pocketbook because i'm the mother.</td>\n",
       "      <td>[need, a, pocketbook, because, i'm, the, mother]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm I'm the</td>\n",
       "      <td>3261</td>\n",
       "      <td>279670</td>\n",
       "      <td>5</td>\n",
       "      <td>CHI</td>\n",
       "      <td>trail off</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] i'm i'm the...</td>\n",
       "      <td>[i'm, i'm, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>now you can watch now wait a minute</td>\n",
       "      <td>3261</td>\n",
       "      <td>279672</td>\n",
       "      <td>7</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] now you can watch now wait a minute.</td>\n",
       "      <td>[now, you, can, watch, now, wait, a, minute]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205066</th>\n",
       "      <td>none you did so</td>\n",
       "      <td>25473</td>\n",
       "      <td>10212128</td>\n",
       "      <td>1763</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] none you did so.</td>\n",
       "      <td>[none, you, did, so]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205068</th>\n",
       "      <td>is it not nice</td>\n",
       "      <td>25473</td>\n",
       "      <td>10212130</td>\n",
       "      <td>1765</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "      <td>False</td>\n",
       "      <td>?</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] is it not nice?</td>\n",
       "      <td>[is, it, not, nice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205069</th>\n",
       "      <td>no</td>\n",
       "      <td>25473</td>\n",
       "      <td>10212131</td>\n",
       "      <td>1766</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] no.</td>\n",
       "      <td>[no]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205070</th>\n",
       "      <td>yeah you have me tired out</td>\n",
       "      <td>25473</td>\n",
       "      <td>10212132</td>\n",
       "      <td>1767</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] yeah you have me tired out.</td>\n",
       "      <td>[yeah, you, have, me, tired, out]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205071</th>\n",
       "      <td>me too</td>\n",
       "      <td>25473</td>\n",
       "      <td>10212136</td>\n",
       "      <td>1768</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] me too.</td>\n",
       "      <td>[me, too]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926534 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            gloss  transcript_id        id  \\\n",
       "1                                now we need this           3261    279663   \n",
       "2                            we need we you don't           3261    279666   \n",
       "3        need a pocketbook because I'm the mother           3261    279668   \n",
       "4                                     I'm I'm the           3261    279670   \n",
       "6             now you can watch now wait a minute           3261    279672   \n",
       "...                                           ...            ...       ...   \n",
       "4205066                           none you did so          25473  10212128   \n",
       "4205068                            is it not nice          25473  10212130   \n",
       "4205069                                        no          25473  10212131   \n",
       "4205070                yeah you have me tired out          25473  10212132   \n",
       "4205071                                    me too          25473  10212136   \n",
       "\n",
       "         utterance_order speaker_code         type  contains_error punct  \\\n",
       "1                      1          CHI    trail off           False   ...   \n",
       "2                      2          CHI  declarative           False     .   \n",
       "3                      3          CHI  declarative           False     .   \n",
       "4                      5          CHI    trail off           False   ...   \n",
       "6                      7          CHI  declarative           False     .   \n",
       "...                  ...          ...          ...             ...   ...   \n",
       "4205066             1763          MOT  declarative           False     .   \n",
       "4205068             1765          MOT     question           False     ?   \n",
       "4205069             1766          CHI  declarative           False     .   \n",
       "4205070             1767          MOT  declarative           False     .   \n",
       "4205071             1768          CHI  declarative           False     .   \n",
       "\n",
       "        speaker_code_simple                                 gloss_with_punct  \\\n",
       "1                     [CHI]                        [CHI] now we need this...   \n",
       "2                     [CHI]                      [CHI] we need we you don't.   \n",
       "3                     [CHI]  [CHI] need a pocketbook because i'm the mother.   \n",
       "4                     [CHI]                             [CHI] i'm i'm the...   \n",
       "6                     [CHI]       [CHI] now you can watch now wait a minute.   \n",
       "...                     ...                                              ...   \n",
       "4205066               [CGV]                           [CGV] none you did so.   \n",
       "4205068               [CGV]                            [CGV] is it not nice?   \n",
       "4205069               [CHI]                                        [CHI] no.   \n",
       "4205070               [CGV]                [CGV] yeah you have me tired out.   \n",
       "4205071               [CHI]                                    [CHI] me too.   \n",
       "\n",
       "                                                   tokens  \n",
       "1                                   [now, we, need, this]  \n",
       "2                              [we, need, we, you, don't]  \n",
       "3        [need, a, pocketbook, because, i'm, the, mother]  \n",
       "4                                         [i'm, i'm, the]  \n",
       "6            [now, you, can, watch, now, wait, a, minute]  \n",
       "...                                                   ...  \n",
       "4205066                              [none, you, did, so]  \n",
       "4205068                               [is, it, not, nice]  \n",
       "4205069                                              [no]  \n",
       "4205070                 [yeah, you, have, me, tired, out]  \n",
       "4205071                                         [me, too]  \n",
       "\n",
       "[3926534 rows x 11 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_utt_glosses = utt_glosses.loc[utt_glosses.speaker_code == 'CHI']\n",
    "chi_tokens = [y for x in chi_utt_glosses['tokens'] for y in x]\n",
    "chi_token_frequencies = pd.Series(chi_tokens).value_counts().reset_index()\n",
    "chi_token_frequencies.columns = ['word','count']\n",
    "chi_token_frequencies.to_csv('data/chi_vocab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>168156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>131763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>111961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeah</td>\n",
       "      <td>103693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it</td>\n",
       "      <td>100575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word   count\n",
       "0     i  168156\n",
       "1     a  131763\n",
       "2   the  111961\n",
       "3  yeah  103693\n",
       "4    it  100575"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_token_frequencies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4205071 4205071\n"
     ]
    }
   ],
   "source": [
    "number_id = len(set(utt_glosses.id))\n",
    "this_len = len(utt_glosses)\n",
    "\n",
    "print(number_id, this_len) # Yes, they are true ids of the entries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
