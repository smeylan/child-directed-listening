{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepares Providence data\n",
    "\n",
    "Evaluation set for all and age splits.\n",
    "\n",
    "Both the finetuning and evaluation set (split) for child finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "import childespy\n",
    "import numpy as np\n",
    "import os\n",
    "import imp\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import re\n",
    "import unicodedata\n",
    "import scipy.stats\n",
    "import copy\n",
    "from string import punctuation\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import transfomers_bert_completions, split_gen, data_cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and clean the source of individual utterance samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communicative success: how many no-xxx, no-yyy child  utterances are in Providence? \n",
    "# Communicative failures: how many one-yyy, no-xxx child utterances are in Providence?\n",
    "# Subset to instances that are monosyllabic later\n",
    "\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n",
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"').iloc[0]['id']\n",
    "\n",
    "phono_glosses = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, actual_phonology, model_phonology, transcript_id, utterance_id, \\\n",
    "    token_order, corpus_name, collection_name, language from token where \\\n",
    "    actual_phonology != \"\" and model_phonology != \"\" and collection_name = \"Eng-NA\" \\\n",
    "    and corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providence    396621\n",
      "Name: corpus_name, dtype: int64\n",
      "*          26736\n",
      "ə             10\n",
      "(.)            7\n",
      "aɪ             4\n",
      "pitched        2\n",
      "           ...  \n",
      "pʊ             1\n",
      "dulɪ           1\n",
      "kɪ             1\n",
      "noise          1\n",
      "də             1\n",
      "Name: actual_phonology, Length: 76, dtype: int64\n",
      "ɛ           3206\n",
      "ʌ           2132\n",
      "ɪ           1881\n",
      "ə            512\n",
      "o            507\n",
      "            ... \n",
      "maɪklwə        1\n",
      "mʌmɪzɪ         1\n",
      "nɪtʌns̩        1\n",
      "wɑdɪdɑɛː       1\n",
      "lʌ̃            1\n",
      "Name: actual_phonology, Length: 30293, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if verbose: \n",
    "    print(phono_glosses.corpus_name.value_counts())\n",
    "    print(phono_glosses.loc[phono_glosses.gloss == 'xxx'].actual_phonology.value_counts())\n",
    "    print(phono_glosses.loc[phono_glosses.gloss == 'yyy'].actual_phonology.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_phono = phono_glosses.loc[(phono_glosses.speaker_code == 'CHI') & \n",
    "    (phono_glosses.target_child_age < (365*5))]\n",
    "\n",
    "def count_transmission_errors(utt_vector, error_codes):\n",
    "    return(np.sum([x in error_codes for x in  utt_vector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gloss', 'target_child_name', 'target_child_age', 'speaker_code',\n",
       "       'actual_phonology', 'model_phonology', 'transcript_id', 'utterance_id',\n",
       "       'token_order', 'corpus_name', 'collection_name', 'language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_phono.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31457, 3)\n",
      "(83880, 3)\n"
     ]
    }
   ],
   "source": [
    "xxxs_per_utt = chi_phono.groupby('utterance_id').gloss.agg(\n",
    "    lambda x: count_transmission_errors(x, ['xxx'])).reset_index()\n",
    "xxxs_per_utt.columns = ['utterance_id', 'num_xxx']\n",
    "yyys_per_utt = chi_phono.groupby('utterance_id').gloss.agg(\n",
    "    lambda x: count_transmission_errors(x, ['yyy'])).reset_index()\n",
    "yyys_per_utt.columns = ['utterance_id', 'num_yyy']\n",
    "failures_per_utt = xxxs_per_utt.merge(yyys_per_utt)\n",
    "\n",
    "raw_yyy_utts = failures_per_utt.loc[(failures_per_utt.num_xxx == 0) &  (failures_per_utt.num_yyy == 1)]\n",
    "\n",
    "if verbose: print(raw_yyy_utts.shape)\n",
    "\n",
    "raw_success_utts = failures_per_utt.loc[(failures_per_utt.num_xxx == 0) &  \n",
    "    (failures_per_utt.num_yyy == 0)]\n",
    "\n",
    "if verbose: print(raw_success_utts.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor below to the other notebook -- load based on cached successes instead? Unsure if there is a dependency there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214239, 12)\n",
      "1          ɑmɪ\n",
      "3          wiː\n",
      "4          wiː\n",
      "5           uː\n",
      "52           ɛ\n",
      "          ... \n",
      "396606       o\n",
      "396607     waɪ\n",
      "396608     liʔ\n",
      "396609       ɪ\n",
      "396610    hɪpo\n",
      "Name: actual_phonology, Length: 214239, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Probably move this to the other analysis notebook and use caching instead on the data.\n",
    "\n",
    "\n",
    "tokens_from_errorless_utts = chi_phono.loc[chi_phono.utterance_id.isin(raw_success_utts.utterance_id)]\n",
    "#exclude un-transcribed tokens and syllabically transcribed tokens\n",
    "excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "tokens_from_errorless_utts = tokens_from_errorless_utts.loc[~(tokens_from_errorless_utts.actual_phonology.isin(excludes) |\n",
    "    tokens_from_errorless_utts.model_phonology.isin(excludes))]\n",
    "\n",
    "if verbose:\n",
    "    print(tokens_from_errorless_utts.shape)\n",
    "    print(tokens_from_errorless_utts.actual_phonology)\n",
    "\n",
    "# 31,457 transmission errors (from 31,457 utterances)\n",
    "# 214,239 transmission successes (from 83,880 utterances)\n",
    "# this will be further decreased later by the need to test monosyllabic forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and clean Providence data \n",
    "\n",
    "Corresponds to: 4 | Prep Utterances / Tokens for BERT,\n",
    "    in the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_models, data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n",
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regenerate = True\n",
    "verbose = True\n",
    "\n",
    "# Get the index of the Providence corpus\n",
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"').iloc[0]['id']\n",
    "\n",
    "# Load utterances from the Providence corpus from childs-db\n",
    "\n",
    "if regenerate:\n",
    "    raw_utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, target_child_name, target_child_age, type from utterance where corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    raw_utt_glosses.to_csv('csv/pvd_utt_glosses.csv', index=False)\n",
    "else: \n",
    "    raw_utt_glosses = pd.read_csv('csv/pvd_utt_glosses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gloss', 'transcript_id', 'id', 'utterance_order', 'speaker_code',\n",
       "       'target_child_name', 'target_child_age', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_utt_glosses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_chi_phono_utts = raw_utt_glosses.copy() # Avoid cleaning the glosses for the utt_glosses twice (see prep code for child splits)\n",
    "utt_glosses = data_cleaning.clean_glosses(for_chi_phono_utts, '.')\n",
    "\n",
    "if verbose: utt_glosses[utt_glosses.id == 17280964]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7904, 8)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(load_models)\n",
    "\n",
    "root_dir = '/home/nwong/chompsky/childes/child_listening_continuation/child-directed-listening/'\n",
    "\n",
    "cmu_2syl_inchildes = load_models.get_cmu_dict_info(root_dir = root_dir)\n",
    "\n",
    "# tokenize with the most extensive tokenizer, which is the one used for model #2\n",
    "\n",
    "initial_tokenizer = load_models.get_meylan_original_model(with_tags = True, root_dir = root_dir)['tokenizer']\n",
    "\n",
    "initial_tokenizer.add_tokens(['yyy','xxx']) #must maintain xxx and yyy for alignment,\n",
    "# otherwwise, BERT tokenizer will try to separate these into x #x and #x and y #y #y\n",
    "inital_vocab_mask, initial_vocab = transfomers_bert_completions.get_softmax_mask(initial_tokenizer,\n",
    "    cmu_2syl_inchildes.word)\n",
    "\n",
    "# confirm yyy treated as a separate character\n",
    "assert initial_tokenizer.tokenize('this is a yyy.') == ['this', 'is', 'a', 'yyy', '.']\n",
    "\n",
    "cmu_in_initial_vocab = cmu_2syl_inchildes.loc[cmu_2syl_inchildes.word.isin(initial_vocab)]\n",
    "\n",
    "if verbose: print(cmu_in_initial_vocab.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   token        id                                         gloss  \\\n",
      "0  [cgv]  16759250                    where do you want me to go   \n",
      "1  where  16759250                    where do you want me to go   \n",
      "2     do  16759250                    where do you want me to go   \n",
      "3    you  16759250                    where do you want me to go   \n",
      "4   want  16759250                    where do you want me to go   \n",
      "5     me  16759250                    where do you want me to go   \n",
      "6     to  16759250                    where do you want me to go   \n",
      "7     go  16759250                    where do you want me to go   \n",
      "8      ?  16759250                    where do you want me to go   \n",
      "9  [cgv]  16759261  anywhere you'll feel comfortable um anywhere   \n",
      "\n",
      "   transcript_id  utterance_order speaker_code target_child_name  \\\n",
      "0          42204                1          OPE              Alex   \n",
      "1          42204                1          OPE              Alex   \n",
      "2          42204                1          OPE              Alex   \n",
      "3          42204                1          OPE              Alex   \n",
      "4          42204                1          OPE              Alex   \n",
      "5          42204                1          OPE              Alex   \n",
      "6          42204                1          OPE              Alex   \n",
      "7          42204                1          OPE              Alex   \n",
      "8          42204                1          OPE              Alex   \n",
      "9          42204                2          MOT              Alex   \n",
      "\n",
      "   target_child_age         type punct speaker_code_simple  \\\n",
      "0             514.0     question     ?               [CGV]   \n",
      "1             514.0     question     ?               [CGV]   \n",
      "2             514.0     question     ?               [CGV]   \n",
      "3             514.0     question     ?               [CGV]   \n",
      "4             514.0     question     ?               [CGV]   \n",
      "5             514.0     question     ?               [CGV]   \n",
      "6             514.0     question     ?               [CGV]   \n",
      "7             514.0     question     ?               [CGV]   \n",
      "8             514.0     question     ?               [CGV]   \n",
      "9             514.0  declarative     .               [CGV]   \n",
      "\n",
      "                                    gloss_with_punct  \n",
      "0                  [CGV] where do you want me to go?  \n",
      "1                  [CGV] where do you want me to go?  \n",
      "2                  [CGV] where do you want me to go?  \n",
      "3                  [CGV] where do you want me to go?  \n",
      "4                  [CGV] where do you want me to go?  \n",
      "5                  [CGV] where do you want me to go?  \n",
      "6                  [CGV] where do you want me to go?  \n",
      "7                  [CGV] where do you want me to go?  \n",
      "8                  [CGV] where do you want me to go?  \n",
      "9  [CGV] anywhere you'll feel comfortable um anyw...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build a dataframe of tokens \n",
    "# this is slow, because tokenization is slow\n",
    "def inflate (row):\n",
    "    tokens = initial_tokenizer.tokenize(row['gloss_with_punct'])\n",
    "    return(pd.DataFrame({'token':tokens, 'id':row['id']}) )\n",
    "\n",
    "regenerate = True\n",
    "if regenerate:\n",
    "    all_tokens = pd.concat([inflate(x) for x in utt_glosses.to_dict('records')])\n",
    "    all_tokens = all_tokens.merge(utt_glosses)\n",
    "    all_tokens.to_csv('csv/pvd_utt_glosses_inflated.csv')\n",
    "\n",
    "else:\n",
    "    all_tokens = pd.read_csv('csv/pvd_utt_glosses_inflated.csv', na_filter=False)\n",
    "\n",
    "if verbose: print(all_tokens.iloc[0:10])\n",
    "\n",
    "# Assign a token_id (integer in the BERT vocabulary). \n",
    "# Because these are from the tokenized utterances, there is no correpsondence \n",
    "# with childes-db token ids\n",
    "all_tokens['token_id'] = initial_tokenizer.convert_tokens_to_ids(all_tokens['token'])\n",
    "# assigns utterances a 0-indexed index column\n",
    "all_tokens['seq_utt_id'] = all_tokens['id'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add back IPA, syllable structure, and child ages for child productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/frame.py:1554: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% complete...\n",
      "2.0% complete...\n",
      "3.0% complete...\n",
      "4.0% complete...\n",
      "5.0% complete...\n",
      "6.0% complete...\n",
      "7.0% complete...\n",
      "8.0% complete...\n",
      "9.0% complete...\n",
      "10.0% complete...\n",
      "11.0% complete...\n",
      "12.0% complete...\n",
      "13.0% complete...\n",
      "14.0% complete...\n",
      "15.0% complete...\n",
      "16.0% complete...\n",
      "17.0% complete...\n",
      "18.0% complete...\n",
      "19.0% complete...\n",
      "20.0% complete...\n",
      "21.0% complete...\n",
      "22.0% complete...\n",
      "23.0% complete...\n",
      "24.0% complete...\n",
      "25.0% complete...\n",
      "26.0% complete...\n",
      "27.0% complete...\n",
      "28.0% complete...\n",
      "29.0% complete...\n",
      "30.0% complete...\n",
      "31.0% complete...\n",
      "32.0% complete...\n",
      "33.0% complete...\n",
      "34.0% complete...\n",
      "35.0% complete...\n",
      "36.0% complete...\n",
      "37.0% complete...\n",
      "37.99% complete...\n",
      "38.99% complete...\n",
      "39.99% complete...\n",
      "40.99% complete...\n",
      "41.99% complete...\n",
      "42.99% complete...\n",
      "43.99% complete...\n",
      "44.99% complete...\n",
      "45.99% complete...\n",
      "46.99% complete...\n",
      "47.99% complete...\n",
      "48.99% complete...\n",
      "49.99% complete...\n",
      "50.99% complete...\n",
      "51.99% complete...\n",
      "52.99% complete...\n",
      "53.99% complete...\n",
      "54.99% complete...\n",
      "55.99% complete...\n",
      "56.99% complete...\n",
      "57.99% complete...\n",
      "58.99% complete...\n",
      "59.99% complete...\n",
      "60.99% complete...\n",
      "61.99% complete...\n",
      "62.99% complete...\n",
      "63.99% complete...\n",
      "64.99% complete...\n",
      "65.99% complete...\n",
      "66.99% complete...\n",
      "67.99% complete...\n",
      "68.99% complete...\n",
      "69.99% complete...\n",
      "70.99% complete...\n",
      "71.99% complete...\n",
      "72.99% complete...\n",
      "73.99% complete...\n",
      "74.99% complete...\n",
      "75.99% complete...\n",
      "76.99% complete...\n",
      "77.99% complete...\n",
      "78.99% complete...\n",
      "79.99% complete...\n",
      "80.99% complete...\n",
      "81.99% complete...\n",
      "82.99% complete...\n",
      "83.99% complete...\n",
      "84.99% complete...\n",
      "85.99% complete...\n",
      "86.99% complete...\n",
      "87.99% complete...\n",
      "88.99% complete...\n",
      "89.99% complete...\n",
      "90.99% complete...\n",
      "91.99% complete...\n",
      "92.99% complete...\n",
      "93.99% complete...\n",
      "94.99% complete...\n",
      "95.99% complete...\n",
      "96.99% complete...\n",
      "97.99% complete...\n",
      "98.99% complete...\n",
      "99.99% complete...\n"
     ]
    }
   ],
   "source": [
    "# get the token-level data, esp phonology\n",
    "\n",
    "if regenerate:\n",
    "\n",
    "    # get token-level information for Providence\n",
    "    pvd_chi_tokens = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, actual_phonology, model_phonology, transcript_id, utterance_id, \\\n",
    "    token_order from token where speaker_code = \"CHI\" and corpus_id = '+str(pvd_idx),\n",
    "        db_version = \"2020.1\")\n",
    "    pvd_chi_tokens['gloss'] = [data_cleaning.fix_gloss(x) for x in pvd_chi_tokens.gloss]\n",
    "    \n",
    "    # prep the tokens generated from segmenting the utterances\n",
    "    all_tokens_test = copy.deepcopy(all_tokens) \n",
    "\n",
    "    # initialize the fields that need to be populated\n",
    "    all_tokens_test['actual_phonology'] = ''\n",
    "    all_tokens_test['model_phonology'] = ''\n",
    "    all_tokens_test['target_child_age'] = np.nan\n",
    "    \n",
    "    # get a set of unique utterances\n",
    "    _, idx = np.unique(all_tokens_test.id, return_index=True)\n",
    "    all_utt_indices = all_tokens_test.id[np.sort(idx)]\n",
    "    \n",
    "    # For fast retrieval of IPA, split pvd_chi_tokens into a dictionary\n",
    "    pvd_chi_tokens_list = pvd_chi_tokens.groupby(['utterance_id'])\n",
    "    pvd_chi_tokens_dict = dict(zip(\n",
    "        [x[0] for x in pvd_chi_tokens_list], \n",
    "        [x[1] for x in pvd_chi_tokens_list], \n",
    "    ))\n",
    "    \n",
    "    # For fast retrival of BERT tokenization\n",
    "    all_tokens_test_list = all_tokens_test.groupby(['id'])\n",
    "    all_tokens_test_dict = dict(zip(\n",
    "        [x[0] for x in all_tokens_test_list], \n",
    "        [x[1] for x in all_tokens_test_list], \n",
    "    ))\n",
    "        \n",
    "    # Augment the tokens from all_tokens with the IPA from pvd_chi_tokens \n",
    "    rvs = [] \n",
    "    utts_to_retrieve = raw_yyy_utts.utterance_id.to_list() + raw_success_utts.utterance_id.to_list()\n",
    "    i=-1\n",
    "    for utt_index in all_utt_indices: #utts_to_retrieve: #[16760331]:       \n",
    "        i+=1\n",
    "        if i % int(len(all_utt_indices) / 100) == 0:\n",
    "            print(str(np.round((i / (len(all_utt_indices)) * 100),2))+'% complete...')    \n",
    "            # should learn to use tqdm instead\n",
    "        if utt_index in utts_to_retrieve:        \n",
    "            utt_df = copy.deepcopy(all_tokens_test_dict[utt_index])\n",
    "            utt_df['model_phonology'] = transfomers_bert_completions.augment_with_ipa(\n",
    "              utt_df, pvd_chi_tokens_dict[utt_index],initial_tokenizer, 'model_phonology')\n",
    "            utt_df['actual_phonology'] = transfomers_bert_completions.augment_with_ipa(\n",
    "              utt_df, pvd_chi_tokens_dict[utt_index],initial_tokenizer, 'actual_phonology')\n",
    "            utt_df['target_child_age'] = pvd_chi_tokens_dict[utt_index].iloc[0].target_child_age    \n",
    "            rvs.append(utt_df)  \n",
    "        else:\n",
    "            rvs.append(all_tokens_test_dict[utt_index])  \n",
    "            \n",
    "    # get the resulting augmented forms back into a dataframe\n",
    "    all_tokens_phono = pd.concat(rvs)\n",
    "    \n",
    "    # add a unique identifier to the BERT tokens\n",
    "    all_tokens_phono['bert_token_id'] = range(all_tokens_phono.shape[0])\n",
    "    \n",
    "    #save the results\n",
    "    all_tokens_phono.to_pickle('csv/pvd_utt_glosses_phono_inflated.pkl')\n",
    "else:\n",
    "    all_tokens_phono = pd.read_pickle('csv/pvd_utt_glosses_phono_inflated.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IPA map\n",
    "phone_map_df = pd.read_csv('phon/phon_map_populated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          token actual_phonology model_phonology\n",
      "42        mommy              ɑmɪ           mɑmiː\n",
      "81          yyy                ʌ               *\n",
      "170         wee              wiː             wiː\n",
      "173         yyy               aʊ               *\n",
      "201         wee              wiː             wiː\n",
      "...         ...              ...             ...\n",
      "3083588  nobody           nobɑɾi        noʊbɑdiː\n",
      "3083589   hates             heɪs           heɪts\n",
      "3083594      oh                o              oʊ\n",
      "3083595     why              waɪ             waɪ\n",
      "3083596    lick              liʔ             lɪk\n",
      "\n",
      "[254517 rows x 3 columns]\n",
      "  arpa ipa c_or_v\n",
      "0   AA   ɑ      v\n",
      "1   AE   æ      v\n",
      "2   AH   ə      v\n",
      "3   AO   ɔ      v\n",
      "4   AW  aʊ      v\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    # Inspect the IPA\n",
    "    print(all_tokens_phono.loc[all_tokens_phono.actual_phonology != ''][['token','actual_phonology','model_phonology']])\n",
    "    print(phone_map_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_remap(x):\n",
    "    return(x.replace(\"ː\",\"\").replace('ʌ','ə')\n",
    ".replace('ɪ','ə').replace('ɔ','ɑ').replace('a','ɑ').replace('o','oʊ').replace('˞','').replace('ʰ',\n",
    "    ''). replace('r','ɹ')).replace('\\\\^','').replace('\\\\ ̃','').replace(' ̩','').replace('^',''\n",
    ").replace('ʙ','b').replace('(','').replace(')','').replace('.','').replace('ch','ʧ'\n",
    ").replace('c','k').replace('g','ɡ').replace('y','j').replace('ʁ','ɹ')\n",
    "\n",
    "def strip_accents(string, accents=('COMBINING ACUTE ACCENT', \n",
    "    'COMBINING GRAVE ACCENT', 'COMBINING TILDE', 'COMBINING VERTICAL LINE BELOW',\n",
    "    'COMBINING SHORT STROKE OVERLAY')):\n",
    "    accents = set(map(unicodedata.lookup, accents))\n",
    "    chars = [c for c in unicodedata.normalize('NFD', string) if c not in accents]\n",
    "    return unicodedata.normalize('NFC', ''.join(chars))\n",
    "\n",
    "cv_map = dict(zip(phone_map_df['ipa'], phone_map_df['c_or_v']))\n",
    "cv_map['o'] = 'v' \n",
    "cv_map['ɜ'] = 'v'\n",
    "cv_map['e'] = 'v'\n",
    "cv_map['ʔ'] = 'c'\n",
    "cv_map['ɾ'] = 'c'\n",
    "cv_map['ɲ'] = 'c'\n",
    "cv_map['x'] = 'c'\n",
    "cv_map['ɱ'] = 'c'\n",
    "cv_map['ɣ'] = 'c'\n",
    "\n",
    "def cv_mapper(x, cv_map):\n",
    "    try:\n",
    "        return(cv_map[x])\n",
    "    except:\n",
    "        raise ValueError(x)\n",
    "\n",
    "regenerate = True\n",
    "if regenerate:    \n",
    "\n",
    "    # Do the same excludes as were used to identify appropriate utterances\n",
    "    excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "    all_tokens_phono.loc[all_tokens_phono.actual_phonology.isin(excludes),'actual_phonology'] =''\n",
    "    all_tokens_phono.loc[all_tokens_phono.actual_phonology.str.contains('V'),'actual_phonology'] =''\n",
    "    \n",
    "    # remap phonology from narrow phonetic transcription to broad phonological transcription\n",
    "    all_tokens_phono['model_phonology_clean'] = [phone_remap(x) for x in all_tokens_phono['model_phonology']]\n",
    "    all_tokens_phono['actual_phonology_clean'] = [phone_remap(x) for x in all_tokens_phono['actual_phonology']]\n",
    "\n",
    "    # remove any non-combining diacritical marks\n",
    "    all_tokens_phono['model_phonology_no_dia'] = [strip_accents(x) for x in \\\n",
    "    all_tokens_phono['model_phonology_clean']]\n",
    "    all_tokens_phono['actual_phonology_no_dia'] = [strip_accents(x) for x in \\\n",
    "    all_tokens_phono['actual_phonology_clean']]\n",
    "    \n",
    "    # Compute the number of non-contiguous vowels.\n",
    "    # slightly different than the cmu vowel computation ---\n",
    "    # because here we are computing it directly from IPA\n",
    "    all_tokens_phono['cv_raw'] = [''.join([cv_mapper(x, cv_map) for x in list(y)]) if y != '' else '' for y in all_tokens_phono['actual_phonology_no_dia']]    \n",
    "    all_tokens_phono['cv_collapsed']  = [re.sub(r'(.)\\1+', r'\\1', str(x)) if x != '' else '' for x in all_tokens_phono['cv_raw']]\n",
    "    all_tokens_phono['num_vowels'] = [np.sum(np.array(list(x)) == 'v') if x !='' else np.nan for x in all_tokens_phono['cv_collapsed']]\n",
    "    all_tokens_phono.to_pickle('csv/pvd_utt_glosses_phono_cleaned_inflated.pkl')\n",
    "else:\n",
    "    all_tokens_phono = pd.read_pickle('csv/pvd_utt_glosses_phono_cleaned_inflated.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42             ɑmə\n",
      "81               ə\n",
      "170             wi\n",
      "173             ɑʊ\n",
      "201             wi\n",
      "            ...   \n",
      "3083588    noʊbɑɾi\n",
      "3083589       heəs\n",
      "3083594         oʊ\n",
      "3083595        wɑə\n",
      "3083596        liʔ\n",
      "Name: actual_phonology_no_dia, Length: 254440, dtype: object\n",
      "(3083625, 24)\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    # Why no actual phonology?\n",
    "    print(all_tokens_phono.loc[all_tokens_phono.actual_phonology_no_dia != '']['actual_phonology_no_dia'])\n",
    "    print(all_tokens_phono.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the tokens that can be evaluated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_utt_ids = set(raw_success_utts['utterance_id']) \n",
    "initial_vocab_set = set(initial_vocab)\n",
    "yyy_utt_ids = set(raw_yyy_utts['utterance_id'])\n",
    "all_tokens_phono['in_vocab'] = all_tokens_phono['token'].isin(initial_vocab_set)\n",
    "all_tokens_phono['success_token'] = [x in successful_utt_ids for x in \n",
    "    all_tokens_phono['id']]\n",
    "all_tokens_phono['yyy_token'] = [x in yyy_utt_ids for x in \n",
    "    all_tokens_phono['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'b' 'c' ... 'hideout' 'pudding' 'stalks']\n",
      "(3083625, 27)\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    print(initial_vocab)\n",
    "    print(all_tokens_phono.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the subset of success and failure utterances that have transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono['partition'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188212, 28)\n",
      "         token        id               gloss  transcript_id  utterance_order  \\\n",
      "42       mommy  16759315               Mommy          42204                6   \n",
      "170        wee  16759467                 wee          42204               24   \n",
      "201        wee  16759501                 wee          42204               28   \n",
      "239        woo  16759549                 woo          42204               33   \n",
      "743      ernie  16759752               Ernie          42204               58   \n",
      "...        ...       ...                 ...            ...              ...   \n",
      "3083575   help  17280891                help          42569              752   \n",
      "3083589  hates  17280946  nobody hates Simba          42569              755   \n",
      "3083594     oh  17280964   oh why lick hippo          42569              756   \n",
      "3083595    why  17280964   oh why lick hippo          42569              756   \n",
      "3083596   lick  17280964   oh why lick hippo          42569              756   \n",
      "\n",
      "        speaker_code target_child_name  target_child_age               type  \\\n",
      "42               CHI              Alex          514.0000        declarative   \n",
      "170              CHI              Alex          514.0000        declarative   \n",
      "201              CHI              Alex          514.0000        declarative   \n",
      "239              CHI              Alex          514.0000        declarative   \n",
      "743              CHI              Alex          514.0000        declarative   \n",
      "...              ...               ...               ...                ...   \n",
      "3083575          CHI           William         1212.0625        declarative   \n",
      "3083589          CHI           William         1212.0625        declarative   \n",
      "3083594          CHI           William         1212.0625  self interruption   \n",
      "3083595          CHI           William         1212.0625  self interruption   \n",
      "3083596          CHI           William         1212.0625  self interruption   \n",
      "\n",
      "        punct  ... actual_phonology_clean model_phonology_no_dia  \\\n",
      "42          .  ...                    ɑmə                   mɑmi   \n",
      "170         .  ...                     wi                     wi   \n",
      "201         .  ...                     wi                     wi   \n",
      "239         .  ...                      u                     wu   \n",
      "743         .  ...                      ɛ                   əɹni   \n",
      "...       ...  ...                    ...                    ...   \n",
      "3083575     .  ...                    ɛlp                   hɛlp   \n",
      "3083589     .  ...                   heəs                  heəts   \n",
      "3083594     .  ...                     oʊ                    oʊʊ   \n",
      "3083595     .  ...                    wɑə                    wɑə   \n",
      "3083596     .  ...                    liʔ                    lək   \n",
      "\n",
      "         actual_phonology_no_dia  cv_raw cv_collapsed num_vowels  in_vocab  \\\n",
      "42                           ɑmə     vcv          vcv        2.0      True   \n",
      "170                           wi      cv           cv        1.0      True   \n",
      "201                           wi      cv           cv        1.0      True   \n",
      "239                            u       v            v        1.0      True   \n",
      "743                            ɛ       v            v        1.0      True   \n",
      "...                          ...     ...          ...        ...       ...   \n",
      "3083575                      ɛlp     vcc           vc        1.0      True   \n",
      "3083589                     heəs    cvvc          cvc        1.0      True   \n",
      "3083594                       oʊ      vv            v        1.0      True   \n",
      "3083595                      wɑə     cvv           cv        1.0      True   \n",
      "3083596                      liʔ     cvc          cvc        1.0      True   \n",
      "\n",
      "        success_token yyy_token partition  \n",
      "42               True     False   success  \n",
      "170              True     False   success  \n",
      "201              True     False   success  \n",
      "239              True     False   success  \n",
      "743              True     False   success  \n",
      "...               ...       ...       ...  \n",
      "3083575          True     False   success  \n",
      "3083589          True     False   success  \n",
      "3083594          True     False   success  \n",
      "3083595          True     False   success  \n",
      "3083596          True     False   success  \n",
      "\n",
      "[188212 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "success_tokens = all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2) ]\n",
    "all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2), 'partition'] = 'success'     \n",
    "\n",
    "if verbose:\n",
    "    print(success_tokens.shape)\n",
    "    print(all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_tokens = all_tokens_phono.loc[(all_tokens_phono['yyy_token']) & \n",
    "(all_tokens_phono['token'] == 'yyy') & (all_tokens_phono.num_vowels <= 2) ]\n",
    "all_tokens_phono.loc[(all_tokens_phono['yyy_token']) & \n",
    "(all_tokens_phono['token'] == 'yyy') & (all_tokens_phono.num_vowels <= 2),'partition'] = 'yyy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27693, 28)\n",
      "none       2867720\n",
      "success     188212\n",
      "yyy          27693\n",
      "Name: partition, dtype: int64\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    print(yyy_tokens.shape)\n",
    "    print(all_tokens_phono.partition.value_counts())\n",
    "    print(initial_tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional section from 6 | Prevalence of Successes and Failures Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to augment successes/failures with information on age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.data_cleaning' from '/home/nwong/chompsky/childes/child_listening_continuation/child-directed-listening/utils/data_cleaning.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'success_utts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-95d90c10e442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuccess_utts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'success_utts' is not defined"
     ]
    }
   ],
   "source": [
    "success_utts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get number of tokens per age\n",
    "# Warnings were present in the original code\n",
    "\n",
    "raw_success_utts['set'] = 'success'\n",
    "raw_yyy_utts['set'] = 'failure'\n",
    "\n",
    "utt_age = chi_phono.groupby('utterance_id').target_child_age.agg(np.unique).reset_index()\n",
    "\n",
    "# Additional attributes needed for the text split.\n",
    "utt_name = chi_phono.groupby('utterance_id').target_child_name.agg(np.unique).reset_index()\n",
    "utt_transcript = chi_phono.groupby('utterance_id').transcript_id.agg(np.unique).reset_index()\n",
    "\n",
    "#Generate the glosses per utterance id\n",
    "utt_gloss_save = data_cleaning.gloss_df_augmentation(chi_phono, raw_success_utts.utterance_id)\n",
    "\n",
    "inter_success_utts = raw_success_utts.copy()\n",
    "inter_yyy_utts = raw_yyy_utts.copy()\n",
    "\n",
    "for add_attr in [utt_age, utt_name, utt_transcript, utt_gloss_save]:\n",
    "    inter_success_utts = inter_success_utts.merge(add_attr, on = 'utterance_id')\n",
    "    inter_yyy_utts = inter_yyy_utts.merge(add_attr, on = 'utterance_id')\n",
    "    \n",
    "success_utts = inter_success_utts\n",
    "yyy_utts = inter_yyy_utts\n",
    "\n",
    "utts_with_ages = pd.concat([success_utts, yyy_utts]).merge(utt_age, on = 'utterance_id')\n",
    "\n",
    "assert len(set(utts_with_ages['utterance_id'])) == utts_with_ages.shape[0],\\\n",
    "\"Make sure that the utterance id is a unique identifier for the observations in the yyy and success dataframes\"\n",
    "assert len(set(utt_age['utterance_id'])) == utt_age.shape[0],\\\n",
    "\"Make sure that the utterance id is a unique identifier for the observations in the utt_age dataframe\"\n",
    "\n",
    "# Changed from the original: the merged dfs don't have the same order of utterance id immediately,\n",
    "# so am now merging on utterance id\n",
    "\n",
    "utts_with_ages['year'] = .5*np.floor(utts_with_ages['target_child_age'] / (365. /2) ) \n",
    "\n",
    "if verbose:\n",
    "    print(utts_with_ages.loc[utts_with_ages.set == 'failure'].year.value_counts())\n",
    "    print(utts_with_ages.loc[utts_with_ages.set == 'success'].year.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A cell that acts as a check for the utt_age, utt_name augumentations.\n",
    "\n",
    "# Check that every utterance_id is matched to its right age in yyy/success dataframe\n",
    "# This is a valid method because all of the utterance IDs are unique per dataframe.\n",
    "\n",
    "for i in range(utts_with_ages.shape[0]):\n",
    "    \n",
    "    if i % 10000 == 0: print(f'{(i / utts_with_ages.shape[0]) * 100.0}% complete')\n",
    "    this_entry = utts_with_ages.iloc[i]\n",
    "    this_id = this_entry['utterance_id']\n",
    "    \n",
    "    keys_to_check = ['target_child_age', 'target_child_name', 'transcript_id', 'gloss']\n",
    "    \n",
    "    cross_entry = chi_phono[chi_phono['utterance_id'] == this_id]\n",
    "    # Why is the cross value actually still a string?\n",
    "    # Where is it converted to non-string -- is there a way to convert it to non string?\n",
    "\n",
    "    for key in keys_to_check:\n",
    "        \n",
    "        this_value = this_entry[key]\n",
    "    \n",
    "        \n",
    "        if key == 'gloss' and ' ' in this_entry['gloss']:\n",
    "            # If this utterance is multiple tokens,\n",
    "            # you will have to match across multiple entries in chi_phono and join them to make the gloss.\n",
    "            # For example, idx = 5 using utts_with_ages indexing\n",
    "            \n",
    "            # what this checks for\n",
    "            # 1) you got the right pieces of the gloss\n",
    "            # 2) they are in the right token order\n",
    "            \n",
    "            formatted_cross = list(cross_entry[key])\n",
    "            \n",
    "            assert list(cross_entry['token_order']) == list(range(1, 1 + cross_entry.shape[0])),\\\n",
    "            \"Cross entry was not sliced in ascending token order, so gloss order of words is wrong.\"\n",
    "            \n",
    "            \n",
    "            assert this_value == ' '.join(formatted_cross), f'if, at index: {i}, key: {key}, real: {this_value}, cross: {formatted_cross}'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # The item to be matched is a single value or string.\n",
    "            # Applies to everything but the multiple token gloss.\n",
    "            # If the gloss of the utt_with_ages is multiple tokens,\n",
    "            # then it will still match to multiple locations in chi_phono tokens.\n",
    "            # However, because it's not the gloss attribute itself, the child attribute\n",
    "            # should be repeated across all of those entries.\n",
    "            \n",
    "            if cross_entry.shape[0] == 1:\n",
    "                cross_single_val = cross_entry[key].item()\n",
    "            else:\n",
    "                cross_set = list(set(cross_entry[key]))\n",
    "                assert len(cross_set) == 1\n",
    "                cross_single_val = cross_set[0]\n",
    "                \n",
    "            assert this_value == cross_single_val, f'else, at index: {i}, key: {key}, real: {this_value}, cross: {cross_entry[key]}'\n",
    "\n",
    "print('Asserts passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This marks the end of the section before the model evaluations/queries beginning.\n",
    "## It also marks the end of chi_phono generation -- do NOT re-run above or you will double-merge and lose the target_child_age attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_eval_data(data, filename, split_name, dataset_name, base_dir = 'eval/new_splits'):\n",
    "    \n",
    "    assert split_name in ['all', 'age', 'child'], \"Invalid split name. Must be one of {all, age, child}.\"\n",
    "    \n",
    "    # Saving based on a mask of a copy of a? Will this be a problem?\n",
    "    \n",
    "    save_path = split_gen.get_split_folder('all', 'all', base_dir)\n",
    "    save_location = join(save_path, filename)\n",
    "    data.to_pickle(save_location)\n",
    "    \n",
    "    print(f'Saved all/all evaluation data to {save_location}')\n",
    "    \n",
    "    return save_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phono_filename = 'pvd_utt_glosses_phono_cleaned_inflated.pkl'\n",
    "success_utts_filename = 'success_utts.csv'\n",
    "yyy_utts_filename = 'yyy_utts.csv'\n",
    "\n",
    "data_filenames = [phono_filename, success_utts_filename, yyy_utts_filename]\n",
    "\n",
    "# Use this line from the original code and load the above two CSVs for model inputs later:\n",
    "# utts_with_ages = pd.concat([success_utts, yyy_utts]).merge(utt_age)\n",
    "\n",
    "# for the input into the actual models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save evaluation data for all split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for this_data, filename in zip([all_tokens_phono, success_utts, yyy_utts], data_filenames):\n",
    "    save_eval_data(this_data, filename, 'all', 'all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save evaluation data for age split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "young_tokens_phono, old_tokens_phono = split_gen.get_age_split_data(all_tokens_phono, months = 36)\n",
    "young_success_utts, old_success_utts = split_gen.get_age_split_data(success_utts, months = 36)\n",
    "young_yyy_utts, old_yyy_utts = split_gen.get_age_split_data(yyy_utts, months = 36)\n",
    "\n",
    "for this_data, filename in zip([old_tokens_phono, old_success_utts, old_yyy_utts], data_filenames):\n",
    "    save_eval_data(this_data, filename, 'age', 'old')\n",
    "    \n",
    "for this_data, filename in zip([young_tokens_phono, young_success_utts, young_yyy_utts], data_filenames):\n",
    "    save_eval_data(this_data, filename, 'age', 'young') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process finetuning and evaluation data for child split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(split_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_child_pool.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you'll have to restart runtime/re-gen all of this on random seed\n",
    "\n",
    "# For now, define a success as any utterance without any yyy and xxx -- any such utterance can be used for training.\n",
    "# This is how it's defined in the implementation elsewhere in the other splits\n",
    "# -- although technically the token itself should also be monosyllabic?\n",
    "\n",
    "# Because type is not available in the first query,\n",
    "# just make all of the sentences end with a period for now.\n",
    "\n",
    "\n",
    "# Save the successes and yyy and write them to files for finetuning.\n",
    "success_child_pool = success_utts\n",
    "success_child_pool.type = [ 'declarative' for _ in range(success_utts.shape[0])]\n",
    "yyy_child_pool.type = [ 'declarative' for _ in range(yyy_utts.shape[0])]\n",
    "\n",
    "child_names = set(success_child_pool['target_child_name'])\n",
    "\n",
    "for name in child_names:\n",
    "    \n",
    "    child_success_utts = success_child_pool[success_child_pool['target_child_name'] == name]\n",
    "    child_yyy_utts = success_child_pool[success_yyy_pool['target_child_name'] == name]\n",
    "    child_tokens_phono = child_tokens_phono[child_tokens_phono['target_child_name'] == name]\n",
    "    \n",
    "    # Split the successes and prepare them for file writing.\n",
    "    this_partition_folder = split_gen.get_split_folder('child', name, base_dir = 'data/new_splits')\n",
    "    val_idxs = split_gen.glosses_random_split(child_success_utts, val_num = 200)\n",
    "    \n",
    "    # use None to match the processing of the other splits.\n",
    "    child_success_utts = data_cleaning.prep_utt_glosses(child_success_utts, None)\n",
    "    train_child_tokens_phono, val_child_tokens_phono, child_tokens_phono = split_gen.assign_phase_and_split(child_tokens_phono, val_idxs)\n",
    "    pooled_data, train_data, val_data = split_gen.write_data_partitions_text(child_success_utts, this_partition_folder, val_idxs)\n",
    "    # Note: Here, partition = success or not\n",
    "    # phase = train or validation (this was changed from the original)\n",
    "    \n",
    "    write_all_tokens_phono_partitions(this_partition_folder, train_child_tokens_phono, val_child_tokens_phono)\n",
    "    \n",
    "    # Disjoint check at data generation\n",
    "    # Check both utterance_id (per entry) and transcript id (my guess is this is higher in the hierarchy) are both disjoint.\n",
    "    # transcript_id because it's in the uniqueness call in the split code\n",
    "    \n",
    "    assert len(set(train_data.utterance_id) & set(val_data.utterance_id)) == 0, \"Train and validation data written was not disjoint.\"\n",
    "    assert len(set(train_data.transcript_id) & set(val_data.transcript_id)) == 0, \"Train and validation data written was not disjoint.\"\n",
    "    \n",
    "    pooled_data.to_csv(join(this_partition_folder, 'utts_pooled_data_with_phases.csv'))\n",
    "    child_tokens_phono.to_csv(join(this_partition_folder, 'tokens_phono_pooled_data_with_phases.csv'))\n",
    "    \n",
    "    print(name, child_success_utts.shape[0], 'number of examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name in child_names:\n",
    "    \n",
    "    child_yyy_utts = yyy_utts[yyy_utts['target_child_name'] == name]\n",
    "    child_tokens_phono = child_tokens_phono[child_tokens_phono['target_child_name'] == name]\n",
    "    \n",
    "    this_partition_folder = split_gen.get_split_folder('child', name, base_dir = 'data/new_splits')\n",
    "    val_idxs = split_gen.glosses_random_split(child_success_utts, val_num = 200)\n",
    "    \n",
    "    child_yyy_utts.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that validation indices for train and val match for each of the child datasets\n",
    "# across the save for all_tokens_phono and utt_df\n",
    "\n",
    "# How to check?\n",
    "# For every child, load its validation and train data\n",
    "# Then, load the pooled_data_with_phases\n",
    "# Check that the transcript ids are all properly put into their partitions\n",
    "\n",
    "# Need to test this (from above): assign child_tokens_phono the same validation/train split as the utterances\n",
    "# via the utterance id\n",
    "\n",
    "join(this_partition_folder, 'pooled_data_with_phases.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
