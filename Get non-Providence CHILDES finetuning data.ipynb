{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import childespy\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import config\n",
    "\n",
    "np.random.seed(config.SEED)\n",
    "\n",
    "# Important: Run this cell only once per \"restart runtime\"\n",
    "# for reproducibility of random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_gen, data_cleaning, load_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Train, Val for All and Age splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the North American and British English adult and child utterances without xxx or yyy\n",
    "#concatenate them at the the transcript level\n",
    "#hold out 20% for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>data_source</th>\n",
       "      <th>collection_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Valian</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Bernstein</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>Clark</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>PetersonMcCabe</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>221</td>\n",
       "      <td>Wells</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>222</td>\n",
       "      <td>Gathburn</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>223</td>\n",
       "      <td>Nuffield</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>224</td>\n",
       "      <td>Lara</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>225</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id            name collection_name data_source  collection_id\n",
       "1    32          Garvey          Eng-NA     CHILDES              2\n",
       "2    33          Valian          Eng-NA     CHILDES              2\n",
       "3    34       Bernstein          Eng-NA     CHILDES              2\n",
       "4    35           Clark          Eng-NA     CHILDES              2\n",
       "5    36  PetersonMcCabe          Eng-NA     CHILDES              2\n",
       "..  ...             ...             ...         ...            ...\n",
       "57  221           Wells          Eng-UK     CHILDES             12\n",
       "58  222        Gathburn          Eng-UK     CHILDES             12\n",
       "59  223        Nuffield          Eng-UK     CHILDES             12\n",
       "60  224            Lara          Eng-UK     CHILDES             12\n",
       "61  225         Belfast          Eng-UK     CHILDES             12\n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora = childespy.get_sql_query('select * from corpus where \\\n",
    "collection_name in (\"Eng-NA\", \"Eng-UK\") and data_source = \"CHILDES\"')\n",
    "corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "childes_datasets = \",\".join([str(x) for x in corpora.collection_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_path = join(config.finetune_dir, 'utt_glosses.pkl')\n",
    "\n",
    "if config.regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, target_child_name, corpus_name, target_child_age, type from utterance where collection_name in (\"Eng-NA\", \"Eng-UK\") \\\n",
    "    and collection_id in ('+childes_datasets+') and speaker_code in (\"MOT\", \"FAT\",\"CHI\")' , db_version = \"2020.1\")\n",
    "    utt_glosses.to_pickle(save_path)\n",
    "else: \n",
    "    utt_glosses = pd.read_pickle(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"all\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# expectations for verbose output.\n",
    "# 232 should be (4205071, 7) (because you added two extra fields)\n",
    "# 233 likewise is (3959952, 7)\n",
    "\n",
    "# Save the partition markings as well, for verification purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 7/26/21: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\n",
    "# for general function\n",
    "# 7/27/21: https://stackoverflow.com/questions/46096307/alias-for-column-in-pandas\n",
    "# for using columns keyword\n",
    "all_utt_glosses = utt_glosses.rename(columns = {'id' : 'utterance_id'}).copy()\n",
    "# end both cites\n",
    "\n",
    "this_split_folder = split_gen.get_split_folder('all', 'all', config.finetune_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changed to drop xxx and yyy for all of the splits.\n",
    "\n",
    "if config.verbose: print('Cell 232 output', all_utt_glosses.shape)\n",
    "\n",
    "# Cell 233 in the notebook relative to Dr Meylan's commit\n",
    "data = data_cleaning.drop_errors(all_utt_glosses)\n",
    "\n",
    "if config.verbose: print('Cell 233 output', data.shape)\n",
    "\n",
    "data = data_cleaning.clean_glosses(data)\n",
    "\n",
    "assert not any(['xxx' in s for s in set(data.gloss_with_punct)])\n",
    "assert not any(['yyy' in s for s in set(data.gloss_with_punct)])\n",
    "\n",
    "if config.verbose: print('Cell 269', data.head(5).gloss_with_punct)\n",
    "\n",
    "# Cell 271: This was moved outside of token cleaning because it's needed for the CHI analysis.\n",
    "data['tokens'] = [str(x).lower().split(' ') for x in data.gloss]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_glosses_df, train_df = split_gen.exec_split_gen(data, this_split_folder, 'val', phase_label = 'phase_finetune')\n",
    "\n",
    "chi_tok_freq = split_gen.save_chi_vocab(train_df, 'all', 'all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(split_glosses_df[split_glosses_df.transcript_id.isin(set(train_df.transcript_id))].phase_finetune) == {'train'}\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"age\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write age-based train/val data.\n",
    "\n",
    "young_df, old_df = split_gen.get_age_split_data(split_glosses_df.copy(), months = config.age_split)\n",
    "\n",
    "for args, which_df in zip([('age', 'old'), ('age', 'young')], [old_df, young_df]):\n",
    "    \n",
    "    split, dataset = args\n",
    "    this_split_folder = split_gen.get_split_folder(split, dataset, config.finetune_dir) \n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        \n",
    "        rel_data = which_df[which_df.phase_finetune == phase]\n",
    "        split_gen.write_partition(phase, rel_data, this_split_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
