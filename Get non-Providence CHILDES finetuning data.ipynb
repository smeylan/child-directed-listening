{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import childespy\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import config\n",
    "\n",
    "np.random.seed(config.SEED)\n",
    "\n",
    "# Important: Run this cell only once per \"restart runtime\"\n",
    "# for reproducibility of random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_gen, data_cleaning, load_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Train, Val for All and Age splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the North American and British English adult and child utterances without xxx or yyy\n",
    "#concatenate them at the the transcript level\n",
    "#hold out 20% for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>data_source</th>\n",
       "      <th>collection_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Valian</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Bernstein</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>Clark</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>PetersonMcCabe</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>221</td>\n",
       "      <td>Wells</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>222</td>\n",
       "      <td>Gathburn</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>223</td>\n",
       "      <td>Nuffield</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>224</td>\n",
       "      <td>Lara</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>225</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id            name collection_name data_source  collection_id\n",
       "1    32          Garvey          Eng-NA     CHILDES              2\n",
       "2    33          Valian          Eng-NA     CHILDES              2\n",
       "3    34       Bernstein          Eng-NA     CHILDES              2\n",
       "4    35           Clark          Eng-NA     CHILDES              2\n",
       "5    36  PetersonMcCabe          Eng-NA     CHILDES              2\n",
       "..  ...             ...             ...         ...            ...\n",
       "57  221           Wells          Eng-UK     CHILDES             12\n",
       "58  222        Gathburn          Eng-UK     CHILDES             12\n",
       "59  223        Nuffield          Eng-UK     CHILDES             12\n",
       "60  224            Lara          Eng-UK     CHILDES             12\n",
       "61  225         Belfast          Eng-UK     CHILDES             12\n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora = childespy.get_sql_query('select * from corpus where \\\n",
    "collection_name in (\"Eng-NA\", \"Eng-UK\") and data_source = \"CHILDES\"')\n",
    "corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "childes_datasets = \",\".join([str(x) for x in corpora.collection_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "regenerate = False\n",
    "if regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, target_child_name, corpus_name, target_child_age, type from utterance where collection_name in (\"Eng-NA\", \"Eng-UK\") \\\n",
    "    and collection_id in ('+childes_datasets+') and speaker_code in (\"MOT\", \"FAT\",\"CHI\")' , db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv('csv/utt_glosses.csv', index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv('csv/utt_glosses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gloss', 'transcript_id', 'id', 'utterance_order', 'speaker_code',\n",
       "       'target_child_name', 'corpus_name', 'target_child_age', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses = data_cleaning.drop_errors(utt_glosses) # Drop errors for age and all splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"all\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning split gen call: all all\n",
      "File written to data/new_splits/all/all/train.txt\n",
      "File written to data/new_splits/all/all/val.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_utt_glosses = utt_glosses.copy() # Important because split_gen functions often mutate, not copy.\n",
    "all_split_df, _, _ = split_gen.exec_split_gen(all_utt_glosses, 'all', 'all')\n",
    "\n",
    "# expectations for verbose output.\n",
    "# 232 should be (4205071, 7) (because you added two extra fields)\n",
    "# 233 likewise is (3959952, 7)\n",
    "\n",
    "# Save the partition markings as well, for verification purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_split_path = split_gen.get_split_folder('all', 'all', config.data_dir)\n",
    "all_split_df.to_pickle(join(this_split_path, 'data_pool_with_phases.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"age\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning split gen call: age young\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-directed-listening/utils/data_cleaning.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['gloss_with_punct'] = [x['speaker_code_simple'] + ' '+ x['gloss'].lower() + x['punct'] for x in data.to_dict('records')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to data/new_splits/age/young/train.txt\n",
      "File written to data/new_splits/age/young/val.txt\n",
      "Beginning split gen call: age old\n",
      "File written to data/new_splits/age/old/train.txt\n",
      "File written to data/new_splits/age/old/val.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "young_df, old_df = split_gen.get_age_split_data(utt_glosses.copy(), months = config.age_split)\n",
    "\n",
    "cleaned_young_split_df, young_tok, young_chi_tok = split_gen.exec_split_gen(young_df, 'age', 'young')\n",
    "cleaned_old_split_df, old_tok, old_chi_tok = split_gen.exec_split_gen(old_df, 'age', 'old')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, this_data in zip(['young', 'old'], [cleaned_young_split_df, cleaned_old_split_df]):\n",
    "    this_split_path = split_gen.get_split_folder('age', name, config.data_dir)\n",
    "    this_data.to_pickle(join(this_split_path, 'data_pool_with_phases.pkl'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write chi_token_freq dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_args = [('all', 'all'), ('age', 'young'), ('age', 'old')]\n",
    "\n",
    "for names in model_args:\n",
    "    \n",
    "    split, dataset = names\n",
    "    this_split_path = split_gen.get_split_folder(split, dataset, config.data_dir)\n",
    "    \n",
    "    this_pool = pd.read_pickle(join(this_split_path, 'data_pool_with_phases.pkl'))\n",
    "    this_pool_train = split_gen.find_phase_data('train', this_pool)\n",
    "    \n",
    "    res_freq = split_gen.save_chi_vocab(this_pool_train, split, dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional checks to consider writing -- no xxx, yyy in the resulting pools/text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (need to revisit these, maybe -- or verify otherwise) Verifications: Quick checks for consistency with the full notebook (on \"all\" split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you refer to a partition as a phase to avoid confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The fix gloss should now match?\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "retrieve_path = split_gen.get_split_folder('all', 'all', base_path)\n",
    "tok = load_csvs.load_csv_with_lists(join(retrieve_path, 'vocab.csv'))\n",
    "chi_tok = load_csvs.load_csv_with_lists(join(retrieve_path, 'chi_vocab.csv'))\n",
    "\n",
    "\n",
    "orig_tok = load_csvs.load_csv_with_lists('data/vocab.csv') # Saved by the original notebook in your run.\n",
    "orig_chi_tok = load_csvs.load_csv_with_lists('data/chi_vocab.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nan_filler = 'is_an_nan_need_to_fill'\n",
    "orig_tok_sorted = orig_tok.sort_values('word').reset_index(drop = True).fillna(nan_filler)\n",
    "tok_sorted = tok.sort_values('word').reset_index(drop = True).fillna(nan_filler)\n",
    "\n",
    "orig_tok_sorted.equals(tok_sorted)\n",
    "\n",
    "orig_tok_sorted.head()\n",
    "\n",
    "assert all(orig_tok_sorted['word'] == tok_sorted['word'])\n",
    "assert all(orig_tok_sorted['count'] == tok_sorted['count'])\n",
    "\n",
    "# Note that if you compare the dataframes directly, like:\n",
    "# print(orig_tok_sorted[orig_tok_sorted != tok_sorted])\n",
    "# print(tok_sorted[orig_tok_sorted != tok_sorted])\n",
    "# This is not going to work because of the Unnamed: 0 column. But the actual contents are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking if the dataframes are the same after the first cleaning\n",
    "\n",
    "base_path = 'refactored'\n",
    "\n",
    "my_out = load_csvs.load_csv_with_lists(join(base_path, 'cleaned_utt_glosses_my.csv'))\n",
    "his_out = load_csvs.load_csv_with_lists('data/cleaned_utt_glosses_meylan.csv')\n",
    "\n",
    "my_out.sort_values('id')\n",
    "his_out.sort_values('id')\n",
    "\n",
    "filler = 'fill_this_nan______'\n",
    "\n",
    "my_out = my_out.fillna(filler)\n",
    "his_out = his_out.fillna(filler)\n",
    "\n",
    "for field in my_out.columns:\n",
    "    if field not in his_out.columns: continue\n",
    "    if not all(my_out[field] == his_out[field]):\n",
    "        print(field)\n",
    "        print(my_out[my_out[field] != his_out[field]])\n",
    "        break\n",
    "        \n",
    "    # Seems like they are actually the same\n",
    "    # So long as \"NaN\" glosses are filled with some value to be equivalent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
