{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import childespy\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "np.random.seed(0)\n",
    "\n",
    "# Important: Run this cell only once per \"restart runtime\"\n",
    "# for reproducibility of random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## General description of splits (this notebook addresses the \"all\" and \"age\" splits)\n",
    " \n",
    " **All split**\n",
    "    \n",
    "- The normal train and validation from the original query on CHILDES in \"Generate data to fine-tune\" notebook.\n",
    "- Train, Val chosen 80/20 randomly using unique transcript IDs only.\n",
    "- Doesn't have xxx or yyy.\n",
    "\n",
    "**Age split**\n",
    "\n",
    "- Split on <=36 months for young, and rest for old.\n",
    "- Do all split process.\n",
    "- Doesn't have xxx or yyy.\n",
    "\n",
    "**Child split**\n",
    "- Split on 6 children as found in Generate Phonological Analysis. See notebook \"Generate child data for finetuning\".\n",
    "- Has 200 yyy for validation, randomly select from UNIQUE TRANSCRIPT IDS ONLY. The rest is train.\n",
    "- Doesn't have xxx or yyy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Train, Val for All and Age splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the North American and British English adult and child utterances without xxx or yyy\n",
    "#concatenate them at the the transcript level\n",
    "#hold out 20% for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>data_source</th>\n",
       "      <th>collection_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Valian</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Bernstein</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>Clark</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>PetersonMcCabe</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>221</td>\n",
       "      <td>Wells</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>222</td>\n",
       "      <td>Gathburn</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>223</td>\n",
       "      <td>Nuffield</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>224</td>\n",
       "      <td>Lara</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>225</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>Eng-UK</td>\n",
       "      <td>CHILDES</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id            name collection_name data_source  collection_id\n",
       "1    32          Garvey          Eng-NA     CHILDES              2\n",
       "2    33          Valian          Eng-NA     CHILDES              2\n",
       "3    34       Bernstein          Eng-NA     CHILDES              2\n",
       "4    35           Clark          Eng-NA     CHILDES              2\n",
       "5    36  PetersonMcCabe          Eng-NA     CHILDES              2\n",
       "..  ...             ...             ...         ...            ...\n",
       "57  221           Wells          Eng-UK     CHILDES             12\n",
       "58  222        Gathburn          Eng-UK     CHILDES             12\n",
       "59  223        Nuffield          Eng-UK     CHILDES             12\n",
       "60  224            Lara          Eng-UK     CHILDES             12\n",
       "61  225         Belfast          Eng-UK     CHILDES             12\n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora = childespy.get_sql_query('select * from corpus where \\\n",
    "collection_name in (\"Eng-NA\", \"Eng-UK\") and data_source = \"CHILDES\"')\n",
    "corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "childes_datasets = \",\".join([str(x) for x in corpora.collection_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regenerate = True\n",
    "if regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, target_child_name, corpus_name, target_child_age, type from utterance where collection_name in (\"Eng-NA\", \"Eng-UK\") \\\n",
    "    and collection_id in ('+childes_datasets+') and speaker_code in (\"MOT\", \"FAT\",\"CHI\")' , db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv('csv/utt_glosses.csv', index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv('csv/utt_glosses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses = split_gen.drop_errors(utt_glosses) # Drop errors for age and all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>target_child_age</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now we need this</td>\n",
       "      <td>3261</td>\n",
       "      <td>279663</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>None</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trail off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we need we you don't</td>\n",
       "      <td>3261</td>\n",
       "      <td>279666</td>\n",
       "      <td>2</td>\n",
       "      <td>CHI</td>\n",
       "      <td>None</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need a pocketbook because I'm the mother</td>\n",
       "      <td>3261</td>\n",
       "      <td>279668</td>\n",
       "      <td>3</td>\n",
       "      <td>CHI</td>\n",
       "      <td>None</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm I'm the</td>\n",
       "      <td>3261</td>\n",
       "      <td>279670</td>\n",
       "      <td>5</td>\n",
       "      <td>CHI</td>\n",
       "      <td>None</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trail off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it won't work xxx</td>\n",
       "      <td>3261</td>\n",
       "      <td>279671</td>\n",
       "      <td>6</td>\n",
       "      <td>CHI</td>\n",
       "      <td>None</td>\n",
       "      <td>Garvey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      gloss  transcript_id      id  \\\n",
       "1                          now we need this           3261  279663   \n",
       "2                      we need we you don't           3261  279666   \n",
       "3  need a pocketbook because I'm the mother           3261  279668   \n",
       "4                               I'm I'm the           3261  279670   \n",
       "5                         it won't work xxx           3261  279671   \n",
       "\n",
       "   utterance_order speaker_code target_child_name corpus_name  \\\n",
       "1                1          CHI              None      Garvey   \n",
       "2                2          CHI              None      Garvey   \n",
       "3                3          CHI              None      Garvey   \n",
       "4                5          CHI              None      Garvey   \n",
       "5                6          CHI              None      Garvey   \n",
       "\n",
       "   target_child_age         type  \n",
       "1               NaN    trail off  \n",
       "2               NaN  declarative  \n",
       "3               NaN  declarative  \n",
       "4               NaN    trail off  \n",
       "5               NaN  declarative  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"all\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning split gen call: all all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-directed-listening/utils/split_gen.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['gloss_with_punct'] = [x['speaker_code_simple'] + ' '+ x['gloss'].lower() + x['punct'] for x in data.to_dict('records')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files written to data/new_splits/all/all\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_path = 'data/new_splits'\n",
    "\n",
    "all_utt_glosses = utt_glosses.copy() # Important because split_gen functions often mutate, not copy.\n",
    "all_split_df, _, _ = split_gen.exec_split_gen(all_utt_glosses, 'all', 'all', base_dir = base_path)\n",
    "\n",
    "# expectations for verbose output.\n",
    "# 232 should be (4205071, 7) (because you added two extra fields)\n",
    "# 233 likewise is (3959952, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"age\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning split gen call: age young\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-directed-listening/utils/split_gen.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['gloss_with_punct'] = [x['speaker_code_simple'] + ' '+ x['gloss'].lower() + x['punct'] for x in data.to_dict('records')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files written to data/new_splits/age/young\n",
      "Beginning split gen call: age old\n",
      "Files written to data/new_splits/age/old\n"
     ]
    }
   ],
   "source": [
    "young_df, old_df = split_gen.get_age_split_data(months = 36)\n",
    "\n",
    "cleaned_young_split_df, young_tok, young_chi_tok = split_gen.exec_split_gen(young_df, 'age', 'young', base_dir = base_path)\n",
    "cleaned_old_split_df, old_tok, old_chi_tok = split_gen.exec_split_gen(old_df, 'age', 'old', base_dir = base_path)\n",
    "\n",
    "# The young and old need to be overwritten -- how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifications: Quick checks for consistency with the full notebook (on \"all\" split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you refer to a partition as a phase to avoid confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The fix gloss should now match?\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "retrieve_path = split_gen.get_split_folder('all', 'all', base_path)\n",
    "tok = pd.read_csv(join(retrieve_path, 'vocab.csv'))\n",
    "chi_tok = pd.read_csv(join(retrieve_path, 'chi_vocab.csv'))\n",
    "\n",
    "\n",
    "orig_tok = pd.read_csv('data/vocab.csv') # Saved by the original notebook in your run.\n",
    "orig_chi_tok = pd.read_csv('data/chi_vocab.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nan_filler = 'is_an_nan_need_to_fill'\n",
    "orig_tok_sorted = orig_tok.sort_values('word').reset_index(drop = True).fillna(nan_filler)\n",
    "tok_sorted = tok.sort_values('word').reset_index(drop = True).fillna(nan_filler)\n",
    "\n",
    "orig_tok_sorted.equals(tok_sorted)\n",
    "\n",
    "orig_tok_sorted.head()\n",
    "\n",
    "assert all(orig_tok_sorted['word'] == tok_sorted['word'])\n",
    "assert all(orig_tok_sorted['count'] == tok_sorted['count'])\n",
    "\n",
    "# Note that if you compare the dataframes directly, like:\n",
    "# print(orig_tok_sorted[orig_tok_sorted != tok_sorted])\n",
    "# print(tok_sorted[orig_tok_sorted != tok_sorted])\n",
    "# This is not going to work because of the Unnamed: 0 column. But the actual contents are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking if the dataframes are the same after the first cleaning\n",
    "\n",
    "base_path = 'refactored'\n",
    "\n",
    "my_out = pd.read_csv(join(base_path, 'cleaned_utt_glosses_my.csv'))\n",
    "his_out = pd.read_csv('data/cleaned_utt_glosses_meylan.csv')\n",
    "\n",
    "my_out.sort_values('id')\n",
    "his_out.sort_values('id')\n",
    "\n",
    "filler = 'fill_this_nan______'\n",
    "\n",
    "my_out = my_out.fillna(filler)\n",
    "his_out = his_out.fillna(filler)\n",
    "\n",
    "for field in my_out.columns:\n",
    "    if field not in his_out.columns: continue\n",
    "    if not all(my_out[field] == his_out[field]):\n",
    "        print(field)\n",
    "        print(my_out[my_out[field] != his_out[field]])\n",
    "        break\n",
    "        \n",
    "    # Seems like they are actually the same\n",
    "    # So long as \"NaN\" glosses are filled with some value to be equivalent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
