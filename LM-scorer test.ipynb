{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import sys\n",
    "import ipywidgets\n",
    "import imp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import googletrans\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multilingual_scorer import MultilingualScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mls = MultilingualScorer(cache_dir=\"/shared_hd2/huggingface/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mls.score('We zullen met ze praten.', 'nl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mls.score('We wil talk to them.', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_probs(target_sentence):\n",
    "    scores = []\n",
    "    for language in ['de', 'nl','fr', 'en']:\n",
    "        if language == 'en':\n",
    "            translated_text = target_sentence\n",
    "            en_score = mls.score(translated_text, language)\n",
    "        else:\n",
    "            translated_text = translator.translate(target_sentence, dest=language, src='en').text\n",
    "        score = mls.score(translated_text, language)    \n",
    "        scores.append({'language':language,\n",
    "         'translation': translated_text,\n",
    "        'score': score[0].numpy(),        \n",
    "        'source_text': target_sentence})\n",
    "    \n",
    "    rdf = pd.DataFrame(scores)\n",
    "    rdf['en_score'] = en_score[0].numpy().astype('float')\n",
    "    return(rdf)\n",
    "\n",
    "get_translation_probs(\"What is that?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'We will talk to them.',\n",
    "    'What is that?',\n",
    "    \"Please don't do that.\",\n",
    "    \"Where is the dog?\",\n",
    "    \"That's a bad idea.\",\n",
    "    \"Bring that over here.\",\n",
    "    \"Come back over here.\",\n",
    "    \"Look at all the stars!\",\n",
    "    \"It's time to go to bed.\",\n",
    "    \"Give me the cookie.\",\n",
    "    'How do you know?',\n",
    "    \"I'm going to the store\",\n",
    "    'The dog chased the cat.',\n",
    "    'The cat chased the dog.',\n",
    "    \"I spilled the milk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_probs = pd.concat([get_translation_probs(x) for x in sentences]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_probs.score = sentence_probs.score.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -i sentence_probs\n",
    "sentence_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "sprobs = aggregate(en_score ~ source_text, sentence_probs, mean)\n",
    "sprobs = sprobs[order(sprobs$en_score),]\n",
    "\n",
    "sentence_probs$source_text = factor(sentence_probs$source_text, levels = sprobs$source_text)\n",
    "\n",
    "ggplot(sentence_probs) + geom_point(aes(x=source_text, y=-1*score, color=language, shape=language)\n",
    ", size=6 ) + theme_classic() + theme(axis.text.x = element_text(angle = 45, vjust = 0.5)\n",
    ") + xlab('Target Sentence (English translation)') + ylab('Log Probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare probability of Grammatical and ungrammatical variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mls.score('The cats are on the bed.', 'en'))\n",
    "print(mls.score('The cat are on the bed.', 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mls.score('Two little kitty cats.', 'en'))\n",
    "print(mls.score('Two little kitty cat.', 'en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/lib/python3.7/site-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/home/stephan/python/mlm-scoring/src/')\n",
    "from mlm.scorers import MLMScorer, MLMScorerPT, LMScorer\n",
    "from mlm.models import get_pretrained\n",
    "import mxnet as mx\n",
    "ctxs = [mx.cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocab, tokenizer = get_pretrained(ctxs, 'bert-base-en-cased')\n",
    "scorer = MLMScorer(model, vocab, tokenizer, ctxs)\n",
    "print(scorer.score_sentences([\"Hello world!\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer.score_sentences([\"There are two cat.\", \"There are two cats.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"There are two cat.\",\n",
    "        \"There are two cats.\",\n",
    "        \"Los dos perros son feos.\",\n",
    "        \"Los dos perro son feos.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlm.models\n",
    "mlm.models.SUPPORTED_MLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer.score_sentences(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_probs_mlm(target_sentence, scorer, lower=False):\n",
    "    scores = []\n",
    "    for language in ['de', 'nl','fr', 'en']:\n",
    "        if language == 'en':\n",
    "            translated_text = target_sentence\n",
    "            en_score = scorer.score_sentences([translated_text])[0]\n",
    "        else:\n",
    "            translated_text = translator.translate(target_sentence, dest=language, src='en').text\n",
    "        if lower:\n",
    "            translated_text = translated_text.lower()\n",
    "        score = scorer.score_sentences([translated_text])[0]    \n",
    "        scores.append({'language':language,\n",
    "         'translation': translated_text,\n",
    "        'score': score,\n",
    "        'source_text': target_sentence})\n",
    "    \n",
    "    rdf = pd.DataFrame(scores)\n",
    "    rdf['en_score'] = en_score\n",
    "    return(rdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower Case Multilingual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocab, tokenizer = get_pretrained(ctxs, 'bert-base-multi-uncased')\n",
    "scorer = MLMScorer(model, vocab, tokenizer, ctxs)\n",
    "print(scorer.score_sentences([\"hello world!\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case_sentence_probs = pd.concat([get_translation_probs_mlm(x, scorer, lower=True) for x in sentences]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -i lower_case_sentence_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "lower_sprobs = aggregate(en_score ~ source_text, lower_case_sentence_probs, mean)\n",
    "lower_sprobs = lower_sprobs[order(lower_sprobs$en_score),]\n",
    "lower_case_sentence_probs$source_text = factor(sentence_probs$source_text, levels = lower_sprobs$source_text)\n",
    "\n",
    "ggplot(lower_case_sentence_probs) + geom_point(aes(x=source_text, y=score, color=language, shape=language)\n",
    ", size=6 ) + theme_classic() + theme(axis.text.x = element_text(angle = 45, hjust=1,\n",
    "vjust = 1)) + xlab('Target Sentence (English translation)') + ylab('Log Probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper Case Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocab, tokenizer = get_pretrained(ctxs, 'bert-base-multi-cased')\n",
    "scorer = MLMScorer(model, vocab, tokenizer, ctxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_sentence_probs = pd.concat([get_translation_probs_mlm(x, scorer) for x in sentences]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -i upper_sentence_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "upper_sprobs = aggregate(en_score ~ source_text, upper_sentence_probs, mean)\n",
    "upper_sprobs = upper_sprobs[order(upper_sprobs$en_score),]\n",
    "upper_sentence_probs$source_text = factor(upper_sentence_probs$source_text, levels = upper_sprobs$source_text)\n",
    "\n",
    "ggplot(upper_sentence_probs) + geom_point(aes(x=source_text, y=score, color=language, shape=language)\n",
    ", size=6 ) + theme_classic() + theme(axis.text.x = element_text(angle = 45, hjust=1,\n",
    "vjust = 1)) + xlab('Target Sentence (English translation)') + ylab('Log Probability')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-directed-listening",
   "language": "python",
   "name": "child-directed-listening"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
