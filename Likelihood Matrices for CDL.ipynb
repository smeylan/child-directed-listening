{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that this should be run with the \"openfst\" kernel to allow us to open the correct python bindings for openfst,\n",
    "# pywrapfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import Levenshtein\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return(pickle.load(file))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
    "from utils import wfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono = load_pickle('likelihood_inputs/all_tokens_phono.obj')\n",
    "cmu_in_initial_vocab = load_pickle('likelihood_inputs/cmu_in_initial_vocab_with_duplicates.obj')\n",
    "# note that cmu_in_initial_vocab was updated to reflect additional records\n",
    "initial_vocab = load_pickle('likelihood_inputs/initial_vocab.obj')\n",
    "priors_for_age_interval = load_pickle('likelihood_inputs/priors_for_age_interval.obj')\n",
    "\n",
    "initial_vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>phones</th>\n",
       "      <th>ipa</th>\n",
       "      <th>ipa_short</th>\n",
       "      <th>structure</th>\n",
       "      <th>num_vowels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>a</td>\n",
       "      <td>AH0</td>\n",
       "      <td>[AH]</td>\n",
       "      <td>[ə]</td>\n",
       "      <td>ə</td>\n",
       "      <td>[v]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>a</td>\n",
       "      <td>EY1</td>\n",
       "      <td>[EY]</td>\n",
       "      <td>[eə]</td>\n",
       "      <td>eə</td>\n",
       "      <td>[v]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>aa</td>\n",
       "      <td>EY2 EY1</td>\n",
       "      <td>[EY, EY]</td>\n",
       "      <td>[eə, eə]</td>\n",
       "      <td>eəeə</td>\n",
       "      <td>[v, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>aaron</td>\n",
       "      <td>EH1 R AH0 N</td>\n",
       "      <td>[EH, R, AH, N]</td>\n",
       "      <td>[ɛ, ɹ, ə, n]</td>\n",
       "      <td>ɛɹən</td>\n",
       "      <td>[v, c, v, c]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ab</td>\n",
       "      <td>AE1 B</td>\n",
       "      <td>[AE, B]</td>\n",
       "      <td>[æ, b]</td>\n",
       "      <td>æb</td>\n",
       "      <td>[v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133666</th>\n",
       "      <td>zombie</td>\n",
       "      <td>Z AA1 M B IY0</td>\n",
       "      <td>[Z, AA, M, B, IY]</td>\n",
       "      <td>[z, ɑ, m, b, i]</td>\n",
       "      <td>zɑmbi</td>\n",
       "      <td>[c, v, c, c, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133671</th>\n",
       "      <td>zone</td>\n",
       "      <td>Z OW1 N</td>\n",
       "      <td>[Z, OW, N]</td>\n",
       "      <td>[z, oʊʊ, n]</td>\n",
       "      <td>zoʊʊn</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133676</th>\n",
       "      <td>zoo</td>\n",
       "      <td>Z UW1</td>\n",
       "      <td>[Z, UW]</td>\n",
       "      <td>[z, u]</td>\n",
       "      <td>zu</td>\n",
       "      <td>[c, v]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133683</th>\n",
       "      <td>zoom</td>\n",
       "      <td>Z UW1 M</td>\n",
       "      <td>[Z, UW, M]</td>\n",
       "      <td>[z, u, m]</td>\n",
       "      <td>zum</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133775</th>\n",
       "      <td>zulu</td>\n",
       "      <td>Z UW1 L UW2</td>\n",
       "      <td>[Z, UW, L, UW]</td>\n",
       "      <td>[z, u, l, u]</td>\n",
       "      <td>zulu</td>\n",
       "      <td>[c, v, c, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8869 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  pronunciation             phones              ipa ipa_short  \\\n",
       "70           a            AH0               [AH]              [ə]         ə   \n",
       "71           a            EY1               [EY]             [eə]        eə   \n",
       "77          aa        EY2 EY1           [EY, EY]         [eə, eə]      eəeə   \n",
       "92       aaron    EH1 R AH0 N     [EH, R, AH, N]     [ɛ, ɹ, ə, n]      ɛɹən   \n",
       "102         ab          AE1 B            [AE, B]           [æ, b]        æb   \n",
       "...        ...            ...                ...              ...       ...   \n",
       "133666  zombie  Z AA1 M B IY0  [Z, AA, M, B, IY]  [z, ɑ, m, b, i]     zɑmbi   \n",
       "133671    zone        Z OW1 N         [Z, OW, N]      [z, oʊʊ, n]     zoʊʊn   \n",
       "133676     zoo          Z UW1            [Z, UW]           [z, u]        zu   \n",
       "133683    zoom        Z UW1 M         [Z, UW, M]        [z, u, m]       zum   \n",
       "133775    zulu    Z UW1 L UW2     [Z, UW, L, UW]     [z, u, l, u]      zulu   \n",
       "\n",
       "              structure num_vowels  \n",
       "70                  [v]          1  \n",
       "71                  [v]          1  \n",
       "77               [v, v]          2  \n",
       "92         [v, c, v, c]          2  \n",
       "102              [v, c]          1  \n",
       "...                 ...        ...  \n",
       "133666  [c, v, c, c, v]          2  \n",
       "133671        [c, v, c]          1  \n",
       "133676           [c, v]          1  \n",
       "133683        [c, v, c]          1  \n",
       "133775     [c, v, c, v]          2  \n",
       "\n",
       "[8869 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_initial_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>phones</th>\n",
       "      <th>ipa</th>\n",
       "      <th>ipa_short</th>\n",
       "      <th>structure</th>\n",
       "      <th>num_vowels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97825</th>\n",
       "      <td>read</td>\n",
       "      <td>R EH1 D</td>\n",
       "      <td>[R, EH, D]</td>\n",
       "      <td>[ɹ, ɛ, d]</td>\n",
       "      <td>ɹɛd</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97826</th>\n",
       "      <td>read</td>\n",
       "      <td>R IY1 D</td>\n",
       "      <td>[R, IY, D]</td>\n",
       "      <td>[ɹ, i, d]</td>\n",
       "      <td>ɹid</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word pronunciation      phones        ipa ipa_short  structure  \\\n",
       "97825  read       R EH1 D  [R, EH, D]  [ɹ, ɛ, d]       ɹɛd  [c, v, c]   \n",
       "97826  read       R IY1 D  [R, IY, D]  [ɹ, i, d]       ɹid  [c, v, c]   \n",
       "\n",
       "      num_vowels  \n",
       "97825          1  \n",
       "97826          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_initial_vocab.loc[cmu_in_initial_vocab.word == 'read']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>phones</th>\n",
       "      <th>ipa</th>\n",
       "      <th>ipa_short</th>\n",
       "      <th>structure</th>\n",
       "      <th>num_vowels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>a</td>\n",
       "      <td>AH0</td>\n",
       "      <td>[AH]</td>\n",
       "      <td>[ə]</td>\n",
       "      <td>ə</td>\n",
       "      <td>[v]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>aa</td>\n",
       "      <td>EY2 EY1</td>\n",
       "      <td>[EY, EY]</td>\n",
       "      <td>[eɪ, eɪ]</td>\n",
       "      <td>eəeə</td>\n",
       "      <td>[v, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93</td>\n",
       "      <td>aaron</td>\n",
       "      <td>EH1 R AH0 N</td>\n",
       "      <td>[EH, R, AH, N]</td>\n",
       "      <td>[ɛ, ɹ, ə, n]</td>\n",
       "      <td>ɛɹən</td>\n",
       "      <td>[v, c, v, c]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>103</td>\n",
       "      <td>ab</td>\n",
       "      <td>AE1 B</td>\n",
       "      <td>[AE, B]</td>\n",
       "      <td>[æ, b]</td>\n",
       "      <td>æb</td>\n",
       "      <td>[v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150</td>\n",
       "      <td>abbey</td>\n",
       "      <td>AE1 B IY0</td>\n",
       "      <td>[AE, B, IY]</td>\n",
       "      <td>[æ, b, i]</td>\n",
       "      <td>æbi</td>\n",
       "      <td>[v, c, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12546</th>\n",
       "      <td>133667</td>\n",
       "      <td>zombie</td>\n",
       "      <td>Z AA1 M B IY0</td>\n",
       "      <td>[Z, AA, M, B, IY]</td>\n",
       "      <td>[z, ɑ, m, b, i]</td>\n",
       "      <td>zɑmbi</td>\n",
       "      <td>[c, v, c, c, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12547</th>\n",
       "      <td>133672</td>\n",
       "      <td>zone</td>\n",
       "      <td>Z OW1 N</td>\n",
       "      <td>[Z, OW, N]</td>\n",
       "      <td>[z, oʊ, n]</td>\n",
       "      <td>zoʊʊn</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12548</th>\n",
       "      <td>133677</td>\n",
       "      <td>zoo</td>\n",
       "      <td>Z UW1</td>\n",
       "      <td>[Z, UW]</td>\n",
       "      <td>[z, u]</td>\n",
       "      <td>zu</td>\n",
       "      <td>[c, v]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12549</th>\n",
       "      <td>133684</td>\n",
       "      <td>zoom</td>\n",
       "      <td>Z UW1 M</td>\n",
       "      <td>[Z, UW, M]</td>\n",
       "      <td>[z, u, m]</td>\n",
       "      <td>zum</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12556</th>\n",
       "      <td>133776</td>\n",
       "      <td>zulu</td>\n",
       "      <td>Z UW1 L UW2</td>\n",
       "      <td>[Z, UW, L, UW]</td>\n",
       "      <td>[z, u, l, u]</td>\n",
       "      <td>zulu</td>\n",
       "      <td>[c, v, c, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7904 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index    word  pronunciation             phones              ipa  \\\n",
       "0          71       a            AH0               [AH]              [ə]   \n",
       "1          78      aa        EY2 EY1           [EY, EY]         [eɪ, eɪ]   \n",
       "5          93   aaron    EH1 R AH0 N     [EH, R, AH, N]     [ɛ, ɹ, ə, n]   \n",
       "7         103      ab          AE1 B            [AE, B]           [æ, b]   \n",
       "9         150   abbey      AE1 B IY0        [AE, B, IY]        [æ, b, i]   \n",
       "...       ...     ...            ...                ...              ...   \n",
       "12546  133667  zombie  Z AA1 M B IY0  [Z, AA, M, B, IY]  [z, ɑ, m, b, i]   \n",
       "12547  133672    zone        Z OW1 N         [Z, OW, N]       [z, oʊ, n]   \n",
       "12548  133677     zoo          Z UW1            [Z, UW]           [z, u]   \n",
       "12549  133684    zoom        Z UW1 M         [Z, UW, M]        [z, u, m]   \n",
       "12556  133776    zulu    Z UW1 L UW2     [Z, UW, L, UW]     [z, u, l, u]   \n",
       "\n",
       "      ipa_short        structure  num_vowels  \n",
       "0             ə              [v]           1  \n",
       "1          eəeə           [v, v]           2  \n",
       "5          ɛɹən     [v, c, v, c]           2  \n",
       "7            æb           [v, c]           1  \n",
       "9           æbi        [v, c, v]           2  \n",
       "...         ...              ...         ...  \n",
       "12546     zɑmbi  [c, v, c, c, v]           2  \n",
       "12547     zoʊʊn        [c, v, c]           1  \n",
       "12548        zu           [c, v]           1  \n",
       "12549       zum        [c, v, c]           1  \n",
       "12556      zulu     [c, v, c, v]           2  \n",
       "\n",
       "[7904 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_initial_vocab_original = load_pickle('likelihood_inputs/cmu_in_initial_vocab.obj')\n",
    "cmu_in_initial_vocab_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_distance_matrix(all_tokens_phono, prior_data, initial_vocab,  cmu_2syl_inchildes):    \n",
    "    '''\n",
    "    Get an edit distance matrix for matrix-based computation of the posterior\n",
    "\n",
    "    all_tokens_phono: corpus in tokenized from, with phonological transcriptions\n",
    "    prior_data: priors of the form output by `compare_successes_failures_*`\n",
    "    initial_vocab: word types corresponding to the softmask mask\n",
    "    cmu_2syl_inchildes: cmu pronunctiations, must have 'word' and 'ipa_short' columns \n",
    "    '''\n",
    "\n",
    "    bert_token_ids = prior_data['scores']['bert_token_id']\n",
    "    ipa = pd.DataFrame({'bert_token_id':bert_token_ids}).merge(all_tokens_phono[['bert_token_id',\n",
    "        'actual_phonology_no_dia']])\n",
    "\n",
    "    iv = pd.DataFrame({'word':initial_vocab})\n",
    "    iv = iv.merge(cmu_2syl_inchildes, how='left')\n",
    "\n",
    "    levdists = np.vstack([np.array([Levenshtein.distance(target,x) for x in iv.ipa_short\n",
    "    ]) for target in ipa.actual_phonology_no_dia])    \n",
    "    return(levdists, ipa)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "levdists, lev_ipa = get_edit_distance_matrix(all_tokens_phono, priors_for_age_interval, initial_vocab,  cmu_in_initial_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11718, 8869)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levdists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11718, 8869)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levdists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "levdists_reduced = wfst.reduce_duplicates(levdists, cmu_in_initial_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 4, ..., 3, 3, 4],\n",
       "       [2, 2, 4, ..., 2, 3, 4],\n",
       "       [2, 2, 4, ..., 2, 3, 4],\n",
       "       ...,\n",
       "       [2, 2, 3, ..., 3, 3, 4],\n",
       "       [2, 2, 4, ..., 2, 3, 4],\n",
       "       [0, 1, 3, ..., 2, 3, 4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levdists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 4, ..., 3, 3, 4],\n",
       "       [2, 4, 4, ..., 2, 3, 4],\n",
       "       [2, 4, 4, ..., 2, 3, 4],\n",
       "       ...,\n",
       "       [2, 3, 3, ..., 3, 3, 4],\n",
       "       [2, 4, 4, ..., 2, 3, 4],\n",
       "       [1, 3, 3, ..., 2, 3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levdists_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WFST Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.wfst' from '/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(wfst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/nicole/child-directed-listening/cdl_env/lib/python3.6/site-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end[0,2] = ''\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end[0,3] = ''\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end[0,4] = ''\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py:255: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[[1]] = -1 * np.log(1)\n",
      "/home/stephan/notebooks/nicole/child-directed-listening/cdl_env/lib/python3.6/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/stephan/notebooks/nicole/child-directed-listening/utils/wfst.py\u001b[0m(288)\u001b[0;36mget_wfst_distance_matrix\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    286 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    287 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 288 \u001b[0;31m    \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    289 \u001b[0;31m    \u001b[0md_fsa_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mserial_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    290 \u001b[0;31m    \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_all_likelihoods_for_w_over_paths_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fsa_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_fsa_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md_fsa_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  serial_inputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ipa.actual_phonology_no_dia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: actual_phonology_no_dia, dtype: object)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ipa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [bert_token_id, actual_phonology_no_dia]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  bert_token_ids = prior_data['scores']['bert_token_id']\n",
      "ipdb>  prior_data['scores']['bert_token_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2749419    2749419.0\n",
      "558301      558301.0\n",
      "558302      558302.0\n",
      "558303      558303.0\n",
      "558304      558304.0\n",
      "             ...    \n",
      "955657      955657.0\n",
      "248413      248413.0\n",
      "1725984    1725984.0\n",
      "2545317    2545317.0\n",
      "1533942    1533942.0\n",
      "Name: bert_token_id, Length: 11718, dtype: float64\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ipa = pd.DataFrame({'bert_token_id':bert_token_ids}).merge(all_tokens_phono[['bert_token_id',         'actual_phonology_no_dia']])\n",
      "ipdb>  Ipa.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'Ipa' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ipa.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  all_tokens_phono[['bert_token_id']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bert_token_id\n",
      "0              0\n",
      "1              1\n",
      "2              2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  all_tokens_phono.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 72)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.min(prior_data['scores']['bert_token_id’])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: EOL while scanning string literal\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.min(prior_data['scores']['bert_token_id'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42474.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  all_tokens_phono.loc[all_tokens_phono.bert_token_id == 42474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [token, utterance_id, gloss, transcript_id, utterance_order, target_child_name, speaker_code, type, punct, speaker_code_simple, gloss_with_punct, token_id, seq_utt_id, actual_phonology, model_phonology, target_child_age, bert_token_id, model_phonology_clean, actual_phonology_clean, model_phonology_no_dia, actual_phonology_no_dia, cv_raw_actual, cv_collapsed_actual, num_vowels_actual, cv_raw_model, cv_collapsed_model, num_vowels_model, num_vowels, in_vocab, success_token, yyy_token, partition, phase_sample, year, phase_child_sample, phase_child_finetune, phase_child_sample_n=2_type=success_name=Alex, phase_child_sample_n=2_type=success_name=Ethan, phase_child_sample_n=2_type=success_name=Lily, phase_child_sample_n=2_type=success_name=Naima, phase_child_sample_n=2_type=success_name=Violet, phase_child_sample_n=2_type=success_name=William, phase_child_sample_n=2_type=yyy_name=Alex, phase_child_sample_n=2_type=yyy_name=Ethan, phase_child_sample_n=2_type=yyy_name=Lily, phase_child_sample_n=2_type=yyy_name=Naima, phase_child_sample_n=2_type=yyy_name=Violet, phase_child_sample_n=2_type=yyy_name=William, phase_child_sample_n=1000_type=success_name=Alex, phase_child_sample_n=1000_type=success_name=Ethan, phase_child_sample_n=1000_type=success_name=Lily, phase_child_sample_n=1000_type=success_name=Naima, phase_child_sample_n=1000_type=success_name=Violet, phase_child_sample_n=1000_type=success_name=William, phase_child_sample_n=1000_type=yyy_name=Alex, phase_child_sample_n=1000_type=yyy_name=Ethan, phase_child_sample_n=1000_type=yyy_name=Lily, phase_child_sample_n=1000_type=yyy_name=Naima, phase_child_sample_n=1000_type=yyy_name=Violet, phase_child_sample_n=1000_type=yyy_name=William, phase_child_sample_n=5000_type=success_name=Alex, phase_child_sample_n=5000_type=success_name=Ethan, phase_child_sample_n=5000_type=success_name=Lily, phase_child_sample_n=5000_type=success_name=Naima, phase_child_sample_n=5000_type=success_name=Violet, phase_child_sample_n=5000_type=success_name=William, phase_child_sample_n=5000_type=yyy_name=Alex, phase_child_sample_n=5000_type=yyy_name=Ethan, phase_child_sample_n=5000_type=yyy_name=Lily, phase_child_sample_n=5000_type=yyy_name=Naima, phase_child_sample_n=5000_type=yyy_name=Violet, phase_child_sample_n=5000_type=yyy_name=William]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "wfst_dists, wfst_ipa = wfst.get_wfst_distance_matrix(all_tokens_phono.iloc[0:3], priors_for_age_interval, initial_vocab,  cmu_in_initial_vocab,\n",
    "    'fst/chi-1.txt', 'fst/chi_phones.sym', num_cores=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.91034475e-07, 9.70735108e-10, 3.67834322e-09, ...,\n",
       "        7.37326126e-07, 8.21103669e-08, 4.29370811e-09],\n",
       "       [1.52810475e-05, 1.07906226e-02, 3.85958957e-04, ...,\n",
       "        3.55403403e-07, 7.24668517e-03, 5.87386341e-08],\n",
       "       [1.54677852e-05, 1.29174011e-07, 1.94688503e-06, ...,\n",
       "        5.18680997e-05, 2.73407839e-06, 6.45766567e-06],\n",
       "       ...,\n",
       "       [3.71623671e-06, 3.66785446e-07, 1.41435053e-05, ...,\n",
       "        1.57430170e-08, 4.41272637e-07, 3.82429106e-06],\n",
       "       [1.99342754e-05, 7.02976751e-07, 6.30810697e-07, ...,\n",
       "        2.25177957e-06, 3.33650960e-07, 8.37396635e-08],\n",
       "       [8.37781899e-01, 2.10227361e-03, 7.96600896e-03, ...,\n",
       "        8.34289234e-04, 3.93670646e-03, 9.49116777e-05]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfst_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cd6904cf41a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwfst_dists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m7904\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(wfst_dists.shape[1] != 7904)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7904 is out of bounds for axis 1 with size 7904",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9fe0945b514f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwfst_dists_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwfst_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmu_in_initial_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwfst_dists_reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/nicole/child-directed-listening/utils/wfst.py\u001b[0m in \u001b[0;36mreduce_duplicates\u001b[0;34m(wfst_dists, cmu_in_initial_vocab)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# take the max of the previous word's columns before starting the new word's columns group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mwfst_dists_by_word_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_group_for_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mcurrent_group_for_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwfst_dists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwfst_dists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mcurrent_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0mwfst_dists_by_word_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_group_for_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7904 is out of bounds for axis 1 with size 7904"
     ]
    }
   ],
   "source": [
    "wfst_dists_reduced = wfst.reduce_duplicates(wfst_dists, cmu_in_initial_vocab)\n",
    "wfst_dists_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfst_dists_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_wfst(wfst_dists_reduced, wfst_ipa, row_index):\n",
    "    d_word = wfst_ipa.iloc[row_index]\n",
    "    w_word_index = np.argmax(wfst_dists_reduced[row_index,:])\n",
    "    w_word = initial_vocab[w_word_index]\n",
    "    print(d_word)\n",
    "    print(w_word_index)\n",
    "    print(w_word)\n",
    "\n",
    "sanity_check_wfst(wfst_dists_reduced, wfst_ipa, 7530)\n",
    "sanity_check_wfst(wfst_dists_reduced, wfst_ipa, 7531)\n",
    "sanity_check_wfst(wfst_dists_reduced, wfst_ipa, 7532)\n",
    "sanity_check_wfst(wfst_dists_reduced, wfst_ipa, 7533)\n",
    "sanity_check_wfst(wfst_dists_reduced, wfst_ipa, 7534)\n",
    "sanity_check_wfst(wfst_dists_reduced, wfst_ipa, 7535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_vocab_with_duplicates = list(cmu_in_initial_vocab[\"word\"])\n",
    "\n",
    "def sanity_check_lev(levdists, lev_ipa, row_index):\n",
    "    d_word = lev_ipa.iloc[row_index]\n",
    "    w_word_index = np.argmin(levdists[row_index,:])\n",
    "    w_word = initial_vocab_with_duplicates[w_word_index]\n",
    "    print(d_word)\n",
    "    print(w_word)\n",
    "\n",
    "sanity_check_lev(levdists, lev_ipa, 7530)\n",
    "sanity_check_lev(levdists, lev_ipa, 7531)\n",
    "sanity_check_lev(levdists, lev_ipa, 7532)\n",
    "sanity_check_lev(levdists, lev_ipa, 7533)\n",
    "sanity_check_lev(levdists, lev_ipa, 7534)\n",
    "sanity_check_lev(levdists, lev_ipa, 7535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levdists"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
