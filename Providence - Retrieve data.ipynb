{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9e0345",
   "metadata": {},
   "source": [
    "## Prepares Providence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b5b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7/22/21: https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# end cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ad24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "import childespy\n",
    "import numpy as np\n",
    "import os\n",
    "import imp\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import re\n",
    "import unicodedata\n",
    "import scipy.stats\n",
    "import copy\n",
    "from string import punctuation\n",
    "\n",
    "from os.path import join, exists\n",
    "\n",
    "import config\n",
    "np.random.seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72431001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_gen, sampling, data_cleaning, load_models, data_cleaning, transformers_bert_completions\n",
    "from utils_child import child_split_gen, child_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772bd16b",
   "metadata": {},
   "source": [
    "### Prepare and clean Providence data \n",
    "\n",
    "Corresponds to: 4 | Prep Utterances / Tokens for BERT,\n",
    "    in the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef241b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n",
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the index of the Providence corpus\n",
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"').iloc[0]['id']\n",
    "\n",
    "# Load utterances from the Providence corpus from childs-db\n",
    "\n",
    "raw_utt_glosses_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses.csv')\n",
    "if config.regenerate:\n",
    "    raw_utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, actual_phonology, model_phonology, target_child_name, target_child_age, type from utterance where speaker_code in (\"MOT\", \"FAT\",\"CHI\") and corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    raw_utt_glosses.to_csv(raw_utt_glosses_save_path, index=False)\n",
    "else: \n",
    "    raw_utt_glosses = pd.read_csv(raw_utt_glosses_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32feef7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please don't do that</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mommy</td>\n",
       "      <td>ɑmɪ</td>\n",
       "      <td>mɑmiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>okay that's fine</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445363</th>\n",
       "      <td>oh why lick hippo</td>\n",
       "      <td>o waɪ liʔ ɪ</td>\n",
       "      <td>oʊ waɪ lɪk hɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445364</th>\n",
       "      <td>hippo</td>\n",
       "      <td>hɪpo</td>\n",
       "      <td>hɪpoʊ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445365</th>\n",
       "      <td>xxx</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445366</th>\n",
       "      <td>xxx la la xxx</td>\n",
       "      <td>* lɑ lɑ *</td>\n",
       "      <td>* lɑː lɑː *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445367</th>\n",
       "      <td>xxx ola xxx ola xxx ola xxx</td>\n",
       "      <td>* olɑ * olə * olɑ *</td>\n",
       "      <td>* oʊlə * oʊlə * oʊlə *</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445367 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               gloss     actual_phonology  \\\n",
       "1       anywhere you'll feel comfortable um anywhere                        \n",
       "2                               please don't do that                        \n",
       "3                                            this is                        \n",
       "4                                              Mommy                  ɑmɪ   \n",
       "5                                   okay that's fine                        \n",
       "...                                              ...                  ...   \n",
       "445363                             oh why lick hippo          o waɪ liʔ ɪ   \n",
       "445364                                         hippo                 hɪpo   \n",
       "445365                                           xxx                        \n",
       "445366                                 xxx la la xxx            * lɑ lɑ *   \n",
       "445367                   xxx ola xxx ola xxx ola xxx  * olɑ * olə * olɑ *   \n",
       "\n",
       "               model_phonology  \n",
       "1                               \n",
       "2                               \n",
       "3                               \n",
       "4                        mɑmiː  \n",
       "5                               \n",
       "...                        ...  \n",
       "445363           oʊ waɪ lɪk hɪ  \n",
       "445364                   hɪpoʊ  \n",
       "445365                          \n",
       "445366             * lɑː lɑː *  \n",
       "445367  * oʊlə * oʊlə * oʊlə *  \n",
       "\n",
       "[445367 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_utt_glosses[['gloss', 'actual_phonology', 'model_phonology']] # Utterance id level, then it's tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d162a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7/26/21: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\n",
    "# for general function\n",
    "# 7/27/21: https://stackoverflow.com/questions/46096307/alias-for-column-in-pandas\n",
    "# for using columns keyword\n",
    "raw_utt_glosses = raw_utt_glosses.rename(columns = {'id' : 'utterance_id'})\n",
    "# end both cites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0fecc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "declarative                   325325\n",
      "question                       81758\n",
      "imperative_emphatic            15404\n",
      "trail off                      11924\n",
      "self interruption               6443\n",
      "interruption                    2784\n",
      "self interruption question       807\n",
      "trail off question               631\n",
      "interruption question            285\n",
      "quotation precedes                 3\n",
      "question exclamation               2\n",
      "broken for coding                  1\n",
      "Name: type, dtype: int64\n",
      "Cell 238 gloss                anywhere you'll feel comfortable um anywhere\n",
      "transcript_id                                               42204\n",
      "utterance_id                                             16759261\n",
      "utterance_order                                                 2\n",
      "speaker_code                                                  MOT\n",
      "actual_phonology                                                 \n",
      "model_phonology                                                  \n",
      "target_child_name                                            Alex\n",
      "target_child_age                                            514.0\n",
      "type                                                  declarative\n",
      "punct                                                           .\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "utt_glosses = data_cleaning.clean_glosses(raw_utt_glosses.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f71dc1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    gloss  transcript_id  utterance_id  utterance_order  \\\n",
      "445363  oh why lick hippo          42569      17280964              756   \n",
      "\n",
      "       speaker_code actual_phonology model_phonology target_child_name  \\\n",
      "445363          CHI      o waɪ liʔ ɪ   oʊ waɪ lɪk hɪ           William   \n",
      "\n",
      "        target_child_age               type punct speaker_code_simple  \\\n",
      "445363         1212.0625  self interruption     .               [CHI]   \n",
      "\n",
      "                gloss_with_punct  \n",
      "445363  [CHI] oh why lick hippo.  \n"
     ]
    }
   ],
   "source": [
    "if config.verbose: print(utt_glosses[utt_glosses.utterance_id == 17280964])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31b5b0",
   "metadata": {},
   "source": [
    "### Build the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0bc76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7904, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cmu_2syl_inchildes = load_models.get_cmu_dict_info()\n",
    "initial_tokenizer = load_models.get_primary_tokenizer()\n",
    "\n",
    "initial_vocab, cmu_in_initial_vocab = load_models.get_initial_vocab_info()\n",
    "\n",
    "# confirm yyy treated as a separate character\n",
    "assert initial_tokenizer.tokenize('this is a yyy.') == ['this', 'is', 'a', 'yyy', '.']\n",
    "\n",
    "if config.verbose: print(cmu_in_initial_vocab.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e97d9a",
   "metadata": {},
   "source": [
    "### Count successes/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e06c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_transmission_errors(utt_vector, error_codes):\n",
    "    return(np.sum([x in error_codes for x in  utt_vector]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb85720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19686, 3)\n",
      "(399286, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Only consider scoreable utterances from children,\n",
    "# but here consider CGV utterances as well due to need to filter on finetune data.\n",
    "# Therefore raw_success_utts and raw_yyy_utts refer to things with the appropriate number of errors\n",
    "\n",
    "xxxs_per_utt = utt_glosses.groupby('utterance_id').gloss.agg(\n",
    "    lambda x: count_transmission_errors(x, ['xxx'])).reset_index()\n",
    "\n",
    "xxxs_per_utt.columns = ['utterance_id', 'num_xxx']\n",
    "yyys_per_utt = utt_glosses.groupby('utterance_id').gloss.agg(\n",
    "    lambda x: count_transmission_errors(x, ['yyy'])).reset_index()\n",
    "\n",
    "yyys_per_utt.columns = ['utterance_id', 'num_yyy']\n",
    "\n",
    "failures_per_utt = xxxs_per_utt.merge(yyys_per_utt)\n",
    "\n",
    "raw_yyy_utts = failures_per_utt.loc[(failures_per_utt.num_xxx == 0) &  (failures_per_utt.num_yyy == 1)]\n",
    "\n",
    "if config.verbose: print(raw_yyy_utts.shape)\n",
    "\n",
    "raw_success_utts = failures_per_utt.loc[(failures_per_utt.num_xxx == 0) &  \n",
    "    (failures_per_utt.num_yyy == 0)]\n",
    "\n",
    "# Note this will not be the same as the previous printout because it's directly on all_tokens_phono.\n",
    "if config.verbose: print(raw_success_utts.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b017d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>target_child_age</th>\n",
       "      <th>...</th>\n",
       "      <th>model_phonology_clean</th>\n",
       "      <th>actual_phonology_clean</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>cv_raw</th>\n",
       "      <th>cv_collapsed</th>\n",
       "      <th>num_vowels</th>\n",
       "      <th>in_vocab</th>\n",
       "      <th>success_token</th>\n",
       "      <th>yyy_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[chi]</td>\n",
       "      <td>16759363</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42204</td>\n",
       "      <td>11</td>\n",
       "      <td>CHI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Alex</td>\n",
       "      <td>514.0000</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>yyy</td>\n",
       "      <td>16759363</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42204</td>\n",
       "      <td>11</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>*</td>\n",
       "      <td>Alex</td>\n",
       "      <td>514.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>*</td>\n",
       "      <td>ə</td>\n",
       "      <td>*</td>\n",
       "      <td>ə</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>.</td>\n",
       "      <td>16759363</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42204</td>\n",
       "      <td>11</td>\n",
       "      <td>CHI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Alex</td>\n",
       "      <td>514.0000</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>[chi]</td>\n",
       "      <td>16759468</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42206</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Alex</td>\n",
       "      <td>543.4375</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>yyy</td>\n",
       "      <td>16759468</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42206</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>aʊ</td>\n",
       "      <td>*</td>\n",
       "      <td>Alex</td>\n",
       "      <td>543.4375</td>\n",
       "      <td>...</td>\n",
       "      <td>*</td>\n",
       "      <td>ɑʊ</td>\n",
       "      <td>*</td>\n",
       "      <td>ɑʊ</td>\n",
       "      <td>vv</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991672</th>\n",
       "      <td>yyy</td>\n",
       "      <td>17280335</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42569</td>\n",
       "      <td>723</td>\n",
       "      <td>CHI</td>\n",
       "      <td>iː</td>\n",
       "      <td>*</td>\n",
       "      <td>William</td>\n",
       "      <td>1212.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>*</td>\n",
       "      <td>i</td>\n",
       "      <td>*</td>\n",
       "      <td>i</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991673</th>\n",
       "      <td>.</td>\n",
       "      <td>17280335</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42569</td>\n",
       "      <td>723</td>\n",
       "      <td>CHI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>William</td>\n",
       "      <td>1212.0625</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991674</th>\n",
       "      <td>[chi]</td>\n",
       "      <td>17280349</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42569</td>\n",
       "      <td>724</td>\n",
       "      <td>CHI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>William</td>\n",
       "      <td>1212.0625</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991675</th>\n",
       "      <td>yyy</td>\n",
       "      <td>17280349</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42569</td>\n",
       "      <td>724</td>\n",
       "      <td>CHI</td>\n",
       "      <td>iːɪːoː</td>\n",
       "      <td>*</td>\n",
       "      <td>William</td>\n",
       "      <td>1212.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>*</td>\n",
       "      <td>iəoʊ</td>\n",
       "      <td>*</td>\n",
       "      <td>iəoʊ</td>\n",
       "      <td>vvvv</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991676</th>\n",
       "      <td>.</td>\n",
       "      <td>17280349</td>\n",
       "      <td>yyy</td>\n",
       "      <td>42569</td>\n",
       "      <td>724</td>\n",
       "      <td>CHI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>William</td>\n",
       "      <td>1212.0625</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59222 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  utterance_id gloss  transcript_id  utterance_order  \\\n",
       "54       [chi]      16759363   yyy          42204               11   \n",
       "55         yyy      16759363   yyy          42204               11   \n",
       "56           .      16759363   yyy          42204               11   \n",
       "127      [chi]      16759468   yyy          42206                1   \n",
       "128        yyy      16759468   yyy          42206                1   \n",
       "...        ...           ...   ...            ...              ...   \n",
       "2991672    yyy      17280335   yyy          42569              723   \n",
       "2991673      .      17280335   yyy          42569              723   \n",
       "2991674  [chi]      17280349   yyy          42569              724   \n",
       "2991675    yyy      17280349   yyy          42569              724   \n",
       "2991676      .      17280349   yyy          42569              724   \n",
       "\n",
       "        speaker_code actual_phonology model_phonology target_child_name  \\\n",
       "54               CHI                                               Alex   \n",
       "55               CHI                ʌ               *              Alex   \n",
       "56               CHI                                               Alex   \n",
       "127              CHI                                               Alex   \n",
       "128              CHI               aʊ               *              Alex   \n",
       "...              ...              ...             ...               ...   \n",
       "2991672          CHI               iː               *           William   \n",
       "2991673          CHI                                            William   \n",
       "2991674          CHI                                            William   \n",
       "2991675          CHI           iːɪːoː               *           William   \n",
       "2991676          CHI                                            William   \n",
       "\n",
       "         target_child_age  ... model_phonology_clean actual_phonology_clean  \\\n",
       "54               514.0000  ...                                                \n",
       "55               514.0000  ...                     *                      ə   \n",
       "56               514.0000  ...                                                \n",
       "127              543.4375  ...                                                \n",
       "128              543.4375  ...                     *                     ɑʊ   \n",
       "...                   ...  ...                   ...                    ...   \n",
       "2991672         1212.0625  ...                     *                      i   \n",
       "2991673         1212.0625  ...                                                \n",
       "2991674         1212.0625  ...                                                \n",
       "2991675         1212.0625  ...                     *                   iəoʊ   \n",
       "2991676         1212.0625  ...                                                \n",
       "\n",
       "        model_phonology_no_dia actual_phonology_no_dia  cv_raw  cv_collapsed  \\\n",
       "54                                                                             \n",
       "55                           *                       ə       v             v   \n",
       "56                                                                             \n",
       "127                                                                            \n",
       "128                          *                      ɑʊ      vv             v   \n",
       "...                        ...                     ...     ...           ...   \n",
       "2991672                      *                       i       v             v   \n",
       "2991673                                                                        \n",
       "2991674                                                                        \n",
       "2991675                      *                    iəoʊ    vvvv             v   \n",
       "2991676                                                                        \n",
       "\n",
       "         num_vowels in_vocab success_token yyy_token  \n",
       "54              NaN    False         False     False  \n",
       "55              1.0    False         False      True  \n",
       "56              NaN    False         False     False  \n",
       "127             NaN    False         False     False  \n",
       "128             1.0    False         False      True  \n",
       "...             ...      ...           ...       ...  \n",
       "2991672         1.0    False         False      True  \n",
       "2991673         NaN    False         False     False  \n",
       "2991674         NaN    False         False     False  \n",
       "2991675         1.0    False         False      True  \n",
       "2991676         NaN    False         False     False  \n",
       "\n",
       "[59222 rows x 27 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono[all_tokens_phono.utterance_id.isin(yyy_utt_ids)] # what to do here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c084b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 done\n",
      "0.011 done\n",
      "0.022 done\n",
      "0.034 done\n",
      "0.045 done\n",
      "0.056 done\n",
      "0.067 done\n",
      "0.079 done\n",
      "0.09 done\n",
      "0.101 done\n",
      "0.112 done\n",
      "0.123 done\n",
      "0.135 done\n",
      "0.146 done\n",
      "0.157 done\n",
      "0.168 done\n",
      "0.18 done\n",
      "0.191 done\n",
      "0.202 done\n",
      "0.213 done\n",
      "0.225 done\n",
      "0.236 done\n",
      "0.247 done\n",
      "0.258 done\n",
      "0.269 done\n",
      "0.281 done\n",
      "0.292 done\n",
      "0.303 done\n",
      "0.314 done\n",
      "0.326 done\n",
      "0.337 done\n",
      "0.348 done\n",
      "0.359 done\n",
      "0.37 done\n",
      "0.382 done\n",
      "0.393 done\n",
      "0.404 done\n",
      "0.415 done\n",
      "0.427 done\n",
      "0.438 done\n",
      "0.449 done\n",
      "0.46 done\n",
      "0.472 done\n",
      "0.483 done\n",
      "0.494 done\n",
      "0.505 done\n",
      "0.516 done\n",
      "0.528 done\n",
      "0.539 done\n",
      "0.55 done\n",
      "0.561 done\n",
      "0.573 done\n",
      "0.584 done\n",
      "0.595 done\n",
      "0.606 done\n",
      "0.617 done\n",
      "0.629 done\n",
      "0.64 done\n",
      "0.651 done\n",
      "0.662 done\n",
      "0.674 done\n",
      "0.685 done\n",
      "0.696 done\n",
      "0.707 done\n",
      "0.719 done\n",
      "0.73 done\n",
      "0.741 done\n",
      "0.752 done\n",
      "0.763 done\n",
      "0.775 done\n",
      "0.786 done\n",
      "0.797 done\n",
      "0.808 done\n",
      "0.82 done\n",
      "0.831 done\n",
      "0.842 done\n",
      "0.853 done\n",
      "0.864 done\n",
      "0.876 done\n",
      "0.887 done\n",
      "0.898 done\n",
      "0.909 done\n",
      "0.921 done\n",
      "0.932 done\n",
      "0.943 done\n",
      "0.954 done\n",
      "0.965 done\n",
      "0.977 done\n",
      "0.988 done\n",
      "0.999 done\n",
      "         token  utterance_id                                         gloss  \\\n",
      "0        [cgv]      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "1     anywhere      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "2          you      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "3            '      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "4           ll      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "5         feel      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "6  comfortable      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "7           um      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "8     anywhere      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "9            .      16759261  anywhere you'll feel comfortable um anywhere   \n",
      "\n",
      "   transcript_id  utterance_order speaker_code actual_phonology  \\\n",
      "0          42204                2          MOT                    \n",
      "1          42204                2          MOT                    \n",
      "2          42204                2          MOT                    \n",
      "3          42204                2          MOT                    \n",
      "4          42204                2          MOT                    \n",
      "5          42204                2          MOT                    \n",
      "6          42204                2          MOT                    \n",
      "7          42204                2          MOT                    \n",
      "8          42204                2          MOT                    \n",
      "9          42204                2          MOT                    \n",
      "\n",
      "  model_phonology target_child_name  target_child_age         type punct  \\\n",
      "0                              Alex             514.0  declarative     .   \n",
      "1                              Alex             514.0  declarative     .   \n",
      "2                              Alex             514.0  declarative     .   \n",
      "3                              Alex             514.0  declarative     .   \n",
      "4                              Alex             514.0  declarative     .   \n",
      "5                              Alex             514.0  declarative     .   \n",
      "6                              Alex             514.0  declarative     .   \n",
      "7                              Alex             514.0  declarative     .   \n",
      "8                              Alex             514.0  declarative     .   \n",
      "9                              Alex             514.0  declarative     .   \n",
      "\n",
      "  speaker_code_simple                                   gloss_with_punct  \n",
      "0               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "1               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "2               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "3               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "4               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "5               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "6               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "7               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "8               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
      "9               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build a dataframe of tokens \n",
    "# this is slow, because tokenization is slow\n",
    "\n",
    "def inflate(row):\n",
    "    tokens = initial_tokenizer.tokenize(row['gloss_with_punct'])\n",
    "    return(pd.DataFrame({'token':tokens, 'utterance_id':row['utterance_id']}) )\n",
    "\n",
    "all_tokens_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses_inflated.csv')\n",
    "if config.regenerate:\n",
    "    inflate_all = []\n",
    "    \n",
    "    num_process = utt_glosses.to_dict('records')\n",
    "    \n",
    "    print(f\"Number to process: {num_process}\")\n",
    "    for idx, x in enumerate(utt_glosses.to_dict('records')):\n",
    "        percent_done = round(idx / len(num_process), 3)\n",
    "        if idx % 5000 == 0 : print(f'{percent_done} done')\n",
    "        inflate_all.append(inflate(x))\n",
    "        \n",
    "    all_tokens = pd.concat(inflate_all)\n",
    "    all_tokens = all_tokens.merge(utt_glosses)\n",
    "    \n",
    "    all_tokens.to_csv(all_tokens_save_path)\n",
    "\n",
    "else:\n",
    "    all_tokens = pd.read_csv(all_tokens_save_path, na_filter=False)\n",
    "\n",
    "if config.verbose: print(all_tokens.iloc[0:10])\n",
    "\n",
    "# Assign a token_id (integer in the BERT vocabulary). \n",
    "# Because these are from the tokenized utterances, there is no correpsondence \n",
    "# with childes-db token ids\n",
    "all_tokens['token_id'] = initial_tokenizer.convert_tokens_to_ids(all_tokens['token'])\n",
    "# assigns utterances a 0-indexed index column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ce8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens['seq_utt_id'] = all_tokens['utterance_id'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3807d30",
   "metadata": {},
   "source": [
    "### Add back IPA, syllable structure, and child ages for child productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a56b525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/frame.py:1554: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% complete...\n",
      "2.0% complete...\n",
      "3.0% complete...\n",
      "4.0% complete...\n",
      "5.0% complete...\n",
      "6.0% complete...\n",
      "7.0% complete...\n",
      "8.0% complete...\n",
      "9.0% complete...\n",
      "10.0% complete...\n",
      "11.0% complete...\n",
      "12.0% complete...\n",
      "13.0% complete...\n",
      "14.0% complete...\n",
      "15.0% complete...\n",
      "16.0% complete...\n",
      "17.0% complete...\n",
      "18.0% complete...\n",
      "19.0% complete...\n",
      "20.0% complete...\n",
      "21.0% complete...\n",
      "22.0% complete...\n",
      "23.0% complete...\n",
      "24.0% complete...\n",
      "25.0% complete...\n",
      "26.0% complete...\n",
      "27.0% complete...\n",
      "28.0% complete...\n",
      "29.0% complete...\n",
      "30.0% complete...\n",
      "31.0% complete...\n",
      "32.0% complete...\n",
      "33.0% complete...\n",
      "33.99% complete...\n",
      "34.99% complete...\n",
      "35.99% complete...\n",
      "36.99% complete...\n",
      "37.99% complete...\n",
      "38.99% complete...\n",
      "39.99% complete...\n",
      "40.99% complete...\n",
      "41.99% complete...\n",
      "42.99% complete...\n",
      "43.99% complete...\n",
      "44.99% complete...\n",
      "45.99% complete...\n",
      "46.99% complete...\n",
      "47.99% complete...\n",
      "48.99% complete...\n",
      "49.99% complete...\n",
      "50.99% complete...\n",
      "51.99% complete...\n",
      "52.99% complete...\n",
      "53.99% complete...\n",
      "54.99% complete...\n",
      "55.99% complete...\n",
      "56.99% complete...\n",
      "57.99% complete...\n",
      "58.99% complete...\n",
      "59.99% complete...\n",
      "60.99% complete...\n",
      "61.99% complete...\n",
      "62.99% complete...\n",
      "63.99% complete...\n",
      "64.99% complete...\n",
      "65.99% complete...\n",
      "66.99% complete...\n",
      "67.99% complete...\n",
      "68.99% complete...\n",
      "69.99% complete...\n",
      "70.99% complete...\n",
      "71.99% complete...\n",
      "72.99% complete...\n",
      "73.99% complete...\n",
      "74.99% complete...\n",
      "75.99% complete...\n",
      "76.99% complete...\n",
      "77.99% complete...\n",
      "78.99% complete...\n",
      "79.99% complete...\n",
      "80.99% complete...\n",
      "81.99% complete...\n",
      "82.99% complete...\n",
      "83.99% complete...\n",
      "84.99% complete...\n",
      "85.99% complete...\n",
      "86.99% complete...\n",
      "87.99% complete...\n",
      "88.99% complete...\n",
      "89.99% complete...\n",
      "90.99% complete...\n",
      "91.99% complete...\n",
      "92.99% complete...\n",
      "93.99% complete...\n",
      "94.99% complete...\n",
      "95.99% complete...\n",
      "96.99% complete...\n",
      "97.99% complete...\n",
      "98.99% complete...\n",
      "99.98% complete...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/nwong/chompsky/childes/child_listening_continuation/child-directed-listening/prov_csv/csv/pvd_utt_glosses_phono_inflated.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a4c2c5ee5e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m#save the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mall_tokens_phono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_phono_inflated_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mall_tokens_phono\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_phono_inflated_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   2866\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2867\u001b[0m             \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2868\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2869\u001b[0m         )\n\u001b[1;32m   2870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     ) as handles:\n\u001b[1;32m     97\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/nwong/chompsky/childes/child_listening_continuation/child-directed-listening/prov_csv/csv/pvd_utt_glosses_phono_inflated.pkl'"
     ]
    }
   ],
   "source": [
    "# get the token-level data, esp phonology\n",
    "\n",
    "\n",
    "save_phono_inflated_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_inflated.pkl')\n",
    "if config.regenerate:\n",
    "\n",
    "    # get token-level information for Providence\n",
    "    pvd_chi_tokens = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, actual_phonology, model_phonology, transcript_id, utterance_id, \\\n",
    "    token_order from token where speaker_code = \"CHI\" and corpus_id = '+str(pvd_idx),\n",
    "        db_version = \"2020.1\")\n",
    "    \n",
    "    counts_utt_valid_set = set(pd.concat([raw_success_utts, raw_yyy_utts]).utterance_id)\n",
    "    \n",
    "    # Isolate the utterances that are valid successes and yyy\n",
    "    # And also have model phonology/actual phonology\n",
    "    # The intent is to replace the first query in the original notebook.\n",
    "    \n",
    "    \n",
    "    pvd_chi_phonology_utt_set_df = pvd_chi_tokens[pvd_chi_tokens.isin(counts_utt_valid_set)]\n",
    "    \n",
    "    pvd_chi_phonology_utt_set_df = pvd_chi_phonology_utt_set_df[pvd_chi_phonology_utt_set_df.actual_phonology != \"\"]\n",
    "    pvd_chi_phonology_utt_set_df = pvd_chi_phonology_utt_set_df[pvd_chi_phonology_utt_set_df.model_phonology != \"\"]\n",
    "\n",
    "    pvd_chi_phonology_utt_set = set(pvd_chi_phonology_utt_set_df.utterance_id)\n",
    "\n",
    "    # Pvd chi will enforce that everything populated with phonology is a CHI token\n",
    "    utts_to_retrieve = counts_utt_valid_set & pvd_chi_phonology_utt_set\n",
    "     \n",
    "    pvd_chi_tokens['gloss'] = [data_cleaning.fix_gloss(x) for x in pvd_chi_tokens.gloss]\n",
    "    \n",
    "    # prep the tokens generated from segmenting the utterances\n",
    "    all_tokens_test = copy.deepcopy(all_tokens) \n",
    "\n",
    "    # initialize the fields that need to be populated\n",
    "    all_tokens_test['actual_phonology'] = ''\n",
    "    all_tokens_test['model_phonology'] = ''\n",
    "    all_tokens_test['target_child_age'] = np.nan\n",
    "    \n",
    "    # get a set of unique utterances\n",
    "    _, idx = np.unique(all_tokens_test.utterance_id, return_index=True)\n",
    "    all_utt_indices = all_tokens_test.utterance_id[np.sort(idx)]\n",
    "    \n",
    "    # For fast retrieval of IPA, split pvd_chi_tokens into a dictionary\n",
    "    pvd_chi_tokens_list = pvd_chi_tokens.groupby(['utterance_id'])\n",
    "    pvd_chi_tokens_dict = dict(zip(\n",
    "        [x[0] for x in pvd_chi_tokens_list], \n",
    "        [x[1] for x in pvd_chi_tokens_list], \n",
    "    ))\n",
    "    \n",
    "    # For fast retrival of BERT tokenization\n",
    "    all_tokens_test_list = all_tokens_test.groupby(['utterance_id'])\n",
    "    all_tokens_test_dict = dict(zip(\n",
    "        [x[0] for x in all_tokens_test_list], \n",
    "        [x[1] for x in all_tokens_test_list], \n",
    "    ))\n",
    "        \n",
    "    # Augment the tokens from all_tokens with the IPA from pvd_chi_tokens \n",
    "    rvs = [] \n",
    "    \n",
    "    i=-1\n",
    "    for utt_index in all_utt_indices:\n",
    "        i+=1\n",
    "        if i % int(len(all_utt_indices) / 100) == 0:\n",
    "            print(str(np.round((i / (len(all_utt_indices)) * 100),2))+'% complete...')    \n",
    "            # should learn to use tqdm instead\n",
    "        if utt_index in utts_to_retrieve:        \n",
    "            utt_df = copy.deepcopy(all_tokens_test_dict[utt_index])\n",
    "            utt_df['model_phonology'] = transformers_bert_completions.augment_with_ipa(\n",
    "              utt_df, pvd_chi_tokens_dict[utt_index],initial_tokenizer, 'model_phonology')\n",
    "            utt_df['actual_phonology'] = transformers_bert_completions.augment_with_ipa(\n",
    "              utt_df, pvd_chi_tokens_dict[utt_index],initial_tokenizer, 'actual_phonology')\n",
    "            utt_df['target_child_age'] = pvd_chi_tokens_dict[utt_index].iloc[0].target_child_age    \n",
    "            rvs.append(utt_df)  \n",
    "        else:\n",
    "            rvs.append(all_tokens_test_dict[utt_index])  \n",
    "            \n",
    "    # get the resulting augmented forms back into a dataframe\n",
    "    all_tokens_phono = pd.concat(rvs)\n",
    "    \n",
    "    # add a unique identifier to the BERT tokens\n",
    "    all_tokens_phono['bert_token_id'] = range(all_tokens_phono.shape[0])\n",
    "    \n",
    "    #save the results\n",
    "    all_tokens_phono.to_pickle(save_phono_inflated_path)\n",
    "else:\n",
    "    all_tokens_phono = pd.read_pickle(save_phono_inflated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d9eb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.to_pickle(save_phono_inflated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9aac70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IPA map\n",
    "phone_map_df = pd.read_csv('phon/phon_map_populated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f1c9493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         token actual_phonology model_phonology\n",
      "23       mommy              ɑmɪ           mɑmiː\n",
      "55         yyy                ʌ               *\n",
      "125        wee              wiː             wiː\n",
      "128        yyy               aʊ               *\n",
      "131        yyy                u               *\n",
      "...        ...              ...             ...\n",
      "2991851    xxx                *               *\n",
      "2991854    xxx                *               *\n",
      "2991857    xxx                *               *\n",
      "2991860    xxx                *               *\n",
      "2991863    xxx                *               *\n",
      "\n",
      "[360185 rows x 3 columns]\n",
      "  arpa ipa c_or_v\n",
      "0   AA   ɑ      v\n",
      "1   AE   æ      v\n",
      "2   AH   ə      v\n",
      "3   AO   ɔ      v\n",
      "4   AW  aʊ      v\n"
     ]
    }
   ],
   "source": [
    "if config.verbose:\n",
    "    # Inspect the IPA\n",
    "    print(all_tokens_phono.loc[all_tokens_phono.actual_phonology != ''][['token','actual_phonology','model_phonology']])\n",
    "    print(phone_map_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6185539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_remap(x):\n",
    "    return(x.replace(\"ː\",\"\").replace('ʌ','ə')\n",
    ".replace('ɪ','ə').replace('ɔ','ɑ').replace('a','ɑ').replace('o','oʊ').replace('˞','').replace('ʰ',\n",
    "    ''). replace('r','ɹ')).replace('\\\\^','').replace('\\\\ ̃','').replace(' ̩','').replace('^',''\n",
    ").replace('ʙ','b').replace('(','').replace(')','').replace('.','').replace('ch','ʧ'\n",
    ").replace('c','k').replace('g','ɡ').replace('y','j').replace('ʁ','ɹ')\n",
    "\n",
    "def strip_accents(string, accents=('COMBINING ACUTE ACCENT', \n",
    "    'COMBINING GRAVE ACCENT', 'COMBINING TILDE', 'COMBINING VERTICAL LINE BELOW',\n",
    "    'COMBINING SHORT STROKE OVERLAY')):\n",
    "    accents = set(map(unicodedata.lookup, accents))\n",
    "    chars = [c for c in unicodedata.normalize('NFD', string) if c not in accents]\n",
    "    return unicodedata.normalize('NFC', ''.join(chars))\n",
    "\n",
    "cv_map = dict(zip(phone_map_df['ipa'], phone_map_df['c_or_v']))\n",
    "cv_map['o'] = 'v' \n",
    "cv_map['ɜ'] = 'v'\n",
    "cv_map['e'] = 'v'\n",
    "cv_map['ʔ'] = 'c'\n",
    "cv_map['ɾ'] = 'c'\n",
    "cv_map['ɲ'] = 'c'\n",
    "cv_map['x'] = 'c'\n",
    "cv_map['ɱ'] = 'c'\n",
    "cv_map['ɣ'] = 'c'\n",
    "\n",
    "def cv_mapper(x, cv_map):\n",
    "    try:\n",
    "        return(cv_map[x])\n",
    "    except:\n",
    "        raise ValueError(x)\n",
    "\n",
    "cleaned_inflated_save = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated.pkl')\n",
    "\n",
    "if config.regenerate:    \n",
    "\n",
    "    # Do the same excludes as were used to identify appropriate utterances\n",
    "    excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "    all_tokens_phono.loc[all_tokens_phono.actual_phonology.isin(excludes),'actual_phonology'] =''\n",
    "    all_tokens_phono.loc[all_tokens_phono.actual_phonology.str.contains('V'),'actual_phonology'] =''\n",
    "    \n",
    "    # remap phonology from narrow phonetic transcription to broad phonological transcription\n",
    "    all_tokens_phono['model_phonology_clean'] = [phone_remap(x) for x in all_tokens_phono['model_phonology']]\n",
    "    all_tokens_phono['actual_phonology_clean'] = [phone_remap(x) for x in all_tokens_phono['actual_phonology']]\n",
    "\n",
    "    # remove any non-combining diacritical marks\n",
    "    all_tokens_phono['model_phonology_no_dia'] = [strip_accents(x) for x in \\\n",
    "    all_tokens_phono['model_phonology_clean']]\n",
    "    all_tokens_phono['actual_phonology_no_dia'] = [strip_accents(x) for x in \\\n",
    "    all_tokens_phono['actual_phonology_clean']]\n",
    "    \n",
    "    # Compute the number of non-contiguous vowels.\n",
    "    # slightly different than the cmu vowel computation ---\n",
    "    # because here we are computing it directly from IPA\n",
    "    all_tokens_phono['cv_raw'] = [''.join([cv_mapper(x, cv_map) for x in list(y)]) if y != '' else '' for y in all_tokens_phono['actual_phonology_no_dia']]    \n",
    "    all_tokens_phono['cv_collapsed']  = [re.sub(r'(.)\\1+', r'\\1', str(x)) if x != '' else '' for x in all_tokens_phono['cv_raw']]\n",
    "    all_tokens_phono['num_vowels'] = [np.sum(np.array(list(x)) == 'v') if x !='' else np.nan for x in all_tokens_phono['cv_collapsed']]\n",
    "    all_tokens_phono.to_pickle(cleaned_inflated_save)\n",
    "else:\n",
    "    all_tokens_phono = pd.read_pickle(cleaned_inflated_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7c4bf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>seq_utt_id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gloss, seq_utt_id, token]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono[all_tokens_phono.utterance_id == 16759250][['gloss', 'seq_utt_id', 'token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad0e67b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23         ɑmə\n",
      "55           ə\n",
      "125         wi\n",
      "128         ɑʊ\n",
      "131          u\n",
      "          ... \n",
      "2991834     oʊ\n",
      "2991835    wɑə\n",
      "2991836    liʔ\n",
      "2991849     lɑ\n",
      "2991850     lɑ\n",
      "Name: actual_phonology_no_dia, Length: 344267, dtype: object\n",
      "(2991865, 24)\n"
     ]
    }
   ],
   "source": [
    "if config.verbose:\n",
    "    # Why no actual phonology?\n",
    "    print(all_tokens_phono.loc[all_tokens_phono.actual_phonology_no_dia != '']['actual_phonology_no_dia'])\n",
    "    print(all_tokens_phono.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ddc2b4",
   "metadata": {},
   "source": [
    "### Identify the tokens that can be evaluated & Identify the subset of success and failure utterances that have transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a762bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that these raw\n",
    "\n",
    "successful_utt_ids = set(raw_success_utts['utterance_id']) \n",
    "\n",
    "initial_vocab_set = set(initial_vocab)\n",
    "yyy_utt_ids = set(raw_yyy_utts['utterance_id'])\n",
    "\n",
    "all_tokens_phono['in_vocab'] = all_tokens_phono['token'].isin(initial_vocab_set)\n",
    "\n",
    "# Added logic 7/23/21 here for in_vocab\n",
    "# Changed success_token to be sufficient on the entire requirements\n",
    "\n",
    "all_tokens_phono['success_token'] = [\n",
    "    ((x in successful_utt_ids) and (y) and (z <= 2) )\n",
    "    for x, y, z in zip(\n",
    "        all_tokens_phono['utterance_id'], # Check if has the right number of errors \n",
    "        all_tokens_phono['in_vocab'], # Enforce BERT and CMU requirement\n",
    "        all_tokens_phono['num_vowels'] # Enforce syllable and child requirement (this won't be populated if not CHI)\n",
    "    )]\n",
    "\n",
    "all_tokens_phono['yyy_token'] = [\n",
    "    (x in yyy_utt_ids) and (y == 'yyy') and (z <= 2)\n",
    "    for x, y, z in zip(\n",
    "        all_tokens_phono['utterance_id'], # Check if it has the right number of errors\n",
    "        all_tokens_phono['token'], # Check if it has the right gloss\n",
    "        all_tokens_phono['num_vowels'], # Enforce syllable and child requirement (this won't be populated if not CHI)\n",
    "        \n",
    "    )]\n",
    "\n",
    "# end added logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b62e95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono['partition'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad74ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.loc[(all_tokens_phono['success_token']), 'partition'] = 'success'     \n",
    "all_tokens_phono.loc[(all_tokens_phono['yyy_token']), 'partition'] = 'yyy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "300e5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none       2714806\n",
      "success     259819\n",
      "yyy          17240\n",
      "Name: partition, dtype: int64\n",
      "success shape (259819, 28)\n",
      "yyy shape (17240, 28)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "if config.verbose:\n",
    "    print(all_tokens_phono.partition.value_counts())\n",
    "    print('success shape', all_tokens_phono[all_tokens_phono['success_token']].shape)\n",
    "    print('yyy shape', all_tokens_phono[all_tokens_phono['yyy_token']].shape)\n",
    "    print(initial_tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b215fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.token == 'xxx','token_id'] = initial_tokenizer.unk_token_id\n",
    "all_tokens_phono.loc[all_tokens_phono.token == 'yyy','token_id'] = initial_tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bbea3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated_to_next_notebook.pkl')\n",
    "all_tokens_phono.to_pickle(final_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
