{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import join, exists\n",
    "\n",
    "import config\n",
    "np.random.seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_save_path = join(config.prov_csv_dir, 'csv/pvd_utt_glosses_phono_cleaned_inflated_to_next_notebook.pkl')\n",
    "\n",
    "if config.regenerate:\n",
    "    print('For re-generating final all_tokens_phono before splits, please see other notebook. Using cached values.')\n",
    "\n",
    "all_tokens_phono = all_tokens_phono.read_pickle(final_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the samples and splits for age/all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do this for each of success and yyy, then merge them together.\n",
    "\n",
    "for partition in ['success', 'yyy']:\n",
    "    \n",
    "    all_tokens_phono_valid = all_tokens_phono[all_tokens_phono.partition == partition]\n",
    "\n",
    "    # Split train/val/test: 25/50/50.\n",
    "\n",
    "    split_attr = 'transcript_id'\n",
    "\n",
    "    phono_train_val_idxs, phono_eval_idxs = split_gen.determine_split_idxs(all_tokens_phono_valid, split_attr, 0.5)\n",
    "\n",
    "    phono_train_val = all_tokens_phono_valid[all_tokens_phono_valid.transcript_id.isin(phono_train_val_idxs)]\n",
    "    phono_train_idxs, phono_val_idxs = split_gen.determine_split_idxs(phono_train_val, split_attr, 0.5)\n",
    "\n",
    "    for phase, idx_set in zip(['train', 'val', 'eval'], [phono_train_idxs, phono_val_idxs, phono_eval_idxs]):\n",
    "\n",
    "        # It's on transcript_id, not actual idx, so this is OK.\n",
    "        # all_tokens_phono will receive the val/eval phase marking where it applies.\n",
    "\n",
    "        this_phase_data, all_tokens_phono = split_gen.assign_and_find_phase_data(phase, split_attr, idx_set, all_tokens_phono, 'phase_sample')\n",
    "\n",
    "    all_tokens_phono = data_cleaning.augment_target_child_year(all_tokens_phono)\n",
    "\n",
    "# Below: For debugging only\n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval_before_child.pkl')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "young_phono, old_phono = split_gen.get_age_split_data(all_tokens_phono)\n",
    "\n",
    "phono_pool = [\n",
    "    all_tokens_phono,\n",
    "    young_phono,\n",
    "    old_phono,\n",
    "]\n",
    "\n",
    "model_args = [('all', 'all'), ('age', 'young'), ('age', 'old')]\n",
    "\n",
    "for (split_name, dataset_name), this_phono_raw in zip(model_args, phono_pool):\n",
    "    \n",
    "    print('Processing', split_name, dataset_name)\n",
    "    phono_phase = this_phono_raw[(this_phono_raw.phase_sample == 'val') & (this_phono_raw.partition == 'success')]\n",
    "\n",
    "    # age = None means don't filter on a given age\n",
    "    result_beta_sample = sampling.sample_successes('beta', split_name, dataset_name, None, phono_phase, 'val')        \n",
    "\n",
    "    print('\\tbeta sample', result_beta_sample.shape)\n",
    "\n",
    "\n",
    "# Dropping ages 0.5 and 4.0 because of data sparsity.\n",
    "# -- for 4.0 there is only one transcript so it's not possible to do a val/eval split.\n",
    "# -- for 1.0 it's possible to have a sample size of 1 or 0, which is too unstable.\n",
    "\n",
    "used_ages = data_cleaning.get_years(all_tokens_phono)\n",
    "\n",
    "assert (used_ages[0] == 0.5 and used_ages[-1] == 4.0)\n",
    "\n",
    "for age in used_ages[1:-1]:\n",
    "    \n",
    "    for phase in ['val', 'eval']:\n",
    "        \n",
    "        for sample_func, sample_name in zip([sampling.sample_successes, sampling.sample_yyy], ['success', 'yyy']):\n",
    "\n",
    "            print(f'for {sample_name}')\n",
    "\n",
    "            phono_phase = all_tokens_phono[(all_tokens_phono.phase_sample == phase) & (all_tokens_phono.partition == sample_name)]\n",
    "            this_age_sample = sample_func('models_across_time', None, None, age, phono_phase, phase)        \n",
    "\n",
    "            print('\\tage sample', this_age_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_attr = 'transcript_id'\n",
    "\n",
    "# 7/25/21: https://www.kite.com/python/answers/how-to-create-an-empty-column-in-a-pandas-dataframe-in-python\n",
    "all_tokens_phono['phase_child_sample'] = np.nan\n",
    "all_tokens_phono['phase_child_finetune'] = np.nan\n",
    "# end cite\n",
    "\n",
    "for name in child_models.get_child_names():\n",
    "    \n",
    "    ## -------- Restricted sampling section\n",
    "    \n",
    "    print(f'Processing: {name}')\n",
    "    \n",
    "    this_child_phono = all_tokens_phono[(all_tokens_phono.target_child_name == name)]\n",
    "    \n",
    "    this_success_phono = this_child_phono[this_child_phono.partition == 'success']\n",
    "    this_yyy_phono = this_child_phono[this_child_phono.partition == 'yyy']\n",
    "    \n",
    "    this_partition_folder = split_gen.get_split_folder('child', name, config.finetune_dir)\n",
    " \n",
    "    # Sample across ages\n",
    "    \n",
    "    success_idxs = child_split_gen.find_splits_across_ages(this_success_phono)\n",
    "    \n",
    "    yyy_idxs = child_split_gen.find_splits_across_ages(this_yyy_phono)\n",
    "\n",
    "    # Combine the proper indices into their phases and identify them\n",
    "    \n",
    "    complete_phase_idxs = {}\n",
    "    \n",
    "    for phase in ['train', 'val', 'eval']:\n",
    "        complete_phase_idxs[phase] = np.concatenate([success_idxs[phase], yyy_idxs[phase]])\n",
    "        \n",
    "    for phase_name, idx_set in complete_phase_idxs.items():\n",
    "        \n",
    "        # Make a new attribute for all_tokens_phono parallel to phase (which is the val/eval split defined above)\n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(phase_name, split_attr, idx_set, all_tokens_phono, phase_label = 'phase_child_sample')\n",
    "    \n",
    "    # Beta samples\n",
    "\n",
    "    val_success_pool = all_tokens_phono[\n",
    "        (all_tokens_phono.partition == 'success')\n",
    "        & (all_tokens_phono.target_child_name == name)\n",
    "        & (all_tokens_phono.transcript_id.isin(success_idxs['val']))\n",
    "    ]\n",
    "    \n",
    "    # Note: get_beta_idxs does NOT internally filter things.\n",
    "    # It's necessary to pass all_tokens_phono-based filtering because all_tokens_phono has the phase information\n",
    "    # associated with it.\n",
    "    val_sample = child_split_gen.get_beta_idxs(val_success_pool, 'transcript_id', 'val')\n",
    "    \n",
    "    this_path = sampling.get_sample_path('success', 'beta', 'child', name, eval_phase = 'val')\n",
    "    val_sample.to_csv(this_path)\n",
    "\n",
    "    print(f'\\tWriting beta samples for phase {phase}, to {this_path}, sample size: {val_sample.shape}')\n",
    "    \n",
    "    ## -------- Unrestricted sampling section\n",
    "    \n",
    "    # Identify everything that isn't in the sample.\n",
    "    \n",
    "    complete_sample_idxs = np.concatenate([complete_phase_idxs[phase] for phase in ['train', 'val', 'eval']])\n",
    "    \n",
    "    # Checked that all_tokens_phono is unfiltered pool of information.\n",
    "    \n",
    "    train_val_finetune_phono_new = all_tokens_phono[~all_tokens_phono.transcript_id.isin(complete_sample_idxs)]\n",
    "\n",
    "    train_val_finetune_phono_new = data_cleaning.drop_errors(train_val_finetune_phono_new)\n",
    "    # prepped glosses already done above in Pvd logic\n",
    "    \n",
    "    train_new_idxs, val_finetune_idxs = split_gen.determine_split_idxs(train_val_finetune_phono_new, 'transcript_id', val_ratio = config.val_ratio)\n",
    "    \n",
    "    # Note there's a slight bias in val_finetune, because they cannot be chosen from the scoreable successes/yyy\n",
    "    # But probably better than throwing away data or mixing train_sample and val_finetune\n",
    "\n",
    "    # Complete_phase_idxs['train'] still has some yyy in it.\n",
    "    # Isolate the parts of train_sample that can be merged with the finetune train phase.\n",
    "    \n",
    "    no_errors_phono = data_cleaning.drop_errors(all_tokens_phono)\n",
    "    train_sample_idxs_no_errors_pool = (no_errors_phono[no_errors_phono.transcript_id.isin(complete_phase_idxs['train'])])\n",
    "    \n",
    "    train_sample_idxs_no_errors = np.unique(train_sample_idxs_no_errors_pool.transcript_id)\n",
    "    \n",
    "    train_finetune_idxs = np.concatenate([train_new_idxs, train_sample_idxs_no_errors])\n",
    "    \n",
    "    ## Identify and write the finetune phases relative to partition information.\n",
    "    \n",
    "    for finetune_phase, finetune_idxs in zip(['train', 'val'], [train_finetune_idxs, val_finetune_idxs]):\n",
    "        \n",
    "        # This won't work because you need to eliminate duplicates.\n",
    "        all_tokens_phono, _ = split_gen.write_data_partitions_text(all_tokens_phono, this_partition_folder, finetune_phase, finetune_idxs, 'transcript_id', 'phase_child_finetune')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final all_tokens_phono with all split information to the proper place.\n",
    "\n",
    "if not exists(config.prov_dir):\n",
    "    os.makedirs(config.prov_dir)\n",
    "    \n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
