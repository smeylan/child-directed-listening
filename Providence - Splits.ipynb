{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7/2/21: https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# end cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import join, exists\n",
    "\n",
    "import config\n",
    "np.random.seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For re-generating final all_tokens_phono before splits, please see other notebook. Using cached values.\n"
     ]
    }
   ],
   "source": [
    "final_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated_to_next_notebook.pkl')\n",
    "\n",
    "if config.regenerate:\n",
    "    print('For re-generating final all_tokens_phono before splits, please see other notebook. Using cached values.')\n",
    "\n",
    "all_tokens_phono = pd.read_pickle(final_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_gen, sampling, data_cleaning, load_models, data_cleaning, transformers_bert_completions\n",
    "from utils_child import child_split_gen, child_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the samples and splits for age/all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do this for each of success and yyy, then merge them together.\n",
    "\n",
    "all_tokens_phono_valid = data_cleaning.find_transcripts_with_successes_and_yyy(all_tokens_phono)\n",
    "\n",
    "# Split train/val/test: 25/50/50.\n",
    "\n",
    "split_attr = 'transcript_id'\n",
    "\n",
    "phono_train_val_idxs, phono_eval_idxs = split_gen.determine_split_idxs(all_tokens_phono_valid, split_attr, 0.5)\n",
    "\n",
    "phono_train_val = all_tokens_phono_valid[all_tokens_phono_valid.transcript_id.isin(phono_train_val_idxs)]\n",
    "phono_train_idxs, phono_val_idxs = split_gen.determine_split_idxs(phono_train_val, split_attr, 0.5)\n",
    "\n",
    "for phase, idx_set in zip(['train', 'val', 'eval'], [phono_train_idxs, phono_val_idxs, phono_eval_idxs]):\n",
    "\n",
    "    # It's on transcript_id, not actual idx, so this is OK.\n",
    "    # all_tokens_phono will receive the val/eval phase marking where it applies.\n",
    "\n",
    "    this_phase_data, all_tokens_phono = split_gen.assign_and_find_phase_data(phase, split_attr, idx_set, all_tokens_phono, 'phase_sample')\n",
    "\n",
    "all_tokens_phono = data_cleaning.augment_target_child_year(all_tokens_phono)\n",
    "\n",
    "# Below: For debugging only\n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval_before_child.pkl')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all all\n",
      "Resampling for: task: beta, split: all, dataset: all, age: None, phase: val\n",
      "\tbeta sample (5000, 1)\n",
      "Processing age young\n",
      "Resampling for: task: beta, split: age, dataset: young, age: None, phase: val\n",
      "\tbeta sample (5000, 1)\n",
      "Processing age old\n",
      "Resampling for: task: beta, split: age, dataset: old, age: None, phase: val\n",
      "\tbeta sample (5000, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 0.5, phase: val\n",
      "\tage sample (1, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 0.5, phase: val\n",
      "\tage sample (1, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 0.5, phase: eval\n",
      "\tage sample (97, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 0.5, phase: eval\n",
      "\tage sample (101, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.0, phase: val\n",
      "\tage sample (2316, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.0, phase: val\n",
      "\tage sample (1343, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.0, phase: eval\n",
      "\tage sample (2691, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.0, phase: eval\n",
      "\tage sample (1921, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.5, phase: val\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.5, phase: val\n",
      "\tage sample (1060, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.5, phase: eval\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.5, phase: eval\n",
      "\tage sample (3253, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.0, phase: val\n",
      "\tage sample (4113, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.0, phase: val\n",
      "\tage sample (493, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.0, phase: eval\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.0, phase: eval\n",
      "\tage sample (1364, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.5, phase: val\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.5, phase: val\n",
      "\tage sample (669, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.5, phase: eval\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.5, phase: eval\n",
      "\tage sample (604, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.0, phase: val\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.0, phase: val\n",
      "\tage sample (262, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.0, phase: eval\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.0, phase: eval\n",
      "\tage sample (345, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.5, phase: val\n",
      "\tage sample (699, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.5, phase: val\n",
      "\tage sample (19, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.5, phase: eval\n",
      "\tage sample (1971, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.5, phase: eval\n",
      "\tage sample (49, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 4.0, phase: val\n",
      "\tage sample (379, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 4.0, phase: val\n",
      "\tage sample (2, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 4.0, phase: eval\n",
      "\tage sample (0, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 4.0, phase: eval\n",
      "\tage sample (0, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "young_phono, old_phono = split_gen.get_age_split_data(all_tokens_phono)\n",
    "\n",
    "phono_pool = [\n",
    "    all_tokens_phono,\n",
    "    young_phono,\n",
    "    old_phono,\n",
    "]\n",
    "\n",
    "model_args = [('all', 'all'), ('age', 'young'), ('age', 'old')]\n",
    "\n",
    "for (split_name, dataset_name), this_phono_raw in zip(model_args, phono_pool):\n",
    "    \n",
    "    print('Processing', split_name, dataset_name)\n",
    "    phono_phase = this_phono_raw[(this_phono_raw.phase_sample == 'val') & (this_phono_raw.partition == 'success')]\n",
    "\n",
    "    # age = None means don't filter on a given age\n",
    "    result_beta_sample = sampling.sample_successes('beta', split_name, dataset_name, None, phono_phase, 'val')        \n",
    "\n",
    "    print('\\tbeta sample', result_beta_sample.shape)\n",
    "\n",
    "\n",
    "# Handle sparse ages later in the pipeline, if any\n",
    "\n",
    "used_ages = data_cleaning.get_years(all_tokens_phono)\n",
    "\n",
    "for age in used_ages:\n",
    "    \n",
    "    for phase in ['val', 'eval']:\n",
    "        \n",
    "        for sample_func, sample_name in zip([sampling.sample_successes, sampling.sample_yyy], ['success', 'yyy']):\n",
    "\n",
    "            print(f'for {sample_name}')\n",
    "\n",
    "            phono_phase = all_tokens_phono[(all_tokens_phono.phase_sample == phase) & (all_tokens_phono.partition == sample_name)]\n",
    "            this_age_sample = sample_func('models_across_time', None, None, age, phono_phase, phase)        \n",
    "\n",
    "            print('\\tage sample', this_age_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Alex', 'Alex', 'Alex', 'Alex', 'Alex', 'Alex', 'Alex', 'Alex', 'Alex',\\n       'Alex',\\n       ...\\n       'William', 'William', 'William', 'William', 'William', 'William',\\n       'William', 'William', 'William', 'William'],\\n      dtype='object', length=2991865)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-52c2152886e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# end cite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tokens_phono\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_tokens_phono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_child_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mthis_partition_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_split_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'child'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Alex', 'Alex', 'Alex', 'Alex', 'Alex', 'Alex', 'Alex', 'Alex', 'Alex',\\n       'Alex',\\n       ...\\n       'William', 'William', 'William', 'William', 'William', 'William',\\n       'William', 'William', 'William', 'William'],\\n      dtype='object', length=2991865)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "split_attr = 'transcript_id'\n",
    "\n",
    "# 7/25/21: https://www.kite.com/python/answers/how-to-create-an-empty-column-in-a-pandas-dataframe-in-python\n",
    "all_tokens_phono['phase_child_sample'] = np.nan\n",
    "all_tokens_phono['phase_child_finetune'] = np.nan\n",
    "# end cite\n",
    "\n",
    "for name in sorted(list(set(all_tokens_phono.target_child_name))):\n",
    "    \n",
    "    this_partition_folder = split_gen.get_split_folder('child', name, config.finetune_dir)\n",
    "    \n",
    "    ## -------- Restricted sampling section\n",
    "    \n",
    "    print(f'Processing: {name}')\n",
    "    \n",
    "    this_child_phono = all_tokens_phono[(all_tokens_phono.target_child_name == name)]\n",
    "    \n",
    "    this_valid_phono = data_cleaning.find_transcripts_with_successes_and_yyy(this_child_phono)\n",
    " \n",
    "    # Sample across ages\n",
    "    \n",
    "    complete_phase_idxs = child_split_gen.find_splits_across_ages(this_valid_phono)\n",
    "        \n",
    "    for phase_name, idx_set in complete_phase_idxs.items():\n",
    "        \n",
    "        # Make a new attribute for all_tokens_phono parallel to phase (which is the val/eval split defined above)\n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(phase_name, split_attr, idx_set, all_tokens_phono, phase_label = 'phase_child_sample')\n",
    "    \n",
    "    # Beta samples\n",
    "    \n",
    "    val_success_pool = all_tokens_phono[\n",
    "        (all_tokens_phono.partition == 'success')\n",
    "        & (all_tokens_phono.target_child_name == name)\n",
    "        & (all_tokens_phono.phase_child_sample == 'val')\n",
    "    ]\n",
    "    \n",
    "    # Note: get_beta_idxs does NOT internally filter things.\n",
    "    # It's necessary to pass all_tokens_phono-based filtering because all_tokens_phono has the phase information\n",
    "    # associated with it.\n",
    "    \n",
    "    val_sample = child_split_gen.get_beta_idxs(val_success_pool, 'transcript_id')\n",
    "    \n",
    "    this_path = sampling.get_sample_path('success', 'beta', 'child', name, eval_phase = 'val')\n",
    "    val_sample.to_csv(this_path)\n",
    "\n",
    "    print(f'\\tWriting beta samples for phase {phase}, to {this_path}, sample size: {val_sample.shape}, pool size: {len(set(val_success_pool.utterance_id))}')\n",
    "    \n",
    "    ## -------- Unrestricted sampling section\n",
    "    \n",
    "    # Identify everything that isn't in the sample.\n",
    "    \n",
    "    complete_sample_idxs = np.concatenate([complete_phase_idxs[phase] for phase in ['train', 'val', 'eval']])\n",
    "    \n",
    "    # Checked that all_tokens_phono is unfiltered pool of information.\n",
    "    \n",
    "    train_val_finetune_phono_new = this_child_phono[~this_child_phono.transcript_id.isin(complete_sample_idxs)]\n",
    "\n",
    "    train_val_finetune_phono_new = data_cleaning.drop_errors(train_val_finetune_phono_new)\n",
    "    # prepped glosses already done above in Pvd logic\n",
    "    \n",
    "    train_merge_out_pool = {}\n",
    "    \n",
    "    avail_train_val_finetune_ids = set(train_val_finetune_phono_new.transcript_id)\n",
    "    num_train_val_finetune_new_ids = len(avail_train_val_finetune_ids)\n",
    "    \n",
    "    if num_train_val_finetune_new_ids >= 2:\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = split_gen.determine_split_idxs(train_val_finetune_phono_new, 'transcript_id', val_ratio = config.val_ratio)\n",
    "    elif num_train_val_finetune_new_ids == 1:\n",
    "        # Prioritize validation because train will receive a larger merge from the previous data.\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = np.array([]), np.array(list(avail_train_val_finetune_ids))\n",
    "    else:\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = np.array([]), np.array([])\n",
    "    \n",
    "    # Complete_phase_idxs still has some yyy in it.\n",
    "    # Isolate the parts of train_sample that can be merged with the finetune train phase.\n",
    "    \n",
    "    no_errors_phono = data_cleaning.drop_errors(this_child_phono)\n",
    "    \n",
    "    train_merge_in_pool = {}\n",
    "    for phase in ['train', 'val']:\n",
    "        train_merge_in_pool[phase] = np.unique(no_errors_phono[no_errors_phono.transcript_id.isin(complete_phase_idxs[phase])].transcript_id)\n",
    "    \n",
    "    finetune_idxs = {}\n",
    "    for phase in ['train', 'val']:\n",
    "        finetune_idxs[phase] = np.concatenate([train_merge_out_pool[phase], train_merge_in_pool[phase]])\n",
    "    \n",
    "    ## Identify and write the finetune phases relative to partition information.\n",
    "    \n",
    "    for finetune_phase, finetune_idx_set in finetune_idxs.items():\n",
    "        \n",
    "        split_gen.write_data_partitions_text(this_child_phono, this_partition_folder, finetune_phase, finetune_idx_set, 'transcript_id', 'phase_child_finetune')\n",
    "        \n",
    "        # Re-assign phase information all_tokens_phono\n",
    "        # because need to limit to this_child_phono above for the writing.\n",
    "        \n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(finetune_phase, split_attr, finetune_idx_set, all_tokens_phono, phase_label = 'phase_child_finetune')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final all_tokens_phono with all split information to the proper place.\n",
    "\n",
    "if not exists(config.prov_dir):\n",
    "    os.makedirs(config.prov_dir)\n",
    "    \n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
