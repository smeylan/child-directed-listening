{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import join, exists\n",
    "\n",
    "import config\n",
    "np.random.seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For re-generating final all_tokens_phono and utts_with_ages before splits, please see other notebook. Using cached values.\n"
     ]
    }
   ],
   "source": [
    "final_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated_to_next_notebook.pkl')\n",
    "\n",
    "if config.regenerate:\n",
    "    print('For re-generating final all_tokens_phono and utts_with_ages before splits, please see other notebook. Using cached values.')\n",
    "\n",
    "all_tokens_phono = pd.read_pickle(final_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_gen, sampling, data_cleaning, load_models, data_cleaning, transformers_bert_completions\n",
    "from utils_child import child_split_gen, child_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the samples and splits for age/all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do this for each of success and yyy, then merge them together.\n",
    "\n",
    "all_tokens_phono_valid = data_cleaning.find_transcripts_with_successes_and_yyy(all_tokens_phono)\n",
    "\n",
    "# Split train/val/test: 25/50/50.\n",
    "\n",
    "split_attr = 'transcript_id'\n",
    "\n",
    "phono_train_val_idxs, phono_eval_idxs = split_gen.determine_split_idxs(all_tokens_phono_valid, split_attr, 0.5)\n",
    "\n",
    "phono_train_val = all_tokens_phono_valid[all_tokens_phono_valid.transcript_id.isin(phono_train_val_idxs)]\n",
    "phono_train_idxs, phono_val_idxs = split_gen.determine_split_idxs(phono_train_val, split_attr, 0.5)\n",
    "\n",
    "for phase, idx_set in zip(['train', 'val', 'eval'], [phono_train_idxs, phono_val_idxs, phono_eval_idxs]):\n",
    "\n",
    "    # It's on transcript_id, not actual idx, so this is OK.\n",
    "    # all_tokens_phono will receive the val/eval phase marking where it applies.\n",
    "\n",
    "    this_phase_data, all_tokens_phono = split_gen.assign_and_find_phase_data(phase, split_attr, idx_set, all_tokens_phono, 'phase_sample')\n",
    "\n",
    "all_tokens_phono = data_cleaning.augment_target_child_year(all_tokens_phono)\n",
    "\n",
    "# Below: For debugging only\n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval_before_child.pkl')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all all\n",
      "Resampling for: task: beta, split: all, dataset: all, age: None, phase: val\n",
      "\tbeta sample (5000, 1)\n",
      "Processing age young\n",
      "Resampling for: task: beta, split: age, dataset: young, age: None, phase: val\n",
      "\tbeta sample (5000, 1)\n",
      "Processing age old\n",
      "Resampling for: task: beta, split: age, dataset: old, age: None, phase: val\n",
      "\tbeta sample (5000, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 0.5, phase: val\n",
      "\tage sample (1, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 0.5, phase: val\n",
      "\tage sample (1, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 0.5, phase: eval\n",
      "\tage sample (87, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 0.5, phase: eval\n",
      "\tage sample (105, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.0, phase: val\n",
      "\tage sample (1511, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.0, phase: val\n",
      "\tage sample (1521, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.0, phase: eval\n",
      "\tage sample (2364, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.0, phase: eval\n",
      "\tage sample (2369, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.5, phase: val\n",
      "\tage sample (3186, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.5, phase: val\n",
      "\tage sample (1890, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.5, phase: eval\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 1.5, phase: eval\n",
      "\tage sample (4524, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.0, phase: val\n",
      "\tage sample (4892, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.0, phase: val\n",
      "\tage sample (1412, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.0, phase: eval\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.0, phase: eval\n",
      "\tage sample (2971, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.5, phase: val\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.5, phase: val\n",
      "\tage sample (1149, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.5, phase: eval\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 2.5, phase: eval\n",
      "\tage sample (1994, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.0, phase: val\n",
      "\tage sample (3303, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.0, phase: val\n",
      "\tage sample (699, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.0, phase: eval\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.0, phase: eval\n",
      "\tage sample (810, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.5, phase: val\n",
      "\tage sample (745, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.5, phase: val\n",
      "\tage sample (85, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.5, phase: eval\n",
      "\tage sample (1580, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 3.5, phase: eval\n",
      "\tage sample (118, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 4.0, phase: val\n",
      "\tage sample (323, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 4.0, phase: val\n",
      "\tage sample (11, 1)\n",
      "for success\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 4.0, phase: eval\n",
      "\tage sample (0, 1)\n",
      "for yyy\n",
      "Resampling for: task: models_across_time, split: None, dataset: None, age: 4.0, phase: eval\n",
      "\tage sample (0, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "young_phono, old_phono = split_gen.get_age_split_data(all_tokens_phono)\n",
    "\n",
    "phono_pool = [\n",
    "    all_tokens_phono,\n",
    "    young_phono,\n",
    "    old_phono,\n",
    "]\n",
    "\n",
    "model_args = [('all', 'all'), ('age', 'young'), ('age', 'old')]\n",
    "\n",
    "for (split_name, dataset_name), this_phono_raw in zip(model_args, phono_pool):\n",
    "    \n",
    "    print('Processing', split_name, dataset_name)\n",
    "    phono_phase = this_phono_raw[(this_phono_raw.phase_sample == 'val') & (this_phono_raw.partition == 'success')]\n",
    "\n",
    "    # age = None means don't filter on a given age\n",
    "    result_beta_sample = sampling.sample_successes('beta', split_name, dataset_name, None, phono_phase, 'val')        \n",
    "\n",
    "    print('\\tbeta sample', result_beta_sample.shape)\n",
    "\n",
    "\n",
    "# Handle sparse ages later in the pipeline, if any\n",
    "\n",
    "used_ages = data_cleaning.get_years(all_tokens_phono)\n",
    "\n",
    "for age in used_ages:\n",
    "    \n",
    "    for phase in ['val', 'eval']:\n",
    "        \n",
    "        for sample_func, sample_name in zip([sampling.sample_successes, sampling.sample_yyy], ['success', 'yyy']):\n",
    "\n",
    "            print(f'for {sample_name}')\n",
    "\n",
    "            phono_phase = all_tokens_phono[(all_tokens_phono.phase_sample == phase) & (all_tokens_phono.partition == sample_name)]\n",
    "            this_age_sample = sample_func('models_across_time', None, None, age, phono_phase, phase)        \n",
    "\n",
    "            print('\\tage sample', this_age_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils_child.child_split_gen' from '/home/nwong/chompsky/childes/child_listening_split/child-directed-listening/utils_child/child_split_gen.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "importlib.reload(child_split_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['token', 'utterance_id', 'gloss', 'transcript_id', 'utterance_order',\n",
       "       'target_child_name', 'speaker_code', 'type', 'punct',\n",
       "       'speaker_code_simple', 'gloss_with_punct', 'token_id', 'seq_utt_id',\n",
       "       'actual_phonology', 'model_phonology', 'target_child_age',\n",
       "       'bert_token_id', 'model_phonology_clean', 'actual_phonology_clean',\n",
       "       'model_phonology_no_dia', 'actual_phonology_no_dia', 'cv_raw_actual',\n",
       "       'cv_collapsed_actual', 'num_vowels_actual', 'cv_raw_model',\n",
       "       'cv_collapsed_model', 'num_vowels_model', 'num_vowels', 'in_vocab',\n",
       "       'success_token', 'yyy_token', 'partition', 'phase_sample', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Alex\n",
      "\tWriting beta samples for phase eval, to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/prov/child/Alex/success_utts_beta_5000_val.csv, sample size: (2745, 1), pool size: 2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_split/child-directed-listening/utils/data_cleaning.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Alex/train.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Alex/train_no_tags.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Alex/val.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Alex/val_no_tags.txt\n",
      "Processing: Ethan\n",
      "\tWriting beta samples for phase val, to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/prov/child/Ethan/success_utts_beta_5000_val.csv, sample size: (1938, 1), pool size: 1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_split/child-directed-listening/utils/data_cleaning.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Ethan/train.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Ethan/train_no_tags.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Ethan/val.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Ethan/val_no_tags.txt\n",
      "Processing: Lily\n",
      "\tWriting beta samples for phase val, to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/prov/child/Lily/success_utts_beta_5000_val.csv, sample size: (4141, 1), pool size: 4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_split/child-directed-listening/utils/data_cleaning.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Lily/train.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Lily/train_no_tags.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Lily/val.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Lily/val_no_tags.txt\n",
      "Processing: Naima\n",
      "\tWriting beta samples for phase val, to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/prov/child/Naima/success_utts_beta_5000_val.csv, sample size: (3423, 1), pool size: 3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_split/child-directed-listening/utils/data_cleaning.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Naima/train.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Naima/train_no_tags.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Naima/val.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Naima/val_no_tags.txt\n",
      "Processing: Violet\n",
      "\tWriting beta samples for phase val, to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/prov/child/Violet/success_utts_beta_5000_val.csv, sample size: (2115, 1), pool size: 2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_split/child-directed-listening/utils/data_cleaning.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Violet/train.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Violet/train_no_tags.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Violet/val.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/Violet/val_no_tags.txt\n",
      "Processing: William\n",
      "\tWriting beta samples for phase val, to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/prov/child/William/success_utts_beta_5000_val.csv, sample size: (2944, 1), pool size: 2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_split/child-directed-listening/utils/data_cleaning.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/William/train.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/William/train_no_tags.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/William/val.txt\n",
      "File written to /home/nwong/chompsky/childes/child_listening_split/child-directed-listening/finetune/child/William/val_no_tags.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_attr = 'transcript_id'\n",
    "\n",
    "# 7/25/21: https://www.kite.com/python/answers/how-to-create-an-empty-column-in-a-pandas-dataframe-in-python\n",
    "all_tokens_phono['phase_child_sample'] = np.nan\n",
    "all_tokens_phono['phase_child_finetune'] = np.nan\n",
    "# end cite\n",
    "\n",
    "for name in sorted(list(set(all_tokens_phono.target_child_name))):\n",
    "    \n",
    "    this_partition_folder = split_gen.get_split_folder('child', name, config.finetune_dir)\n",
    "    \n",
    "    ## -------- Restricted sampling section\n",
    "    \n",
    "    print(f'Processing: {name}')\n",
    "    \n",
    "    this_child_phono = all_tokens_phono[(all_tokens_phono.target_child_name == name)]\n",
    "    \n",
    "    this_valid_phono = data_cleaning.find_transcripts_with_successes_and_yyy(this_child_phono)\n",
    " \n",
    "    # Sample across ages\n",
    "    \n",
    "    complete_phase_idxs = child_split_gen.find_splits_across_ages(this_valid_phono)\n",
    "        \n",
    "    for phase_name, idx_set in complete_phase_idxs.items():\n",
    "        \n",
    "        # Make a new attribute for all_tokens_phono parallel to phase (which is the val/eval split defined above)\n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(phase_name, split_attr, idx_set, all_tokens_phono, phase_label = 'phase_child_sample')\n",
    "    \n",
    "    # Beta samples\n",
    "    \n",
    "    val_success_pool = all_tokens_phono[\n",
    "        (all_tokens_phono.partition == 'success')\n",
    "        & (all_tokens_phono.target_child_name == name)\n",
    "        & (all_tokens_phono.phase_child_sample == 'val')\n",
    "    ]\n",
    "    \n",
    "    # Note: get_beta_idxs does NOT internally filter things.\n",
    "    # It's necessary to pass all_tokens_phono-based filtering because all_tokens_phono has the phase information\n",
    "    # associated with it.\n",
    "    \n",
    "    val_sample = child_split_gen.get_beta_idxs(val_success_pool, 'transcript_id')\n",
    "    \n",
    "    this_path = sampling.get_sample_path('success', 'beta', 'child', name, eval_phase = 'val')\n",
    "    val_sample.to_csv(this_path)\n",
    "\n",
    "    print(f'\\tWriting beta samples for phase {phase}, to {this_path}, sample size: {val_sample.shape}, pool size: {len(set(val_success_pool.utterance_id))}')\n",
    "    \n",
    "    ## -------- Unrestricted sampling section\n",
    "    \n",
    "    # Identify everything that isn't in the sample.\n",
    "    \n",
    "    complete_sample_idxs = np.concatenate([complete_phase_idxs[phase] for phase in ['train', 'val', 'eval']])\n",
    "    \n",
    "    # Checked that all_tokens_phono is unfiltered pool of information.\n",
    "    \n",
    "    train_val_finetune_phono_new = this_child_phono[~this_child_phono.transcript_id.isin(complete_sample_idxs)]\n",
    "\n",
    "    train_val_finetune_phono_new = data_cleaning.drop_errors(train_val_finetune_phono_new)\n",
    "    # prepped glosses already done above in Pvd logic\n",
    "    \n",
    "    train_merge_out_pool = {}\n",
    "    \n",
    "    avail_train_val_finetune_ids = set(train_val_finetune_phono_new.transcript_id)\n",
    "    num_train_val_finetune_new_ids = len(avail_train_val_finetune_ids)\n",
    "    \n",
    "    if num_train_val_finetune_new_ids >= 2:\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = split_gen.determine_split_idxs(train_val_finetune_phono_new, 'transcript_id', val_ratio = config.val_ratio)\n",
    "    elif num_train_val_finetune_new_ids == 1:\n",
    "        # Prioritize validation because train will receive a larger merge from the previous data.\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = np.array([]), np.array(list(avail_train_val_finetune_ids))\n",
    "    else:\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = np.array([]), np.array([])\n",
    "    \n",
    "    # Complete_phase_idxs still has some yyy in it.\n",
    "    # Isolate the parts of train_sample that can be merged with the finetune train phase.\n",
    "    \n",
    "    no_errors_phono = data_cleaning.drop_errors(this_child_phono)\n",
    "    \n",
    "    train_merge_in_pool = {}\n",
    "    for phase in ['train', 'val']:\n",
    "        train_merge_in_pool[phase] = np.unique(no_errors_phono[no_errors_phono.transcript_id.isin(complete_phase_idxs[phase])].transcript_id)\n",
    "    \n",
    "    finetune_idxs = {}\n",
    "    for phase in ['train', 'val']:\n",
    "        finetune_idxs[phase] = np.concatenate([train_merge_out_pool[phase], train_merge_in_pool[phase]])\n",
    "    \n",
    "    ## Identify and write the finetune phases relative to partition information.\n",
    "    \n",
    "    for finetune_phase, finetune_idx_set in finetune_idxs.items():\n",
    "        \n",
    "        split_gen.write_data_partitions_text(this_child_phono, this_partition_folder, finetune_phase, finetune_idx_set, 'transcript_id', 'phase_child_finetune')\n",
    "        \n",
    "        # Re-assign phase information all_tokens_phono\n",
    "        # because need to limit to this_child_phono above for the writing.\n",
    "        \n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(finetune_phase, split_attr, finetune_idx_set, all_tokens_phono, phase_label = 'phase_child_finetune')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.to_pickle('./scratch/prov_before_augment_subsampling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in augment with subsamples train 2 success Alex\n",
      "in augment with subsamples train 2 success Ethan\n",
      "in augment with subsamples train 2 success Lily\n",
      "in augment with subsamples train 2 success Naima\n",
      "in augment with subsamples train 2 success Violet\n",
      "in augment with subsamples train 2 success William\n",
      "in augment with subsamples train 2 yyy Alex\n",
      "in augment with subsamples train 2 yyy Ethan\n",
      "in augment with subsamples train 2 yyy Lily\n",
      "in augment with subsamples train 2 yyy Naima\n",
      "in augment with subsamples train 2 yyy Violet\n",
      "in augment with subsamples train 2 yyy William\n",
      "in augment with subsamples train 500 success Alex\n",
      "in augment with subsamples train 500 success Ethan\n",
      "in augment with subsamples train 500 success Lily\n",
      "in augment with subsamples train 500 success Naima\n",
      "in augment with subsamples train 500 success Violet\n",
      "in augment with subsamples train 500 success William\n",
      "in augment with subsamples train 500 yyy Alex\n",
      "in augment with subsamples train 500 yyy Ethan\n",
      "in augment with subsamples train 500 yyy Lily\n",
      "in augment with subsamples train 500 yyy Naima\n",
      "in augment with subsamples train 500 yyy Violet\n",
      "in augment with subsamples train 500 yyy William\n",
      "in augment with subsamples train 1000 success Alex\n",
      "in augment with subsamples train 1000 success Ethan\n",
      "in augment with subsamples train 1000 success Lily\n",
      "in augment with subsamples train 1000 success Naima\n",
      "in augment with subsamples train 1000 success Violet\n",
      "in augment with subsamples train 1000 success William\n",
      "in augment with subsamples train 1000 yyy Alex\n",
      "in augment with subsamples train 1000 yyy Ethan\n",
      "in augment with subsamples train 1000 yyy Lily\n",
      "in augment with subsamples train 1000 yyy Naima\n",
      "in augment with subsamples train 1000 yyy Violet\n",
      "in augment with subsamples train 1000 yyy William\n",
      "in augment with subsamples val 2 success Alex\n",
      "in augment with subsamples val 2 success Ethan\n",
      "in augment with subsamples val 2 success Lily\n",
      "in augment with subsamples val 2 success Naima\n",
      "in augment with subsamples val 2 success Violet\n",
      "in augment with subsamples val 2 success William\n",
      "in augment with subsamples val 2 yyy Alex\n",
      "in augment with subsamples val 2 yyy Ethan\n",
      "in augment with subsamples val 2 yyy Lily\n",
      "in augment with subsamples val 2 yyy Naima\n",
      "in augment with subsamples val 2 yyy Violet\n",
      "in augment with subsamples val 2 yyy William\n",
      "in augment with subsamples val 500 success Alex\n",
      "in augment with subsamples val 500 success Ethan\n",
      "in augment with subsamples val 500 success Lily\n",
      "in augment with subsamples val 500 success Naima\n",
      "in augment with subsamples val 500 success Violet\n",
      "in augment with subsamples val 500 success William\n",
      "in augment with subsamples val 500 yyy Alex\n",
      "in augment with subsamples val 500 yyy Ethan\n",
      "in augment with subsamples val 500 yyy Lily\n",
      "in augment with subsamples val 500 yyy Naima\n",
      "in augment with subsamples val 500 yyy Violet\n",
      "in augment with subsamples val 500 yyy William\n",
      "in augment with subsamples val 1000 success Alex\n",
      "in augment with subsamples val 1000 success Ethan\n",
      "in augment with subsamples val 1000 success Lily\n",
      "in augment with subsamples val 1000 success Naima\n",
      "in augment with subsamples val 1000 success Violet\n",
      "in augment with subsamples val 1000 success William\n",
      "in augment with subsamples val 1000 yyy Alex\n",
      "in augment with subsamples val 1000 yyy Ethan\n",
      "in augment with subsamples val 1000 yyy Lily\n",
      "in augment with subsamples val 1000 yyy Naima\n",
      "in augment with subsamples val 1000 yyy Violet\n",
      "in augment with subsamples val 1000 yyy William\n",
      "in augment with subsamples eval 2 success Alex\n",
      "in augment with subsamples eval 2 success Ethan\n",
      "in augment with subsamples eval 2 success Lily\n",
      "in augment with subsamples eval 2 success Naima\n",
      "in augment with subsamples eval 2 success Violet\n",
      "in augment with subsamples eval 2 success William\n",
      "in augment with subsamples eval 2 yyy Alex\n",
      "in augment with subsamples eval 2 yyy Ethan\n",
      "in augment with subsamples eval 2 yyy Lily\n",
      "in augment with subsamples eval 2 yyy Naima\n",
      "in augment with subsamples eval 2 yyy Violet\n",
      "in augment with subsamples eval 2 yyy William\n",
      "in augment with subsamples eval 500 success Alex\n",
      "in augment with subsamples eval 500 success Ethan\n",
      "in augment with subsamples eval 500 success Lily\n",
      "in augment with subsamples eval 500 success Naima\n",
      "in augment with subsamples eval 500 success Violet\n",
      "in augment with subsamples eval 500 success William\n",
      "in augment with subsamples eval 500 yyy Alex\n",
      "in augment with subsamples eval 500 yyy Ethan\n",
      "in augment with subsamples eval 500 yyy Lily\n",
      "in augment with subsamples eval 500 yyy Naima\n",
      "in augment with subsamples eval 500 yyy Violet\n",
      "in augment with subsamples eval 500 yyy William\n",
      "in augment with subsamples eval 1000 success Alex\n",
      "in augment with subsamples eval 1000 success Ethan\n",
      "in augment with subsamples eval 1000 success Lily\n",
      "in augment with subsamples eval 1000 success Naima\n",
      "in augment with subsamples eval 1000 success Violet\n",
      "in augment with subsamples eval 1000 success William\n",
      "in augment with subsamples eval 1000 yyy Alex\n",
      "in augment with subsamples eval 1000 yyy Ethan\n",
      "in augment with subsamples eval 1000 yyy Lily\n",
      "in augment with subsamples eval 1000 yyy Naima\n",
      "in augment with subsamples eval 1000 yyy Violet\n",
      "in augment with subsamples eval 1000 yyy William\n"
     ]
    }
   ],
   "source": [
    "# Mark the subsampling for the child cross scoring\n",
    "\n",
    "all_tokens_phono = child_split_gen.split_child_subsampling(all_tokens_phono)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final all_tokens_phono with all split information to the proper place.\n",
    "\n",
    "if not exists(config.prov_dir):\n",
    "    os.makedirs(config.prov_dir)\n",
    "    \n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-23 12:54:20.146901\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
