{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from utils import load_splits, split_gen\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SAVE_PATH = 'eval/new_splits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_marked_pooled_data(this_split_path):\n",
    "    return pd.read_csv(join(this_split_path, 'data_pool_with_phases.csv'))\n",
    "\n",
    "def check_disjoint_and_phase_written(split, name, base_dir):\n",
    "    \"\"\"\n",
    "    Checks that the phase data indicated per entry corresponds to the written text in the file.\n",
    "    By nature of the phase marks the data pool will be split disjointly.\n",
    "    \"\"\"\n",
    "    \n",
    "    this_split_loc = split_gen.get_split_folder(split, name, base_dir)\n",
    "    this_pool_data = load_marked_pooled_data(this_split_loc)\n",
    "    \n",
    "    if split == 'child':\n",
    "        data_cleaning.drop_errors(this_pool_data) # Don't consider the yyy, which are not written to the text files.\n",
    "        assert this_pool_data[this_pool_data.gloss == 'yyy'].phase == 'val'\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        phase_locs = this_pool_data[this_pool_data['phase'] == phase]\n",
    "        with open(join(this_split_loc, f\"{phase}.txt\"), 'r') as f:\n",
    "            from_text_text = sorted([l.strip() for l in f.readlines()]) # Get rid of trailing \\n\n",
    "        \n",
    "        from_df_text = sorted(list(phase_locs['gloss_with_punct']))\n",
    "        \n",
    "        assert from_text_text == from_df_text, f'Failed to match phase data for: {split}, {name}, {phase}'\n",
    "    \n",
    "    print(f'Assert passed for {split}, {name}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(load_splits)\n",
    "\n",
    "entire_dataset_dict = load_splits.load_eval_data_all('all', 'all', BASE_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to check that the samples are all <= 36 months for young, old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3418: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert passed for all, all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Disjoint sets for \"all\" split\n",
    "\n",
    "#all_split_paths = load_splits.load_splits_folder_text('all', 'data/new_splits')\n",
    "#assert len(all_split_paths) == 1\n",
    "\n",
    "check_disjoint_and_phase_written('all', 'all', 'data/new_splits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asserts passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for correct age splitting within the evaluation data\n",
    "young_df_dict = load_splits.load_eval_data_all('age', 'young', BASE_SAVE_PATH)\n",
    "old_df_dict = load_splits.load_eval_data_all('age', 'old', BASE_SAVE_PATH)\n",
    "\n",
    "# Convert to months, the comparison in the code is in months but it's converted from days for each comparison\n",
    "assert all(all((young_df_dict[k]['target_child_age'] / 30.5) <= 36) for k in young_df_dict.keys()) \n",
    "assert all(all((old_df_dict[k]['target_child_age'] / 30.5) > 36) for k in old_df_dict.keys())\n",
    "\n",
    "print(\"asserts passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed asserts\n"
     ]
    }
   ],
   "source": [
    "# Disjoint sets for young, old, and merge to form whole dataset in the evaluation data.\n",
    "# This runs really slow so terminating for now,\n",
    " \n",
    "for k in young_df_dict.keys():\n",
    "    \n",
    "    # This is not quite right -- you have to drop all of the NaNs that are \n",
    "    sort_by_cols = sort_on[k] # Just trying to get them to be the same sorted order\n",
    "    this_entire_data = entire_dataset_dict[k]\n",
    "    \n",
    "    # 7/1/21: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
    "    # This makes a copy of the data.\n",
    "    this_entire_data_filtered = this_entire_data.dropna(subset=['target_child_age'])\n",
    "    \n",
    "    concat_df = pd.concat([young_df_dict[k], old_df_dict[k]])\n",
    "    \n",
    "    # Make sure there are no internal duplicates\n",
    "    # 7/1/21: https://thispointer.com/pandas-find-duplicate-rows-in-a-dataframe-based-on-all-or-selected-columns-using-dataframe-duplicated-in-python/\n",
    "    assert (not any(this_entire_data_filtered.duplicated())) and (not any(concat_df.duplicated()))\n",
    "    \n",
    "    # Then, check if the two dataframes are the same\n",
    "    # 7/1/21: https://stackoverflow.com/questions/48647534/python-pandas-find-difference-between-two-data-frames\n",
    "    assert pd.concat([concat_df[this_entire_data_filtered.columns],this_entire_data_filtered]).drop_duplicates(keep=False).shape[0] == 0\n",
    "    \n",
    "print(\"passed asserts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3338: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3418: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert passed for age, old\n",
      "Assert passed for age, young\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct ages for the training/val data.\n",
    "\n",
    "print('started')\n",
    "\n",
    "marked_pooled_old = load_marked_pooled_data(split_gen.get_split_folder('age', 'old', 'data/new_splits'))\n",
    "marked_pooled_young = load_marked_pooled_data(split_gen.get_split_folder('age', 'young', 'data/new_splits'))\n",
    "\n",
    "# Convert to months\n",
    "assert all(age / 30.5 > 36 for age in marked_pooled_old.target_child_age)\n",
    "assert all(age / 30.5 <= 36 for age in marked_pooled_young.target_child_age) \n",
    "\n",
    "\n",
    "# Check for disjointedness within each of the age splits for train/val data.\n",
    "\n",
    "check_disjoint_and_phase_written('age', 'old', 'data/new_splits')\n",
    "check_disjoint_and_phase_written('age', 'young', 'data/new_splits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Come back to child work after finishing age-based work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = ['William', 'Alex', 'Violet', 'Naima', 'Ethan', 'Lily']\n",
    "\n",
    "# 1) Data always addresses the relevant child\n",
    "all_child_data = {}\n",
    "for name in names:\n",
    "    this_info_dict = load_splits.load_eval_data_all('child', name, BASE_SAVE_PATH)\n",
    "    assert all(all(this_info_dict[k]['target_child_name'] == name) for k in this_info_dict.keys())\n",
    "    all_child_data[name] = this_info_dict\n",
    "\n",
    "# 2) Check that child data merges to the entire dataset\n",
    "for k in entire_dataset_dict.keys():\n",
    "    \n",
    "    this_entire_data = entire_dataset_dict[k].sort_values('utterance_id')\n",
    "    concat_df = pd.concat([all_child_data[n][k] for n in names])\n",
    "\n",
    "    assert concat_df.equals(this_entire_data)\n",
    "    \n",
    "# 3) The child splits are disjoint across the train and val data\n",
    "\n",
    "for name in names:\n",
    "    check_disjoint_and_phase_written('child', name, BASE_SAVE_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
