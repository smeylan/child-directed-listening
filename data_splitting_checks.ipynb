{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from utils import load_splits, split_gen, data_cleaning\n",
    "from utils_child import child_models, child_split_gen\n",
    "\n",
    "import config\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sampled_proper_attributes(phono, utt_id_set):\n",
    "    \n",
    "    \"\"\"\n",
    "    Ensures that a given df with tokens that are part of a sample follow the proper attributes\n",
    "    (actual_phonology and model_phonology are populated, and CHI utterance)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = phono[phono.utterance_id.isin(utt_id_set)]\n",
    "    \n",
    "    assert all(df.speaker_code_simple == '[CHI]')\n",
    "    assert has_phonology(df)\n",
    "    assert has_success_or_yyy(df) # Also checked for more stringent criteria later (has success and yyy)\n",
    "    \n",
    "def check_chi_cgv_present(this_df):\n",
    "    this_codes = set(this_df.speaker_code)\n",
    "    assert this_codes.issubset({'CHI', 'FAT', 'MOT'}) and this_codes != {'CHI'}\n",
    "        \n",
    "def load_marked_pooled_data(this_split_path):\n",
    "    return pd.read_pickle(join(this_split_path, 'data_pool_with_phases.pkl'))\n",
    "\n",
    "def check_disjoint_and_phase_written(split, name, base_dir, which_phase):\n",
    "    \"\"\"\n",
    "    Checks that the phase data indicated per entry corresponds to the written text in the file.\n",
    "    \"\"\"\n",
    "    \n",
    "    this_split_loc = split_gen.get_split_folder(split, name, base_dir)\n",
    "    \n",
    "    if split in {'all', 'age'}:\n",
    "        \n",
    "        this_all_loc = split_gen.get_split_folder('all', 'all', base_dir)\n",
    "        this_pool_data = data_cleaning.drop_errors(load_marked_pooled_data(this_all_loc))\n",
    "        if name == 'young':\n",
    "            this_pool_data, _ = split_gen.get_age_split_data(this_pool_data)\n",
    "        if name == 'old':\n",
    "            _, this_pool_data = split_gen.get_age_split_data(this_pool_data)\n",
    "            \n",
    "    if split == 'child':\n",
    "        \n",
    "        # Check that the train/val text files are as expected\n",
    "        #     they match the right phase as marked in the df\n",
    "        #     they match the right child\n",
    "        #     they don't contain errors\n",
    "\n",
    "        this_pool_data = data_cleaning.drop_errors(load_splits.load_phono())\n",
    "        this_pool_data = this_pool_data[(this_pool_data.target_child_name == name)]\n",
    "        this_pool_data = this_pool_data[['utterance_id', 'gloss_with_punct', 'phase_child_finetune']].drop_duplicates()\n",
    "        \n",
    "    for phase in ['train', 'val']:\n",
    "        phase_locs = this_pool_data[this_pool_data[which_phase] == phase]\n",
    "        with open(join(this_split_loc, f\"{phase}.txt\"), 'r') as f:\n",
    "            from_text_text = sorted([l.strip() for l in f.readlines()]) # Get rid of trailing \\n\n",
    "        \n",
    "        from_df_text = sorted(list(phase_locs['gloss_with_punct']))\n",
    "        \n",
    "        assert from_text_text == from_df_text, f'Failed to match phase data for: {split}, {name}, {phase}'\n",
    "    \n",
    "        # Extra checks after first iteration\n",
    "        assert all('xxx' not in s for s in from_text_text)\n",
    "        assert all('yyy' not in s for s in from_text_text)\n",
    "        \n",
    "        assert '[CHI] .\\n' not in set(from_text_text)\n",
    "        assert '[CGV] .\\n' not in set(from_text_text)\n",
    "    \n",
    "    print(f'Assert passed for {split}, {name}')\n",
    "    return True\n",
    "\n",
    "\n",
    "def has_phonology(df):\n",
    "    \n",
    "    def non_empty(entry, attribute):\n",
    "        return any(entry != '')\n",
    "    \n",
    "    actual = df.groupby('utterance_id').actual_phonology.agg(lambda x : non_empty(x, 'actual_phonology')).reset_index()\n",
    "    \n",
    "    return all(actual.actual_phonology)\n",
    "    \n",
    "def has_this(collect, token_type):\n",
    "    return (token_type in set(collect))\n",
    "\n",
    "def give_success(df):\n",
    "    return df.groupby('utterance_id').partition.agg(lambda x : has_this(x, 'success')).reset_index()\n",
    "\n",
    "def give_yyy(df):\n",
    "    return df.groupby('utterance_id').partition.agg(lambda x : has_this(x, 'yyy')).reset_index()\n",
    "    \n",
    "def has_success(df):\n",
    "    return all(give_success(df).partition)\n",
    "\n",
    "def has_yyy(df):\n",
    "    return all(give_yyy(df).partition)\n",
    "\n",
    "def has_success_or_yyy(df):\n",
    "    \n",
    "    success_df = give_success(df)\n",
    "    yyy_df = give_yyy(df)\n",
    "    \n",
    "    either = success_df.partition | yyy_df.partition\n",
    "    \n",
    "    return all(either)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_names = child_models.get_child_names()\n",
    "\n",
    "all_phono = pd.read_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval.pkl'))\n",
    "\n",
    "phases = ['train', 'val', 'eval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks to ensure fixes from incorrect iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# Check that there are no errors in partition == 'success' utterance_id\n",
    "\n",
    "final_utts_save_path = join(config.prov_csv_dir, 'utts_with_ages.csv')\n",
    "\n",
    "utts_with_ages = pd.read_csv(final_utts_save_path)\n",
    "\n",
    "# Find the subsets of partition-based successes and yyy\n",
    "\n",
    "success_ids = set(all_phono[all_phono.partition == 'success'].utterance_id)\n",
    "yyy_ids = set(all_phono[all_phono.partition == 'yyy'].utterance_id)\n",
    "\n",
    "success_phono = all_phono[all_phono.utterance_id.isin(success_ids)]\n",
    "yyy_phono = all_phono[all_phono.utterance_id.isin(yyy_ids)]\n",
    "\n",
    "# Check that utterances that are sampled are appropriate -- they are all in the right set of utterance ids\n",
    "\n",
    "success_ages_utts_id = set(utts_with_ages[utts_with_ages.set == 'success'].utterance_id)\n",
    "yyy_ages_utts_id = set(utts_with_ages[utts_with_ages.set == 'failure'].utterance_id)\n",
    "\n",
    "# Check that success partition markings have utterance ids that are all part of utts_with_ages success\n",
    "# Check the same for yyy\n",
    "\n",
    "assert success_ids.issubset(success_ages_utts_id)\n",
    "assert yyy_ids.issubset(yyy_ages_utts_id)\n",
    "\n",
    "# Check that there are no yyy tokens or xxx tokens in the things marked as success or yyy\n",
    "\n",
    "success_tokens = set(success_phono['token'])\n",
    "yyy_tokens = set(yyy_phono['token'])\n",
    "\n",
    "assert not any(success_phono['token'] == 'yyy')\n",
    "assert not any(success_phono['token'] == 'xxx')\n",
    "\n",
    "assert not any(yyy_phono['token'] == 'xxx')\n",
    "\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Providence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert passed for all, all\n",
      "Assert passed for age, young\n",
      "Assert passed for age, old\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Are the training/text files disjoint for non-Providence?\n",
    "\n",
    "check_disjoint_and_phase_written('all', 'all', config.finetune_dir, 'phase_finetune')\n",
    "check_disjoint_and_phase_written('age', 'young', config.finetune_dir, 'phase_finetune')\n",
    "check_disjoint_and_phase_written('age', 'old', config.finetune_dir, 'phase_finetune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# Make sure that [CHI], [CGV] are present in the model inputs\n",
    "    \n",
    "folder = split_gen.get_split_folder('all', 'all', config.finetune_dir)\n",
    "\n",
    "all_df = load_marked_pooled_data(folder)\n",
    "young_df, old_df = split_gen.get_age_split_data(all_df)\n",
    "\n",
    "for s, d in config.childes_model_args:\n",
    "    \n",
    "    if d == 'old':\n",
    "        this_df = old_df\n",
    "    if d == 'young':\n",
    "        this_df = young_df\n",
    "    if d == 'all':\n",
    "        this_df = all_df\n",
    "            \n",
    "    check_chi_cgv_present(this_df)\n",
    "\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot mask with non-boolean array containing NA / NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-05a49db10e34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mavail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_phono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutterance_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0msel_phono\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_phono\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_phono\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mnum_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_phono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutterance_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'For n: over all phases {n}, {num_sel} / {avail}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Should be approx. 3x the n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0;31m# Don't raise on e.g. [\"A\", \"B\", np.nan], see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0;31m#  test_loc_getitem_list_of_labels_categoricalindex_with_na\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot mask with non-boolean array containing NA / NaN values"
     ]
    }
   ],
   "source": [
    "# Check proper functioning for the sampling\n",
    "\n",
    "for n in config.subsamples:\n",
    "    for phase in phases:\n",
    "        for this_type in ['yyy', 'success']:\n",
    "            for name in child_names:\n",
    "                attr = child_split_gen.get_subsample_key(n, this_type, name)\n",
    "                avail = len(set(all_phono.utterance_id))\n",
    "\n",
    "                sel_phono = all_phono[all_phono[attr]]\n",
    "                num_sel = len(set(sel_phono.utterance_id))\n",
    "                print(f'For n: over all phases {n}, {num_sel} / {avail}') # Should be approx. 3x the n\n",
    "\n",
    "                assert set(sel_phono.target_child_name) == {name}\n",
    "                assert set(sel_phono.partition) == {this_type, 'none'}\n",
    "                # Above: Is possible to have non-scoreable tokens in a single utterance marked for scoring.\n",
    "                \n",
    "                assert set(sel_phono.phase_child_sample) == {phase}\n",
    "                assert not any(all_phono[attr].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying: Alex\n",
      "Assert passed for child, Alex\n",
      "Verifying: Ethan\n",
      "Assert passed for child, Ethan\n",
      "Verifying: Lily\n",
      "Assert passed for child, Lily\n",
      "Verifying: Naima\n",
      "Assert passed for child, Naima\n",
      "Verifying: Violet\n",
      "Assert passed for child, Violet\n",
      "Verifying: William\n",
      "Assert passed for child, William\n"
     ]
    }
   ],
   "source": [
    "# Check the text files for disjointedness (necessary because it splits on a different phase label)\n",
    "# Note this also checks the correctness of train and val partition.\n",
    "\n",
    "for name in child_names:\n",
    "    print(f\"Verifying: {name}\")\n",
    "    check_disjoint_and_phase_written('child', name, config.finetune_dir, which_phase = 'phase_child_finetune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n",
      "Size of phase in transcripts 90\n",
      "\tfor success, number of unique transcripts: 90\n",
      "\tfor yyy, number of unique transcripts: 90\n",
      "Size of phase in transcripts 90\n",
      "\tfor success, number of unique transcripts: 90\n",
      "\tfor yyy, number of unique transcripts: 90\n",
      "Size of phase in transcripts 179\n",
      "\tfor success, number of unique transcripts: 179\n",
      "\tfor yyy, number of unique transcripts: 179\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Check that train, val, eval are disjoint for the age/all splits.\n",
    "\n",
    "phase_set = {}\n",
    "\n",
    "for phase in phases:\n",
    "    phase_set[phase] = set(all_phono[all_phono['phase_sample'] == phase].transcript_id)\n",
    "\n",
    "for p1 in phases:\n",
    "    for p2 in phases:\n",
    "        if p1 == p2 : continue\n",
    "        assert not (phase_set[p1] & phase_set[p2]), f'Overlap for {p1} and {p2}'\n",
    "\n",
    "print('Passed')\n",
    "\n",
    "# For phase sample, for each of success and yyy,\n",
    "# there should be a 25/50/50 split on transcript ids for each of these,\n",
    "# that is about equal for success and yyy\n",
    "\n",
    "for phase in phases:\n",
    "    \n",
    "    print('Size of phase in transcripts', len(set(all_phono[all_phono['phase_sample'] == phase].transcript_id)))\n",
    "    \n",
    "    for part_type in ['success', 'yyy']:\n",
    "        \n",
    "        success_ids_num = len(set(all_phono[all_phono.transcript_id.isin(phase_set[phase]) & (all_phono.partition == part_type)].transcript_id))\n",
    "        print(f'\\tfor {part_type}, number of unique transcripts:', success_ids_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed asserts\n"
     ]
    }
   ],
   "source": [
    "# Make sure that all of the eval and val data are separate for across_time_samples\n",
    "\n",
    "all_time_samples = glob.glob(join(config.prov_dir, 'across_time_samples/*'))\n",
    "\n",
    "val_ids = set(pd.concat([pd.read_csv(path) for path in all_time_samples if '_val' in path]).utterance_id)\n",
    "eval_ids = set(pd.concat([pd.read_csv(path) for path in all_time_samples if '_eval' in path]).utterance_id)\n",
    "\n",
    "val_phases = set(all_phono[all_phono.utterance_id.isin(val_ids)].phase_sample)\n",
    "eval_phases = set(all_phono[all_phono.utterance_id.isin(eval_ids)].phase_sample)\n",
    "\n",
    "assert val_phases == {'val'}\n",
    "assert eval_phases == {'eval'}\n",
    "\n",
    "sampled_proper_attributes(all_phono, val_ids | eval_ids)\n",
    "\n",
    "print('Passed asserts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Phase: val\n",
      "For success\n",
      "Sample shapes\n",
      "\t\tNumber of total utterances in all pool: (1, 2)\n",
      "\t\tNumber of total utterances in all pool: (1511, 2)\n",
      "\t\tNumber of total utterances in all pool: (3186, 2)\n",
      "\t\tNumber of total utterances in all pool: (4892, 2)\n",
      "\t\tNumber of total utterances in all pool: (5000, 2)\n",
      "\t\tNumber of total utterances in all pool: (3303, 2)\n",
      "\t\tNumber of total utterances in all pool: (745, 2)\n",
      "\t\tNumber of total utterances in all pool: (323, 2)\n",
      "For yyy\n",
      "Sample shapes\n",
      "\t\tNumber of total utterances in all pool: (1, 2)\n",
      "\t\tNumber of total utterances in all pool: (1521, 2)\n",
      "\t\tNumber of total utterances in all pool: (1890, 2)\n",
      "\t\tNumber of total utterances in all pool: (1412, 2)\n",
      "\t\tNumber of total utterances in all pool: (1149, 2)\n",
      "\t\tNumber of total utterances in all pool: (699, 2)\n",
      "\t\tNumber of total utterances in all pool: (85, 2)\n",
      "\t\tNumber of total utterances in all pool: (11, 2)\n",
      "******************** Phase: eval\n",
      "For success\n",
      "Sample shapes\n",
      "\t\tNumber of total utterances in all pool: (87, 2)\n",
      "\t\tNumber of total utterances in all pool: (2364, 2)\n",
      "\t\tNumber of total utterances in all pool: (5000, 2)\n",
      "\t\tNumber of total utterances in all pool: (5000, 2)\n",
      "\t\tNumber of total utterances in all pool: (5000, 2)\n",
      "\t\tNumber of total utterances in all pool: (5000, 2)\n",
      "\t\tNumber of total utterances in all pool: (1580, 2)\n",
      "\t\tNumber of total utterances in all pool: (0, 2)\n",
      "For yyy\n",
      "Sample shapes\n",
      "\t\tNumber of total utterances in all pool: (105, 2)\n",
      "\t\tNumber of total utterances in all pool: (2369, 2)\n",
      "\t\tNumber of total utterances in all pool: (4524, 2)\n",
      "\t\tNumber of total utterances in all pool: (2971, 2)\n",
      "\t\tNumber of total utterances in all pool: (1994, 2)\n",
      "\t\tNumber of total utterances in all pool: (810, 2)\n",
      "\t\tNumber of total utterances in all pool: (118, 2)\n",
      "\t\tNumber of total utterances in all pool: (0, 2)\n"
     ]
    }
   ],
   "source": [
    "# For the used ages, check the following:\n",
    "\n",
    "# there are approx 5000 of them (by utterance id!)\n",
    "#     some may have fewer because of data sparsity.\n",
    "\n",
    "# per EACH of successes and yyy\n",
    "# And, they correspond to the right splits (the one in their name)\n",
    "\n",
    "for phase in ['val', 'eval']:\n",
    "    \n",
    "    print('*'*20, f\"Phase: {phase}\")\n",
    "    \n",
    "    for data_type, data_func in zip(['success', 'yyy'], [load_splits.get_age_success_sample_paths, load_splits.get_age_yyy_sample_paths]):\n",
    "\n",
    "        print(f'For {data_type}')\n",
    "        all_paths = data_func(phase = phase)\n",
    "        all_samples = [ pd.read_csv(p) for p in all_paths ]\n",
    "\n",
    "        sample_ids = set(pd.concat(all_samples).utterance_id)\n",
    "\n",
    "        print('Sample shapes')\n",
    "        for sample in all_samples:\n",
    "            print(f'\\t\\tNumber of total utterances in all pool: {sample.shape}')\n",
    "\n",
    "        this_phono = all_phono[all_phono.utterance_id.isin(sample_ids)]\n",
    "        if data_type == 'success':\n",
    "            assert has_success(this_phono)\n",
    "        else:\n",
    "            assert has_yyy(this_phono)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Make sure:\n",
    "# The young data is actually young data\n",
    "# The old data is actually old data\n",
    "\n",
    "old_ids = set(pd.read_csv(join(split_gen.get_split_folder('age', 'old', config.prov_dir), 'success_utts_beta_5000_val.csv')).utterance_id)\n",
    "assert all(all_phono[all_phono.utterance_id.isin(old_ids)].target_child_age > config.age_split * 30.5)\n",
    "\n",
    "young_ids = set(pd.read_csv(join(split_gen.get_split_folder('age', 'young', config.prov_dir), 'success_utts_beta_5000_val.csv')).utterance_id)\n",
    "assert all(all_phono[all_phono.utterance_id.isin(young_ids)].target_child_age <= config.age_split * 30.5)\n",
    "\n",
    "print('Passed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for phase_sample\n",
      "Passed asserts\n",
      "Dataset all all\n",
      "\tNumber of utterances: 5000\n",
      "Dataset age young\n",
      "\tNumber of utterances: 5000\n",
      "Dataset age old\n",
      "\tNumber of utterances: 4371\n",
      "Checking for phase_child_sample\n",
      "Passed asserts\n",
      "Dataset child Alex\n",
      "\tNumber of utterances: 2745\n",
      "Dataset child Ethan\n",
      "\tNumber of utterances: 1938\n",
      "Dataset child Lily\n",
      "\tNumber of utterances: 4141\n",
      "Dataset child Naima\n",
      "\tNumber of utterances: 3423\n",
      "Dataset child Violet\n",
      "\tNumber of utterances: 2115\n",
      "Dataset child William\n",
      "\tNumber of utterances: 2944\n"
     ]
    }
   ],
   "source": [
    "# For the beta samples,\n",
    "# they are all successes\n",
    "# there is approx 5000 of them (by utterance id!)\n",
    "# they all have phase == 'val'\n",
    "\n",
    "def check_beta_samples(arg_set, phase_label):\n",
    "    \n",
    "    print(f'Checking for {phase_label}')\n",
    "    \n",
    "    all_beta_samples = [\n",
    "        pd.read_csv(join(split_gen.get_split_folder(s, d, config.prov_dir), 'success_utts_beta_5000_val.csv'))\n",
    "        for s, d in arg_set\n",
    "    ]\n",
    "\n",
    "    beta_ids = set(pd.concat(all_beta_samples).utterance_id)\n",
    "    sel_phono = all_phono[all_phono.utterance_id.isin(beta_ids)]\n",
    "    beta_phases = set(sel_phono[phase_label])\n",
    "\n",
    "    assert beta_phases == {'val'}\n",
    "    assert has_success(sel_phono)\n",
    "    \n",
    "    # You should have at least one success per utterance, but not all tokens have to be marked as a success.\n",
    "\n",
    "    print('Passed asserts')\n",
    "\n",
    "    for (s, d), (beta_sample) in zip(arg_set, all_beta_samples):\n",
    "        print('Dataset', s, d)\n",
    "        print(f'\\tNumber of utterances: {len(set(beta_sample.utterance_id))}')\n",
    "        \n",
    "    sampled_proper_attributes(all_phono, beta_ids)\n",
    "    \n",
    "check_beta_samples(config.childes_model_args, 'phase_sample')\n",
    "check_beta_samples([('child', name) for name in child_names], 'phase_child_sample')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing across time for split: all, all\n",
      "     year\n",
      "0.5     1\n",
      "4.0    74\n",
      "3.5   162\n",
      "1.0   406\n",
      "3.0   830\n",
      "1.5   831\n",
      "2.0  1249\n",
      "2.5  1447\n",
      "Analyzing across time for split: age, young\n",
      "     year\n",
      "1.0   498\n",
      "1.5  1056\n",
      "2.0  1646\n",
      "2.5  1800\n",
      "Analyzing across time for split: age, old\n",
      "     year\n",
      "4.0   323\n",
      "3.5   745\n",
      "3.0  3303\n",
      "Analyzing across time for split: child, Alex\n",
      "     year\n",
      "1.0    19\n",
      "1.5   381\n",
      "2.0   446\n",
      "2.5   871\n",
      "3.0  1028\n",
      "Analyzing across time for split: child, Ethan\n",
      "     year\n",
      "0.5    29\n",
      "2.5   362\n",
      "2.0   431\n",
      "1.5   499\n",
      "1.0   617\n",
      "Analyzing across time for split: child, Lily\n",
      "     year\n",
      "1.0    50\n",
      "1.5   621\n",
      "3.5   690\n",
      "2.0   740\n",
      "2.5   975\n",
      "3.0  1065\n",
      "Analyzing across time for split: child, Naima\n",
      "     year\n",
      "3.5   272\n",
      "1.0   425\n",
      "3.0   593\n",
      "2.0   656\n",
      "2.5   705\n",
      "1.5   772\n",
      "Analyzing across time for split: child, Violet\n",
      "     year\n",
      "1.0    11\n",
      "3.0   135\n",
      "1.5   235\n",
      "3.5   464\n",
      "2.5   615\n",
      "2.0   655\n",
      "Analyzing across time for split: child, William\n",
      "     year\n",
      "1.0    63\n",
      "1.5   305\n",
      "2.5   570\n",
      "2.0   771\n",
      "3.0  1235\n"
     ]
    }
   ],
   "source": [
    "# Check if my samples are sufficiently across time (beta)\n",
    "\n",
    "all_beta_args = config.childes_model_args + [('child', name) for name in child_names]\n",
    "\n",
    "for (s, d) in all_beta_args:\n",
    "    \n",
    "    print(f'Analyzing across time for split: {s}, {d}')\n",
    "    this_sample = set(pd.read_csv(join(split_gen.get_split_folder(s, d, config.prov_dir), 'success_utts_beta_5000_val.csv')).utterance_id)\n",
    "    \n",
    "    # Select utterances in the beta sample\n",
    "    sel = all_phono[all_phono.utterance_id.isin(this_sample)][['utterance_id', 'year']].drop_duplicates()\n",
    "    \n",
    "    # Year actually means counts of certain years, not the years themselves.\n",
    "    counts = sel.year.value_counts().to_frame().sort_values('year')\n",
    "    \n",
    "    print(counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asserts passed.\n"
     ]
    }
   ],
   "source": [
    "# Make sure the child train/val/eval data is separate within child\n",
    "# Note this no longer requires/uses the constraint that child val/eval matches the overall val/eval.\n",
    "\n",
    "\n",
    "for attr, phase_set in zip(['phase_child_sample', 'phase_child_finetune'], [phases[:], ['train', 'val']]):\n",
    "                                                                            \n",
    "    for name in child_names:\n",
    "\n",
    "        child_pool = all_phono[all_phono.target_child_name == name]\n",
    "        ids = {}\n",
    "        \n",
    "        for phase in phase_set:\n",
    "            ids[phase] = set(child_pool[child_pool[attr] == phase].utterance_id)\n",
    "\n",
    "        for p1 in phase_set:\n",
    "            for p2 in phase_set:\n",
    "                if p1 == p2: continue\n",
    "                assert len(ids[p1] & ids[p2]) == 0, f'{attr}, {p1}, {p2}'\n",
    "    \n",
    "print('Asserts passed.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of phase: train 181\n",
      "Size of phase: val 86\n",
      "Size of phase: eval 92\n",
      "Size of phase: train 183\n",
      "Size of phase: val 89\n",
      "For child: Alex\n",
      "\tFor phase: eval\n",
      "\t\tFor age: 1.0, Number of transcripts: 2\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 3\n",
      "\tFor phase: val\n",
      "\t\tFor age: 1.0, Number of transcripts: 1\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 3\n",
      "For child: Ethan\n",
      "\tFor phase: eval\n",
      "\t\tFor age: 0.5, Number of transcripts: 1\n",
      "\t\tFor age: 1.0, Number of transcripts: 3\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\tFor phase: val\n",
      "\t\tFor age: 0.5, Number of transcripts: 1\n",
      "\t\tFor age: 1.0, Number of transcripts: 3\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "For child: Lily\n",
      "\tFor phase: eval\n",
      "\t\tFor age: 1.0, Number of transcripts: 3\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 3\n",
      "\t\tFor age: 3.5, Number of transcripts: 3\n",
      "\t\tFor age: 4.0, Number of transcripts: 1\n",
      "\tFor phase: val\n",
      "\t\tFor age: 1.0, Number of transcripts: 3\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 3\n",
      "\t\tFor age: 3.5, Number of transcripts: 2\n",
      "For child: Naima\n",
      "\tFor phase: eval\n",
      "\t\tFor age: 0.5, Number of transcripts: 1\n",
      "\t\tFor age: 1.0, Number of transcripts: 3\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 2\n",
      "\t\tFor age: 3.5, Number of transcripts: 1\n",
      "\tFor phase: val\n",
      "\t\tFor age: 1.0, Number of transcripts: 3\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 2\n",
      "\t\tFor age: 3.5, Number of transcripts: 1\n",
      "For child: Violet\n",
      "\tFor phase: eval\n",
      "\t\tFor age: 1.0, Number of transcripts: 3\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 2\n",
      "\t\tFor age: 3.5, Number of transcripts: 3\n",
      "\tFor phase: val\n",
      "\t\tFor age: 1.0, Number of transcripts: 2\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 1\n",
      "\t\tFor age: 3.5, Number of transcripts: 3\n",
      "For child: William\n",
      "\tFor phase: eval\n",
      "\t\tFor age: 1.0, Number of transcripts: 1\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 3\n",
      "\tFor phase: val\n",
      "\t\tFor age: 1.0, Number of transcripts: 1\n",
      "\t\tFor age: 1.5, Number of transcripts: 3\n",
      "\t\tFor age: 2.0, Number of transcripts: 3\n",
      "\t\tFor age: 2.5, Number of transcripts: 3\n",
      "\t\tFor age: 3.0, Number of transcripts: 3\n",
      "Passed automatic checks, manual behavior verifications are above.\n"
     ]
    }
   ],
   "source": [
    "# Other quick checks\n",
    "\n",
    "# Size of the train relative to val, eval for Providence\n",
    "# For all/all, age/old, age/young\n",
    "\n",
    "phase_data = {}\n",
    "\n",
    "for phase_type, phase_set in zip(['phase_child_sample', 'phase_child_finetune'], [phases[:], ['train', 'val']]):\n",
    "    for phase in phase_set:\n",
    "        print(f'Size of phase: {phase}', len(set(all_phono[all_phono[phase_type] == phase].transcript_id)))\n",
    "    \n",
    "\n",
    "# Make sure that there is a spread of age sampling for test\n",
    "# And also val\n",
    "\n",
    "for name in child_names:\n",
    "    \n",
    "    name_pool = all_phono[all_phono.target_child_name == name]\n",
    "    \n",
    "    print(f'For child: {name}')\n",
    "    for phase in ['eval', 'val']:\n",
    "        \n",
    "        print(f'\\tFor phase: {phase}')\n",
    "        this_pool = name_pool[name_pool.phase_child_sample == phase]\n",
    "        # But, you need this per transcript.\n",
    "        \n",
    "        all_ages = data_cleaning.get_years(this_pool)\n",
    "        \n",
    "        # For the val/eval samples \n",
    "        # There is about the right number of transcripts for eval and val (print out the numbers)\n",
    "\n",
    "        for age in all_ages: \n",
    "            \n",
    "            this_sel_df = this_pool[this_pool.year == age]\n",
    "            \n",
    "            get_num_transcripts = lambda df : len(set(df.transcript_id))\n",
    "            all_num = get_num_transcripts(this_sel_df)\n",
    "            success_num = get_num_transcripts(this_sel_df[this_sel_df.partition == \"success\"])\n",
    "            yyy_num = get_num_transcripts(this_sel_df[this_sel_df.partition == \"yyy\"])\n",
    "            \n",
    "            # Request one transcript with both present.\n",
    "            # Expected behavior below for revised sampling with success and yyy present constraint.\n",
    "            \n",
    "            print(f'\\t\\tFor age: {age}, Number of transcripts: {all_num}')\n",
    "            \n",
    "            assert success_num == yyy_num == all_num\n",
    "            assert 1 <= all_num <= 3\n",
    "         \n",
    "print('Passed automatic checks, manual behavior verifications are above.')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Child work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# The phases are all disjoint\n",
    "\n",
    "phase_dict = defaultdict(dict)\n",
    "\n",
    "for phase_type, phase_set in zip(['phase_child_sample', 'phase_child_finetune'], [phases[:], ['train', 'val']]):\n",
    "    \n",
    "    for phase in phase_set:\n",
    "        phase_dict[phase_type][phase] = set(all_phono[all_phono[phase_type] == phase].transcript_id)\n",
    "        \n",
    "    # train/val/eval in phase_child_sample, as well as phase_child_finetune\n",
    "    this_type_dict = phase_dict[phase_type]\n",
    "    for p1 in phase_set:\n",
    "        for p2 in phase_set:\n",
    "            if p1 == p2: continue\n",
    "            assert not (this_type_dict[p1] & this_type_dict[p2])\n",
    "\n",
    "# The finetune phases are all disjoint from val/eval phases in sample\n",
    "# The train_sample phase is in the finetune_phase\n",
    "\n",
    "finetune_disjoint = phase_dict['phase_child_finetune']['train'] | phase_dict['phase_child_finetune']['val']\n",
    "sample_disjoint = phase_dict['phase_child_sample']['eval']\n",
    "\n",
    "\n",
    "# 7/25/21: https://www.geeksforgeeks.org/issubset-in-python/\n",
    "for phase in ['train', 'val']:\n",
    "    valid_for_finetune_partial = (phase_dict['phase_child_sample'][phase]) & set(data_cleaning.drop_errors(all_phono).transcript_id)\n",
    "    assert valid_for_finetune_partial.issubset(phase_dict['phase_child_finetune'][phase])\n",
    "# end cite\n",
    "\n",
    "assert len(finetune_disjoint & sample_disjoint) == 0\n",
    "    \n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "for name in child_names:\n",
    "    for phase in ['train', 'val']:\n",
    "        # Make sure there is cgv, chi in both phases for child data finetuning\n",
    "        rel_df = all_phono[(all_phono.target_child_name == name) & (all_phono.phase_child_finetune == phase)]\n",
    "        check_chi_cgv_present(rel_df)\n",
    "        \n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed for phase_child_sample, phase: train\n",
      "Passed for phase_child_sample, phase: val\n",
      "Passed for phase_child_sample, phase: test\n",
      "Passed for phase_sample, phase: train\n",
      "Passed for phase_sample, phase: val\n",
      "Passed for phase_sample, phase: test\n",
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# Write a check to ensure that if phase_child_sample (or phase_sample) then\n",
    "# every transcript contains both at least one yyy and at least one success\n",
    "\n",
    "def has_success_and_yyy(this_attr):\n",
    "\n",
    "    for phase in ['train', 'val', 'test']:\n",
    "        \n",
    "        has_phase = all_phono[all_phono[this_attr] == phase]\n",
    "\n",
    "        has_success_phase = set(has_phase[has_phase.partition == 'success'].transcript_id)\n",
    "        has_yyy_phase = set(has_phase[has_phase.partition == 'yyy'].transcript_id)\n",
    "        gen_phase = set(has_phase.transcript_id)\n",
    "\n",
    "        # Note: no constraint on at least one yyy and at least one success for the finetune data.\n",
    "\n",
    "        assert has_success_phase == has_yyy_phase == gen_phase\n",
    "\n",
    "        print(f'Passed for {this_attr}, phase: {phase}')\n",
    "\n",
    "has_success_and_yyy('phase_child_sample')\n",
    "has_success_and_yyy('phase_sample')\n",
    "\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the ages are correctly sampled across time.\n",
    "\n",
    "all_time_samples = glob.glob(join(config.prov_dir, 'across_time_samples/*'))\n",
    "\n",
    "for year in data_cleaning.get_years(all_phono):\n",
    "    \n",
    "    age_ids = set(pd.concat([pd.read_csv(path) for path in all_time_samples if str(year) in path]).utterance_id)\n",
    "    \n",
    "    assert set(all_phono[all_phono.utterance_id.isin(age_ids)].year) == {year}\n",
    "\n",
    "\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-02 08:01:45.614089\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
