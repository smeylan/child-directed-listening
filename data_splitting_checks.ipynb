{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7/22/21: https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# end cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from utils import load_splits, split_gen, data_cleaning\n",
    "from utils_child import child_models\n",
    "\n",
    "import config\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sampled_proper_attributes(phono, utt_id_set):\n",
    "    \n",
    "    \"\"\"\n",
    "    Ensures that a given df with tokens that are part of a sample follow the proper attributes\n",
    "    (actual_phonology and model_phonology are populated, and CHI utterance)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = phono[phono.utterance_id.isin(utt_id_set)]\n",
    "    \n",
    "    assert all(df.speaker_code_simple == '[CHI]')\n",
    "    assert has_phonology(df)\n",
    "    assert has_success_or_yyy(df)\n",
    "    \n",
    "def check_chi_cgv_present(this_df):\n",
    "    this_codes = set(this_df.speaker_code)\n",
    "    assert this_codes.issubset({'CHI', 'FAT', 'MOT'}) and this_codes != {'CHI'}\n",
    "        \n",
    "def load_marked_pooled_data(this_split_path):\n",
    "    return pd.read_pickle(join(this_split_path, 'data_pool_with_phases.pkl'))\n",
    "\n",
    "def check_disjoint_and_phase_written(split, name, base_dir, which_phase = 'phase'):\n",
    "    \"\"\"\n",
    "    Checks that the phase data indicated per entry corresponds to the written text in the file.\n",
    "    \"\"\"\n",
    "    \n",
    "    this_split_loc = split_gen.get_split_folder(split, name, base_dir)\n",
    "    \n",
    "    if split in {'all', 'age'}:\n",
    "        \n",
    "        this_all_loc = split_gen.get_split_folder('all', 'all', base_dir)\n",
    "        this_pool_data = load_marked_pooled_data(this_all_loc)\n",
    "        if name == 'young':\n",
    "            this_pool_data, _ = split_gen.get_age_split_data(this_pool_data)\n",
    "        if name == 'old':\n",
    "            _, this_pool_data = split_gen.get_age_split_data(this_pool_data)\n",
    "            \n",
    "    #if split == 'child':\n",
    "    #    this_pool_data = load_splits.load_phono()\n",
    "    #    this_pool_data = this_pool_data[(this_pool_data.target_child_name == name) & (this_pool_data.speaker_code == 'CHI')]\n",
    "        \n",
    "    for phase in ['train', 'val']:\n",
    "        phase_locs = this_pool_data[this_pool_data[which_phase] == phase]\n",
    "        with open(join(this_split_loc, f\"{phase}.txt\"), 'r') as f:\n",
    "            from_text_text = sorted([l.strip() for l in f.readlines()]) # Get rid of trailing \\n\n",
    "        \n",
    "        from_df_text = sorted(list(phase_locs['gloss_with_punct']))\n",
    "        \n",
    "        assert from_text_text == from_df_text, f'Failed to match phase data for: {split}, {name}, {phase}'\n",
    "    \n",
    "    print(f'Assert passed for {split}, {name}')\n",
    "    return True\n",
    "\n",
    "\n",
    "def has_phonology(df):\n",
    "    \n",
    "    def non_empty(entry, attribute):\n",
    "        return any(entry != '')\n",
    "    actual = df.groupby('utterance_id').actual_phonology.agg(lambda x : non_empty(x, 'actual_phonology')).reset_index()\n",
    "    #model = df.groupby('utterance_id').model_phonology.agg(lambda x : non_empty(x, 'model_phonology')).reset_index()\n",
    "    \n",
    "    return all(actual.actual_phonology)# & model.model_phonology) \n",
    "    \n",
    "def has_this(collect, token_type):\n",
    "    return (token_type in set(collect))\n",
    "\n",
    "def give_success(df):\n",
    "    return df.groupby('utterance_id').partition.agg(lambda x : has_this(x, 'success')).reset_index()\n",
    "\n",
    "def give_yyy(df):\n",
    "    return df.groupby('utterance_id').partition.agg(lambda x : has_this(x, 'yyy')).reset_index()\n",
    "    \n",
    "def has_success(df):\n",
    "    return all(give_success(df).partition)\n",
    "\n",
    "def has_yyy(df):\n",
    "    return all(give_yyy(df).partition)\n",
    "\n",
    "def has_success_or_yyy(df):\n",
    "    \n",
    "    success_df = give_success(df)\n",
    "    yyy_df = give_yyy(df)\n",
    "    \n",
    "    either = success_df.partition | yyy_df.partition\n",
    "    \n",
    "    return all(either)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_names = child_models.get_child_names()\n",
    "\n",
    "all_phono = pd.read_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval.pkl'))\n",
    "\n",
    "phases = ['train', 'val', 'eval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Providence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert passed for all, all\n",
      "Assert passed for age, young\n",
      "Assert passed for age, old\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Are the training/text files disjoint for non-Providence?\n",
    "\n",
    "check_disjoint_and_phase_written('all', 'all', config.finetune_dir, which_phase = 'phase_finetune')\n",
    "check_disjoint_and_phase_written('age', 'young', config.finetune_dir, which_phase = 'phase_finetune')\n",
    "check_disjoint_and_phase_written('age', 'old', config.finetune_dir, which_phase = 'phase_finetune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FAT', 'CHI', 'MOT'}\n",
      "Child tags: 1640520 CGV tags: 2319432\n",
      "{'FAT', 'CHI', 'MOT'}\n",
      "Child tags: 985752 CGV tags: 1560943\n",
      "{'FAT', 'CHI', 'MOT'}\n",
      "Child tags: 618718 CGV tags: 639542\n",
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# Make sure that [CHI], [CGV] are present in the model inputs\n",
    "    \n",
    "folder = split_gen.get_split_folder('all', 'all', config.finetune_dir)\n",
    "\n",
    "all_df = load_marked_pooled_data(folder)\n",
    "young_df, old_df = split_gen.get_age_split_data(all_df)\n",
    "\n",
    "for s, d in config.childes_model_args:\n",
    "    \n",
    "    if d == 'old':\n",
    "        this_df = old_df\n",
    "    if d == 'young':\n",
    "        this_df = young_df\n",
    "    if d == 'all':\n",
    "        this_df = all_df\n",
    "            \n",
    "    check_chi_cgv_present(this_df)\n",
    "\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying: William\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'this_pool_data' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1dbe6397991c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Verifying: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcheck_disjoint_and_phase_written\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'child'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'phase_child_finetune'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-72e57734eac6>\u001b[0m in \u001b[0;36mcheck_disjoint_and_phase_written\u001b[0;34m(split, name, base_dir, which_phase)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mphase_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_pool_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_pool_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich_phase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_split_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{phase}.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mfrom_text_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get rid of trailing \\n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'this_pool_data' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Check the text files for disjointedness (necessary because it splits on a different phase label)\n",
    "# Note this also checks the correctness of train and val partition.\n",
    "\n",
    "# The train/val text files are as expected\n",
    "#     they match the right phase as marked in the df (determine if this is hard to check with the current function)\n",
    "#     they match the right child\n",
    "#     they don't contain errors (you can check this via the all_tokens_phono if possible)\n",
    "#     they are about the right size (80/20-ish it won't be exact), on transcript ids.\n",
    "\n",
    "for name in child_names:\n",
    "    \n",
    "    print(f\"Verifying: {name}\")\n",
    "    check_disjoint_and_phase_written('child', name, config.finetune_dir, which_phase = 'phase_child_finetune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n",
      "Size of phase in transcripts 92\n",
      "\tfor success, number of unique transcripts: 91\n",
      "\tfor yyy, number of unique transcripts: 88\n",
      "Size of phase in transcripts 90\n",
      "\tfor success, number of unique transcripts: 90\n",
      "\tfor yyy, number of unique transcripts: 87\n",
      "Size of phase in transcripts 182\n",
      "\tfor success, number of unique transcripts: 179\n",
      "\tfor yyy, number of unique transcripts: 176\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Shouldn't the size of transcripts id be the same for yyy and success?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-157818013907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tfor {part_type}, number of unique transcripts:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess_ids_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Shouldn't the size of transcripts id be the same for yyy and success?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Shouldn't the size of transcripts id be the same for yyy and success?"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Check that train, val, eval are disjoint for the age/all splits.\n",
    "\n",
    "phase_set = {}\n",
    "\n",
    "for phase in phases:\n",
    "    phase_set[phase] = set(all_phono[all_phono['phase_sample'] == phase].transcript_id)\n",
    "\n",
    "for p1 in phases:\n",
    "    for p2 in phases:\n",
    "        if p1 == p2 : continue\n",
    "        assert not (phase_set[p1] & phase_set[p2]), f'Overlap for {p1} and {p2}'\n",
    "\n",
    "print('Passed')\n",
    "\n",
    "# For phase sample, for each of success and yyy,\n",
    "# there should be a 25/50/50 split on transcript ids for each of these,\n",
    "# that is about equal for success and yyy\n",
    "\n",
    "for phase in phases:\n",
    "    \n",
    "    print('Size of phase in transcripts', len(set(all_phono[all_phono['phase_sample'] == phase].transcript_id)))\n",
    "    \n",
    "    for part_type in ['success', 'yyy']:\n",
    "        \n",
    "        success_ids_num = len(set(all_phono[all_phono.transcript_id.isin(phase_set[phase]) & (all_phono.partition == part_type)].transcript_id))\n",
    "        print(f'\\tfor {part_type}, number of unique transcripts:', success_ids_num)\n",
    "\n",
    "assert False, \"Shouldn't the size of transcripts id be the same for yyy and success?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed asserts\n"
     ]
    }
   ],
   "source": [
    "# Make sure that all of the eval and val data are separate for across_time_samples\n",
    "\n",
    "all_time_samples = glob.glob(join(config.prov_dir, 'across_time_samples/*'))\n",
    "\n",
    "val_ids = set(pd.concat([pd.read_csv(path) for path in all_time_samples if '_val' in path]).utterance_id)\n",
    "eval_ids = set(pd.concat([pd.read_csv(path) for path in all_time_samples if '_eval' in path]).utterance_id)\n",
    "\n",
    "val_phases = set(all_phono[all_phono.utterance_id.isin(val_ids)].phase_sample)\n",
    "eval_phases = set(all_phono[all_phono.utterance_id.isin(eval_ids)].phase_sample)\n",
    "\n",
    "assert val_phases == {'val'}\n",
    "assert eval_phases == {'eval'}\n",
    "\n",
    "sampled_proper_attributes(all_phono, val_ids | eval_ids)\n",
    "\n",
    "print('Passed asserts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Phase: val\n",
      "For success\n",
      "Sample shapes\n",
      "\t(1, 2)\n",
      "\t\tNumber of total transcripts in all pool: (1, 2)\n",
      "\t(2316, 2)\n",
      "\t\tNumber of total transcripts in all pool: (2316, 2)\n",
      "\t(5000, 2)\n",
      "\t\tNumber of total transcripts in all pool: (5000, 2)\n",
      "\t(4113, 2)\n",
      "\t\tNumber of total transcripts in all pool: (4113, 2)\n",
      "\t(5000, 2)\n",
      "\t\tNumber of total transcripts in all pool: (5000, 2)\n",
      "\t(5000, 2)\n",
      "\t\tNumber of total transcripts in all pool: (5000, 2)\n",
      "\t(699, 2)\n",
      "\t\tNumber of total transcripts in all pool: (699, 2)\n",
      "\t(379, 2)\n",
      "\t\tNumber of total transcripts in all pool: (379, 2)\n",
      "For yyy\n",
      "Sample shapes\n",
      "\t(1, 2)\n",
      "\t\tNumber of total transcripts in all pool: (1, 2)\n",
      "\t(1343, 2)\n",
      "\t\tNumber of total transcripts in all pool: (1343, 2)\n",
      "\t(1060, 2)\n",
      "\t\tNumber of total transcripts in all pool: (1060, 2)\n",
      "\t(493, 2)\n",
      "\t\tNumber of total transcripts in all pool: (493, 2)\n",
      "\t(669, 2)\n",
      "\t\tNumber of total transcripts in all pool: (669, 2)\n",
      "\t(262, 2)\n",
      "\t\tNumber of total transcripts in all pool: (262, 2)\n",
      "\t(19, 2)\n",
      "\t\tNumber of total transcripts in all pool: (19, 2)\n",
      "\t(2, 2)\n",
      "\t\tNumber of total transcripts in all pool: (2, 2)\n",
      "******************** Phase: eval\n",
      "For success\n",
      "Sample shapes\n",
      "\t(97, 2)\n",
      "\t\tNumber of total transcripts in all pool: (97, 2)\n",
      "\t(2691, 2)\n",
      "\t\tNumber of total transcripts in all pool: (2691, 2)\n",
      "\t(5000, 2)\n",
      "\t\tNumber of total transcripts in all pool: (5000, 2)\n",
      "\t(5000, 2)\n",
      "\t\tNumber of total transcripts in all pool: (5000, 2)\n",
      "\t(5000, 2)\n",
      "\t\tNumber of total transcripts in all pool: (5000, 2)\n",
      "\t(5000, 2)\n",
      "\t\tNumber of total transcripts in all pool: (5000, 2)\n",
      "\t(2336, 2)\n",
      "\t\tNumber of total transcripts in all pool: (2336, 2)\n",
      "\t(0, 2)\n",
      "\t\tNumber of total transcripts in all pool: (0, 2)\n",
      "For yyy\n",
      "Sample shapes\n",
      "\t(101, 2)\n",
      "\t\tNumber of total transcripts in all pool: (101, 2)\n",
      "\t(2410, 2)\n",
      "\t\tNumber of total transcripts in all pool: (2410, 2)\n",
      "\t(3253, 2)\n",
      "\t\tNumber of total transcripts in all pool: (3253, 2)\n",
      "\t(1364, 2)\n",
      "\t\tNumber of total transcripts in all pool: (1364, 2)\n",
      "\t(604, 2)\n",
      "\t\tNumber of total transcripts in all pool: (604, 2)\n",
      "\t(345, 2)\n",
      "\t\tNumber of total transcripts in all pool: (345, 2)\n",
      "\t(49, 2)\n",
      "\t\tNumber of total transcripts in all pool: (49, 2)\n",
      "\t(0, 2)\n",
      "\t\tNumber of total transcripts in all pool: (0, 2)\n"
     ]
    }
   ],
   "source": [
    "# For the used ages, check the following:\n",
    "\n",
    "# there are approx 5000 of them (by utterance id!)\n",
    "#     some may have fewer because of data sparsity.\n",
    "\n",
    "# per EACH of successes and yyy\n",
    "# And, they correspond to the right splits (the one in their name)\n",
    "\n",
    "for phase in ['val', 'eval']:\n",
    "    \n",
    "    print('*'*20, f\"Phase: {phase}\")\n",
    "    \n",
    "    for data_type, data_func in zip(['success', 'yyy'], [load_splits.get_age_success_sample_paths, load_splits.get_age_yyy_sample_paths]):\n",
    "\n",
    "        print(f'For {data_type}')\n",
    "        all_paths = data_func(phase = phase)\n",
    "        all_samples = [ pd.read_csv(p) for p in all_paths ]\n",
    "\n",
    "        sample_ids = set(pd.concat(all_samples).utterance_id)\n",
    "\n",
    "        print('Sample shapes')\n",
    "        for sample in all_samples:\n",
    "            print(f'\\t{sample.shape}')\n",
    "            print(f'\\t\\tNumber of total transcripts in all pool: {sample.shape}')\n",
    "\n",
    "        this_phono = all_phono[all_phono.utterance_id.isin(sample_ids)]\n",
    "        if data_type == 'success':\n",
    "            assert has_success(this_phono)\n",
    "        else:\n",
    "            assert has_yyy(this_phono)\n",
    "\n",
    "# Age 3.5 can be empty\n",
    "# but on the run where it was observed,\n",
    "# it seems that there are only 13 transcripts -- in a development run 10 were assigned to eval\n",
    "# and 3 were assigned to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Make sure:\n",
    "# The young data is actually young data\n",
    "# The old data is actually old data\n",
    "\n",
    "old_ids = set(pd.read_csv(join(split_gen.get_split_folder('age', 'old', config.prov_dir), 'success_utts_beta_5000_val.csv')).utterance_id)\n",
    "assert all(all_phono[all_phono.utterance_id.isin(old_ids)].target_child_age > config.age_split * 30.5)\n",
    "\n",
    "young_ids = set(pd.read_csv(join(split_gen.get_split_folder('age', 'young', config.prov_dir), 'success_utts_beta_5000_val.csv')).utterance_id)\n",
    "assert all(all_phono[all_phono.utterance_id.isin(young_ids)].target_child_age <= config.age_split * 30.5)\n",
    "\n",
    "print('Passed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for phase_sample\n",
      "Passed asserts\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "Checking for phase_child_sample\n",
      "Passed asserts\n",
      "1615\n",
      "931\n",
      "1807\n",
      "1038\n",
      "2517\n",
      "989\n"
     ]
    }
   ],
   "source": [
    "# For the beta samples,\n",
    "# they are all successes\n",
    "# there is approx 5000 of them (by utterance id!)\n",
    "# they all have phase == 'val'\n",
    "\n",
    "\n",
    "# The problem exists both in the general and child versions of the function.\n",
    "\n",
    "\n",
    "def check_beta_samples(arg_set, phase_label):\n",
    "    \n",
    "    print(f'Checking for {phase_label}')\n",
    "    \n",
    "    all_beta_samples = [\n",
    "        pd.read_csv(join(split_gen.get_split_folder(s, d, config.prov_dir), 'success_utts_beta_5000_val.csv'))\n",
    "        for s, d in arg_set\n",
    "    ]\n",
    "\n",
    "    beta_ids = set(pd.concat(all_beta_samples).utterance_id)\n",
    "    sel_phono = all_phono[all_phono.utterance_id.isin(beta_ids)]\n",
    "    beta_phases = set(sel_phono[phase_label])\n",
    "\n",
    "    assert beta_phases == {'val'}\n",
    "    assert has_success(sel_phono)\n",
    "    # You should have at least one success per utterance, but not all tokens have to be marked as a success.\n",
    "\n",
    "    print('Passed asserts')\n",
    "\n",
    "    for beta_sample in all_beta_samples:\n",
    "        print(len(set(beta_sample.utterance_id)))\n",
    "        \n",
    "    sampled_proper_attributes(all_phono, beta_ids)\n",
    "    \n",
    "check_beta_samples(config.childes_model_args, 'phase_sample')\n",
    "check_beta_samples([('child', name) for name in child_names], 'phase_child_sample')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asserts passed.\n"
     ]
    }
   ],
   "source": [
    "# Make sure the child train/val/eval data is separate within child\n",
    "# Note this no longer requires/uses the constraint that child val/eval matches the overall val/eval.\n",
    "\n",
    "\n",
    "for attr, phase_set in zip(['phase_child_sample', 'phase_child_finetune'], [phases[:], ['train', 'val']]):\n",
    "                                                                            \n",
    "    for name in child_names:\n",
    "\n",
    "        child_pool = all_phono[all_phono.target_child_name == name]\n",
    "        ids = {}\n",
    "        \n",
    "        for phase in phase_set:\n",
    "            ids[phase] = set(child_pool[child_pool[attr] == phase].utterance_id)\n",
    "\n",
    "        for p1 in phase_set:\n",
    "            for p2 in phase_set:\n",
    "                if p1 == p2: continue\n",
    "                assert len(ids[p1] & ids[p2]) == 0, f'{attr}, {p1}, {p2}'\n",
    "    \n",
    "print('Asserts passed.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of phase: train 279\n",
      "Size of phase: val 33\n",
      "Size of phase: eval 35\n",
      "Size of phase: train 302\n",
      "Size of phase: val 62\n",
      "\n",
      "For child: Lily, years available: [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]\n",
      "For phase: eval, ages available: [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "\tNumber of transcripts for this age, all: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.5, 1\n",
      "\tNumber of transcripts for this age, all: 4.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 4.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 4.0, 1\n",
      "For phase: val, ages available: [1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "\tNumber of transcripts for this age, all: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.5, 1\n",
      "For child: Ethan, years available: [0.5, 1.0, 1.5, 2.0, 2.5]\n",
      "For phase: eval, ages available: [0.5, 1.0, 1.5, 2.0, 2.5]\n",
      "\tNumber of transcripts for this age, all: 0.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 0.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 0.5, 1\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "For phase: val, ages available: [0.5, 1.0, 1.5, 2.0, 2.5]\n",
      "\tNumber of transcripts for this age, all: 0.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 0.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 0.5, 1\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "For child: Alex, years available: [1.0, 1.5, 2.0, 2.5, 3.0]\n",
      "For phase: eval, ages available: [1.0, 1.5, 2.0, 2.5, 3.0]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "For phase: val, ages available: [1.0, 1.5, 2.0, 2.5, 3.0]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "For child: Violet, years available: [1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
      "For phase: eval, ages available: [1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "\tNumber of transcripts for this age, all: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.5, 1\n",
      "For phase: val, ages available: [1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "\tNumber of transcripts for this age, all: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.5, 1\n",
      "For child: Naima, years available: [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
      "For phase: eval, ages available: [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
      "\tNumber of transcripts for this age, all: 0.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 0.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 0.5, 1\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "\tNumber of transcripts for this age, all: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.5, 1\n",
      "For phase: val, ages available: [1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "\tNumber of transcripts for this age, all: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.5, 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For child: William, years available: [1.0, 1.5, 2.0, 2.5, 3.0]\n",
      "For phase: eval, ages available: [1.0, 1.5, 2.0, 2.5, 3.0]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n",
      "For phase: val, ages available: [1.0, 1.5, 2.0, 2.5, 3.0]\n",
      "\tNumber of transcripts for this age, all: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.0, 1\n",
      "\tNumber of transcripts for this age, all: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 1.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 1.5, 1\n",
      "\tNumber of transcripts for this age, all: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.0, 1\n",
      "\tNumber of transcripts for this age, all: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, successes: 2.5, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 2.5, 1\n",
      "\tNumber of transcripts for this age, all: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, successes: 3.0, 1\n",
      "\t\tNumber of transcripts for this age, yyy: 3.0, 1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Figure out the transcript 1 transcript issue",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-a0909366abc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# This should be sufficient for Providence checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Figure out the transcript 1 transcript issue\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Figure out the transcript 1 transcript issue"
     ]
    }
   ],
   "source": [
    "# Other quick checks\n",
    "\n",
    "# Size of the train relative to val, eval for Providence\n",
    "# For all/all, age/old, age/young\n",
    "\n",
    "phase_data = {}\n",
    "\n",
    "for phase_type, phase_set in zip(['phase_child_sample', 'phase_child_finetune'], [phases[:], ['train', 'val']]):\n",
    "    for phase in phase_set:\n",
    "        print(f'Size of phase: {phase}', len(set(all_phono[all_phono[phase_type] == phase].transcript_id)))\n",
    "    \n",
    "\n",
    "# Make sure that there is a spread of age sampling for test\n",
    "# And also val\n",
    "\n",
    "print()\n",
    "\n",
    "for name in child_names:\n",
    "    \n",
    "    name_pool = all_phono[all_phono.target_child_name == name]\n",
    "    print(f'For child: {name}, years available: {data_cleaning.get_years(name_pool)}')\n",
    "    \n",
    "    for phase in ['eval', 'val']:\n",
    "        this_pool = name_pool[name_pool.phase_child_sample == phase]\n",
    "        # But, you need this per transcript.\n",
    "        \n",
    "        all_ages = data_cleaning.get_years(this_pool)\n",
    "        print(f'For phase: {phase}, ages available: {all_ages}')\n",
    "        \n",
    "        # For the val/eval samples \n",
    "        # There is about the right number of transcripts for eval and val (print out the numbers)\n",
    "\n",
    "        for age in all_ages: \n",
    "            this_sel_df = this_pool[this_pool.year == age]\n",
    "            \n",
    "            get_num_transcripts = lambda df : len(set(df.transcript_id))\n",
    "            all_num = get_num_transcripts(this_sel_df)\n",
    "            success_num = get_num_transcripts(this_sel_df[this_sel_df.partition == \"success\"])\n",
    "            yyy_num = get_num_transcripts(this_sel_df[this_sel_df.partition == \"yyy\"])\n",
    "            \n",
    "            assert 1 <= success_num <= 2\n",
    "            assert 1 <= yyy_num <= 2\n",
    "            \n",
    "            # Although one transcript was requested per success and yyy,\n",
    "            # it's possible that more than one will be printed below\n",
    "            # if that transcript also happened to have the other type in it.\n",
    "            \n",
    "            print(f'\\tNumber of transcripts for this age, all: {age}, {all_num}')\n",
    "            print(f'\\t\\tNumber of transcripts for this age, successes: {age}, {success_num}')\n",
    "            print(f'\\t\\tNumber of transcripts for this age, yyy: {age}, {yyy_num}')\n",
    "\n",
    "# Make sure that 0.5 and 4.0 were dropped from the models across time (do this manually)\n",
    "# Done\n",
    "\n",
    "# This should be sufficient for Providence checks.\n",
    "\n",
    "assert False, \"Figure out the transcript 1 transcript issue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{42426, 42427, 42428, 42429, 42430, 42431, 42432, 42433, 42434, 42435, 42436, 42437, 42438, 42439, 42440, 42441, 42442, 42443, 42444, 42445, 42446, 42447, 42448, 42449}\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Check that transcripts are available for Naima \n",
    "\n",
    "# Why is this?\n",
    "\n",
    "\n",
    "child_pool = all_phono[(all_phono.target_child_name == 'Naima')\n",
    "                      & (all_phono.partition == 'yyy')\n",
    "                      & (all_phono.year == 2.0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes to self;\n",
    "# Naima's transcript didn't sample w/o replacement between successes and yyy\n",
    "\n",
    "# why is 2.0 low for Naima? Is it likely that sampling w/o replacement led to collisions between successes and yyy for the following:\n",
    "\n",
    "# Naima 2.0: success gives 24 utterance ids\n",
    "# Naima 2.0: failure gives 24 utterance ids\n",
    "# Violet 2.5: success: 11, yyy is 11 -> this is somewhat unlikely.\n",
    "\n",
    "# Lily 4.0 (4.0 is correct, only one transcript)\n",
    "# Lily 3.5 is ~5 transcripts so it's somewhat likely to sample w/o replacement.\n",
    "# Can you check if it's really w/o replacement? \n",
    "\n",
    "\n",
    "# Note these numbers have changed because of re-split\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Child work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# The phases are all disjoint\n",
    "\n",
    "phase_dict = defaultdict(dict)\n",
    "\n",
    "for phase_type, phase_set in zip(['phase_child_sample', 'phase_child_finetune'], [phases[:], ['train', 'val']]):\n",
    "    \n",
    "    for phase in phase_set:\n",
    "        phase_dict[phase_type][phase] = set(all_phono[all_phono[phase_type] == phase].transcript_id)\n",
    "        \n",
    "    # train/val/eval in phase_child_sample, as well as phase_child_finetune\n",
    "    this_type_dict = phase_dict[phase_type]\n",
    "    for p1 in phase_set:\n",
    "        for p2 in phase_set:\n",
    "            if p1 == p2: continue\n",
    "            assert not (this_type_dict[p1] & this_type_dict[p2])\n",
    "\n",
    "# The finetune phases are all disjoint from val/eval phases in sample\n",
    "# The train_sample phase is in the finetune_phase\n",
    "\n",
    "finetune_disjoint = phase_dict['phase_child_finetune']['train'] | phase_dict['phase_child_finetune']['val']\n",
    "sample_disjoint = phase_dict['phase_child_sample']['val'] | phase_dict['phase_child_sample']['eval']\n",
    "\n",
    "\n",
    "# 7/25/21: https://www.geeksforgeeks.org/issubset-in-python/\n",
    "valid_for_finetune_partial = (phase_dict['phase_child_sample']['train']) & set(all_phono[~all_phono.contains_error])\n",
    "assert valid_for_finetune_partial.issubset(phase_dict['phase_child_finetune']['train'])\n",
    "# end cite\n",
    "\n",
    "assert len(finetune_disjoint & sample_disjoint) == 0\n",
    "    \n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "for name in child_names:\n",
    "    for phase in ['train', 'val']:\n",
    "        # Make sure there is cgv, chi in both phases for child data finetuning\n",
    "        rel_df = all_phono[(all_phono.target_child_name == name) & (all_phono.phase_child_finetune == phase)]\n",
    "        check_chi_cgv_present(rel_df)\n",
    "        \n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# Write a check to ensure that if phase_child_sample (or phase_sample) then\n",
    "# every transcript contains both at least one yyy and at least one success\n",
    "\n",
    "# How to check if something is not nan, etc? drop nan can be complex?\n",
    "# Just give all of the possibilties\n",
    "\n",
    "has_phase = all_phono[all_phono.phase_child_sample.isin(phases)]\n",
    "\n",
    "has_success_phase = set(has_phase[has_phase.partition == 'success'].transcript_id)\n",
    "has_yyy_phase = set(has_phase[has_phase.partition == 'yyy'].transcript_id)\n",
    "gen_phase = set(has_phase.transcript_id)\n",
    "\n",
    "# Note: no constraint on at least one yyy and at least one success for the finetune data.\n",
    "\n",
    "assert (has_success_phase & has_yyy_phase & gen_phase) == gen_phase\n",
    "\n",
    "print('Passed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think about scoreability checks for child scoring, other than beta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if my samples are sufficiently across time (beta)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
