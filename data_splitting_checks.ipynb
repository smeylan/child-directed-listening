{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from utils import load_splits, split_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SAVE_PATH = 'eval/new_splits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_marked_pooled_data(this_split_path):\n",
    "    return pd.read_csv(join(this_split_path, 'data_pool_with_phases.csv'))\n",
    "\n",
    "def check_disjoint_and_phase_written(split, name, base_dir):\n",
    "    \"\"\"\n",
    "    Checks that the phase data indicated per entry corresponds to the written text in the file.\n",
    "    By nature of the phase marks the data pool will be split disjointly.\n",
    "    \"\"\"\n",
    "    \n",
    "    this_split_loc = split_gen.get_split_folder(split, name, base_dir)\n",
    "    this_pool_data = load_marked_pooled_data(this_split_loc)\n",
    "    \n",
    "    if split == 'child':\n",
    "        data_cleaning.drop_errors(this_pool_data) # Don't consider the yyy, which are not written to the text files.\n",
    "        assert this_pool_data[this_pool_data.gloss == 'yyy'].phase == 'val'\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        phase_locs = this_pool_data[this_pool_data['phase'] == phase]\n",
    "        with open(join(this_split_loc, f\"{phase}.txt\"), 'r') as f:\n",
    "            from_text_text = sorted([l.strip() for l in f.readlines()]) # Get rid of trailing \\n\n",
    "        \n",
    "        from_df_text = sorted(list(phase_locs['gloss_with_punct']))\n",
    "        \n",
    "        assert from_text_text == from_df_text, f'Failed to match phase data for: {split}, {name}, {phase}'\n",
    "    \n",
    "    print(f'Assert passed for {split}, {name}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(load_splits)\n",
    "\n",
    "entire_dataset_dict = load_splits.load_eval_data_all('all', 'all', BASE_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3418: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert passed for all, all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Disjoint sets for \"all\" split\n",
    "\n",
    "#all_split_paths = load_splits.load_splits_folder_text('all', 'data/new_splits')\n",
    "#assert len(all_split_paths) == 1\n",
    "\n",
    "check_disjoint_and_phase_written('all', 'all', 'data/new_splits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asserts passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for correct age splitting within the evaluation data\n",
    "young_df_dict = load_splits.load_eval_data_all('age', 'young', BASE_SAVE_PATH)\n",
    "old_df_dict = load_splits.load_eval_data_all('age', 'old', BASE_SAVE_PATH)\n",
    "\n",
    "# Convert to months, the comparison in the code is in months but it's converted from days for each comparison\n",
    "assert all(all((young_df_dict[k]['target_child_age'] / 30.5) <= 36) for k in young_df_dict.keys()) \n",
    "assert all(all((old_df_dict[k]['target_child_age'] / 30.5) > 36) for k in old_df_dict.keys())\n",
    "\n",
    "print(\"asserts passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-509e7359749b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# 7/1/21: https://stackoverflow.com/questions/48647534/python-pandas-find-difference-between-two-data-frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcat_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthis_entire_data_filtered\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Disjoint sets for young, old, and merge to form whole dataset in the evaluation data.\n",
    "# This runs really slow so terminating for now,\n",
    "# But via comparing unsorted sets of a good number of the columns and seeing there's no ^ difference\n",
    "# I have reason to believe that it's just a question of sorting everything in the same order\n",
    " \n",
    "for k in young_df_dict.keys():\n",
    "    \n",
    "    # This is not quite right -- you have to drop all of the NaNs that are \n",
    "    sort_by_cols = sort_on[k] # Just trying to get them to be the same sorted order\n",
    "    this_entire_data = entire_dataset_dict[k]\n",
    "    \n",
    "    # 7/1/21: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
    "    # This makes a copy of the data.\n",
    "    this_entire_data_filtered = this_entire_data.dropna(subset=['target_child_age'])\n",
    "    \n",
    "    concat_df = pd.concat([young_df_dict[k], old_df_dict[k]])\n",
    "    \n",
    "    # Make sure there are no internal duplicates\n",
    "    # 7/1/21: https://thispointer.com/pandas-find-duplicate-rows-in-a-dataframe-based-on-all-or-selected-columns-using-dataframe-duplicated-in-python/\n",
    "    assert (not any(this_entire_data_filtered.duplicated())) and (not any(concat_df.duplicated()))\n",
    "    \n",
    "    # Then, check if the two dataframes are the same\n",
    "    # 7/1/21: https://stackoverflow.com/questions/48647534/python-pandas-find-difference-between-two-data-frames\n",
    "    \n",
    "    assert pd.concat([concat_df,this_entire_data_filtered]).drop_duplicates(keep=False).shape[0] == 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  utterance_id  num_xxx  num_yyy      set  target_child_age  \\\n",
      "0               0      16759315        0        0  success          514.0000   \n",
      "1               1      16759467        0        0  success          514.0000   \n",
      "2               2      16759501        0        0  success          514.0000   \n",
      "3               3      16759549        0        0  success          514.0000   \n",
      "4               4      16759752        0        0  success          514.0000   \n",
      "...           ...           ...      ...      ...      ...               ...   \n",
      "83875       83875      17280876        0        0  success         1212.0625   \n",
      "83876       83876      17280891        0        0  success         1212.0625   \n",
      "83877       83877      17280946        0        0  success         1212.0625   \n",
      "83878       83878      17280964        0        0  success         1212.0625   \n",
      "83879       83879      17280992        0        0  success         1212.0625   \n",
      "\n",
      "      target_child_name  transcript_id               gloss         type  \\\n",
      "0                  Alex          42204               Mommy  declarative   \n",
      "1                  Alex          42204                 wee  declarative   \n",
      "2                  Alex          42204                 wee  declarative   \n",
      "3                  Alex          42204                 woo  declarative   \n",
      "4                  Alex          42204               Ernie  declarative   \n",
      "...                 ...            ...                 ...          ...   \n",
      "83875           William          42569                help          NaN   \n",
      "83876           William          42569                help          NaN   \n",
      "83877           William          42569  nobody hates Simba          NaN   \n",
      "83878           William          42569   oh why lick hippo          NaN   \n",
      "83879           William          42569               hippo          NaN   \n",
      "\n",
      "      speaker_code  \n",
      "0              CHI  \n",
      "1              CHI  \n",
      "2              CHI  \n",
      "3              CHI  \n",
      "4              CHI  \n",
      "...            ...  \n",
      "83875          NaN  \n",
      "83876          NaN  \n",
      "83877          NaN  \n",
      "83878          NaN  \n",
      "83879          NaN  \n",
      "\n",
      "[167760 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "arr = pd.concat([concat_df,this_entire_data_filtered]).drop_duplicates(keep=False)\n",
    "# The two are not the same -- why?\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/childes/child_listening_continuation/child-listening-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3418: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert passed for age, old\n",
      "Assert passed for age, young\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct ages for the training/val data.\n",
    "\n",
    "print('started')\n",
    "\n",
    "marked_pooled_old = load_marked_pooled_data(split_gen.get_split_folder('age', 'old', 'data/new_splits'))\n",
    "marked_pooled_young = load_marked_pooled_data(split_gen.get_split_folder('age', 'young', 'data/new_splits'))\n",
    "\n",
    "# Convert to months\n",
    "assert all(age / 30.5 > 36 for age in marked_pooled_old.target_child_age)\n",
    "assert all(age / 30.5 <= 36 for age in marked_pooled_young.target_child_age) \n",
    "\n",
    "\n",
    "# Check for disjointedness within each of the age splits for train/val data.\n",
    "\n",
    "check_disjoint_and_phase_written('age', 'old', 'data/new_splits')\n",
    "check_disjoint_and_phase_written('age', 'young', 'data/new_splits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Come back to child work after finishing age-based work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = ['William', 'Alex', 'Violet', 'Naima', 'Ethan', 'Lily']\n",
    "\n",
    "# 1) Data always addresses the relevant child\n",
    "all_child_data = {}\n",
    "for name in names:\n",
    "    this_info_dict = load_splits.load_eval_data_all('child', name, BASE_SAVE_PATH)\n",
    "    assert all(all(this_info_dict[k]['target_child_name'] == name) for k in this_info_dict.keys())\n",
    "    all_child_data[name] = this_info_dict\n",
    "\n",
    "# 2) Check that child data merges to the entire dataset\n",
    "for k in entire_dataset_dict.keys():\n",
    "    \n",
    "    this_entire_data = entire_dataset_dict[k].sort_values('utterance_id')\n",
    "    concat_df = pd.concat([all_child_data[n][k] for n in names])\n",
    "\n",
    "    assert concat_df.equals(this_entire_data)\n",
    "    \n",
    "# 3) The child splits are disjoint across the train and val data\n",
    "\n",
    "for name in names:\n",
    "    check_disjoint_and_phase_written('child', name, BASE_SAVE_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
