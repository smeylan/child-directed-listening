{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise Levenshtein Distances for the Providence corpus / Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "import childespy\n",
    "import numpy as np\n",
    "import os\n",
    "import imp\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"').iloc[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regenerate = True\n",
    "\n",
    "if regenerate:\n",
    "    pvd_chi_tokens = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, actual_phonology, model_phonology, transcript_id, utterance_id, \\\n",
    "    token_order from token where speaker_code = \"CHI\" and corpus_id = '+str(pvd_idx),\n",
    "        db_version = \"2020.1\")\n",
    "    pvd_chi_tokens.to_csv('csv/pvd_tokens.csv', index=False)\n",
    "else: \n",
    "    pvd_chi_tokens = pd.read_csv('csv/pvd_tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "pvd_chi_tokens = pvd_chi_tokens.loc[~(pvd_chi_tokens.model_phonology.isin(excludes) |\n",
    "    pvd_chi_tokens.actual_phonology.isin(excludes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gloss                   Mommy\n",
       "target_child_name        Alex\n",
       "target_child_age        514.0\n",
       "speaker_code              CHI\n",
       "actual_phonology          ɑmɪ\n",
       "model_phonology         mɑmiː\n",
       "transcript_id           42204\n",
       "utterance_id         16759315\n",
       "token_order                 1\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvd_chi_tokens.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most common transcription for each form\n",
    "pvd_chi_tokens.gloss = [x.lower() for x in pvd_chi_tokens.gloss]\n",
    "ipa_for_glosses = pvd_chi_tokens.groupby(['gloss']).model_phonology.agg(lambda x:\n",
    "    x.value_counts().reset_index().iloc[0]['index']    \n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7929, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7929, 2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ipa_for_glosses.shape)\n",
    "test = ipa_for_glosses.dropna()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>model_phonology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>box</td>\n",
       "      <td>bɑks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>cat</td>\n",
       "      <td>kæt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>dog</td>\n",
       "      <td>dɑɡ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>fishes</td>\n",
       "      <td>fɪʃəz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>mommy</td>\n",
       "      <td>mɑmiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>potato</td>\n",
       "      <td>pəteɪtoʊ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gloss model_phonology\n",
       "4          a               ə\n",
       "768      box            bɑks\n",
       "1072     cat             kæt\n",
       "1892     dog             dɑɡ\n",
       "2420  fishes           fɪʃəz\n",
       "4340   mommy           mɑmiː\n",
       "5271  potato        pəteɪtoʊ"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words = ['dog','cat','box','fishes', 'mommy', 'potato','a']\n",
    "ipa_for_glosses.loc[ipa_for_glosses.gloss.isin(test_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6753, 2)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa_for_glosses = ipa_for_glosses.loc[ipa_for_glosses.model_phonology != \"\"]\n",
    "ipa_for_glosses['model_phonology'] = [x.replace(\"ː\",\"\").replace('ʌ','ə')\n",
    ".replace('ɪ','ə').replace('ɔ','ɑ') for x in ipa_for_glosses['model_phonology']]\n",
    "ipa_for_glosses.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>model_phonology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abe</td>\n",
       "      <td>eəb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abide</td>\n",
       "      <td>əbaəd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gloss model_phonology\n",
       "4       a               ə\n",
       "14    abe             eəb\n",
       "15  abide           əbaəd"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa_for_glosses.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using just the model phonology alone is a problem: many words won't be attested. Need\n",
    "# to compare extend these to CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu = pd.read_csv('/shared_hd0/corpora/CMU_pronunciation/cmu_dict_df.csv')\n",
    "cmu.columns = ['index','word','pronunciation']\n",
    "from string import digits\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "cmu['phones'] = [[y.translate(remove_digits) for y in x.split(' ')] for x in cmu['pronunciation']]\n",
    "cmu.word = [str(x).lower() for x in cmu.word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten(list_of_lists):\n",
    "#     return([item for subl in list_of_lists for item in subl])\n",
    "\n",
    "# phone_inventory = pd.DataFrame({'arpa':np.unique(flatten(cmu.phones))})\n",
    "# phone_inventory.to_csv('phon/phon_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_map_df = pd.read_csv('phon/phon_map_populated.csv')\n",
    "phone_map = dict(zip(phone_map_df.arpa, phone_map_df.ipa))\n",
    "cv_map = dict(zip(phone_map_df.arpa, phone_map_df.c_or_v))\n",
    "cmu['ipa'] = [[phone_map[x] for x in y] for y in cmu.phones]\n",
    "cmu['structure'] = [[cv_map[x] for x in y] for y in cmu.phones]\n",
    "cmu['num_vowels'] = [np.sum(np.array(x) == 'v') for x in cmu['structure']]\n",
    "cmu['ipa_short'] = [''.join(x) for x in cmu['ipa']]\n",
    "cmu['ipa_short'] =  [x.replace('ɝ', 'əɹ').replace('ɪ','ə').replace(\n",
    "'ɔ','ɑ') for x in cmu['ipa_short']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>phones</th>\n",
       "      <th>ipa</th>\n",
       "      <th>ipa_short</th>\n",
       "      <th>structure</th>\n",
       "      <th>num_vowels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>a</td>\n",
       "      <td>AH0</td>\n",
       "      <td>[AH]</td>\n",
       "      <td>[ə]</td>\n",
       "      <td>ə</td>\n",
       "      <td>[v]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14024</th>\n",
       "      <td>14025</td>\n",
       "      <td>box</td>\n",
       "      <td>B AA1 K S</td>\n",
       "      <td>[B, AA, K, S]</td>\n",
       "      <td>[b, ɑ, k, s]</td>\n",
       "      <td>bɑks</td>\n",
       "      <td>[c, v, c, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>19020</td>\n",
       "      <td>cat</td>\n",
       "      <td>K AE1 T</td>\n",
       "      <td>[K, AE, T]</td>\n",
       "      <td>[k, æ, t]</td>\n",
       "      <td>kæt</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33320</th>\n",
       "      <td>33321</td>\n",
       "      <td>dog</td>\n",
       "      <td>D AO1 G</td>\n",
       "      <td>[D, AO, G]</td>\n",
       "      <td>[d, ɔ, ɡ]</td>\n",
       "      <td>dɑɡ</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42452</th>\n",
       "      <td>42453</td>\n",
       "      <td>fishes</td>\n",
       "      <td>F IH1 SH AH0 Z</td>\n",
       "      <td>[F, IH, SH, AH, Z]</td>\n",
       "      <td>[f, ɪ, ʃ, ə, z]</td>\n",
       "      <td>fəʃəz</td>\n",
       "      <td>[c, v, c, v, c]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79787</th>\n",
       "      <td>79788</td>\n",
       "      <td>mommy</td>\n",
       "      <td>M AA1 M IY0</td>\n",
       "      <td>[M, AA, M, IY]</td>\n",
       "      <td>[m, ɑ, m, i]</td>\n",
       "      <td>mɑmi</td>\n",
       "      <td>[c, v, c, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93614</th>\n",
       "      <td>93615</td>\n",
       "      <td>potato</td>\n",
       "      <td>P AH0 T EY1 T OW2</td>\n",
       "      <td>[P, AH, T, EY, T, OW]</td>\n",
       "      <td>[p, ə, t, eɪ, t, oʊ]</td>\n",
       "      <td>pəteətoʊ</td>\n",
       "      <td>[c, v, c, v, c, v]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index    word      pronunciation                 phones  \\\n",
       "70        71       a                AH0                   [AH]   \n",
       "14024  14025     box          B AA1 K S          [B, AA, K, S]   \n",
       "19019  19020     cat            K AE1 T             [K, AE, T]   \n",
       "33320  33321     dog            D AO1 G             [D, AO, G]   \n",
       "42452  42453  fishes     F IH1 SH AH0 Z     [F, IH, SH, AH, Z]   \n",
       "79787  79788   mommy        M AA1 M IY0         [M, AA, M, IY]   \n",
       "93614  93615  potato  P AH0 T EY1 T OW2  [P, AH, T, EY, T, OW]   \n",
       "\n",
       "                        ipa ipa_short           structure  num_vowels  \n",
       "70                      [ə]         ə                 [v]           1  \n",
       "14024          [b, ɑ, k, s]      bɑks        [c, v, c, c]           1  \n",
       "19019             [k, æ, t]       kæt           [c, v, c]           1  \n",
       "33320             [d, ɔ, ɡ]       dɑɡ           [c, v, c]           1  \n",
       "42452       [f, ɪ, ʃ, ə, z]     fəʃəz     [c, v, c, v, c]           2  \n",
       "79787          [m, ɑ, m, i]      mɑmi        [c, v, c, v]           2  \n",
       "93614  [p, ə, t, eɪ, t, oʊ]  pəteətoʊ  [c, v, c, v, c, v]           3  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu.loc[cmu.word.isin(test_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8307418924922256"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of Providence annotations that match the annotation in adjusted CMU \n",
    "found_words = ipa_for_glosses.merge(cmu, left_on=['gloss','model_phonology'],\n",
    "    right_on = ['word','ipa_short'])\n",
    "found_words.shape[0] / ipa_for_glosses.shape[0] # 83% found after remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>pvd_ipa</th>\n",
       "      <th>cmu_ipa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>swallowing</td>\n",
       "      <td>swɑloʊwəŋ</td>\n",
       "      <td>swɑloʊəŋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sprinklers</td>\n",
       "      <td>spɹəŋkələɹz</td>\n",
       "      <td>spɹəŋkləɹz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>unusual</td>\n",
       "      <td>ənjuʒəwwəl</td>\n",
       "      <td>ənjuʒuəl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>hola</td>\n",
       "      <td>olɑ</td>\n",
       "      <td>hoʊlə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cuckoo</td>\n",
       "      <td>kuku</td>\n",
       "      <td>kəku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>beware</td>\n",
       "      <td>bəwwɛɹ</td>\n",
       "      <td>bəwɛɹ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>mastodon</td>\n",
       "      <td>mæsdədɑn</td>\n",
       "      <td>mæstədɑn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>might've</td>\n",
       "      <td>maətv</td>\n",
       "      <td>maətəv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>genuine</td>\n",
       "      <td>ʤɛnjəwwən</td>\n",
       "      <td>ʤɛnjuən</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>baa</td>\n",
       "      <td>bæ</td>\n",
       "      <td>bieəeə</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gloss      pvd_ipa     cmu_ipa\n",
       "133  swallowing    swɑloʊwəŋ    swɑloʊəŋ\n",
       "130  sprinklers  spɹəŋkələɹz  spɹəŋkləɹz\n",
       "144     unusual   ənjuʒəwwəl    ənjuʒuəl\n",
       "66         hola          olɑ       hoʊlə\n",
       "30       cuckoo         kuku        kəku\n",
       "20       beware       bəwwɛɹ       bəwɛɹ\n",
       "91     mastodon     mæsdədɑn    mæstədɑn\n",
       "95     might've        maətv      maətəv\n",
       "54      genuine    ʤɛnjəwwən     ʤɛnjuən\n",
       "14          baa           bæ      bieəeə"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing words\n",
    "missing = ipa_for_glosses.loc[~ipa_for_glosses.gloss.isin(found_words.gloss)]\n",
    "missing = missing.merge(cmu, left_on=['gloss'], right_on=['word'])\n",
    "missing_short =missing[['gloss', 'model_phonology','ipa_short']]\n",
    "missing_short.columns = ['gloss','pvd_ipa','cmu_ipa']\n",
    "missing_short.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character differences / shorthand\n",
    "[X] cmu: ɝ -> əɹ\n",
    "[X] cmu:  tʃ -> ʧ\n",
    "[X] cmu  dʒ -> ʤ      \n",
    "# Collapses\n",
    "[X] cmu  I -> schwa\n",
    "[X] ɑ in model phonlogy vs ɔ in cmu: convert ɔ to ɑ in both\n",
    "[X] model phonology: ʌ ->  ə"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# this doesn't produce diphthongs; vowels are weird\n",
    "# cmu = pd.read_csv('/shared_hd0/corpora/CMU_pronunciation/CMU.in.IPA.txt', \n",
    "#                   encoding='utf-8',header = None, sep = \",[ \\t]*\", na_filter=False)\n",
    "# cmu.columns = ['word','ipa']\n",
    "# cmu['ipa'] = [x.replace(\"ˌ\",\"\").replace(\"ˈ\",\"\") if x is not None else None for x in cmu.ipa ]\n",
    "# cmu.loc[cmu.word.isin(['dog','cat','box','fishes', 'mommy', 'potato'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "wswg  = pd.read_csv('/home/stephan/notebooks/ws_analysis/data/raw_data/WSWG_50percentproducing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total coverage\n",
      "0.9827586206896551\n",
      "Coverage for 2 syllable words\n",
      "0.9341692789968652\n",
      "Coverage for 1 syllable words\n",
      "0.622257053291536\n"
     ]
    }
   ],
   "source": [
    "wswg['word'] = [x.split(' ')[0].split('/')[0] for x in wswg.word]\n",
    "' '.join(wswg['word'])\n",
    "wswg_cmu = wswg.merge(cmu)\n",
    "print('Total coverage')\n",
    "print(wswg_cmu.shape[0] / wswg.shape[0])\n",
    "print('Coverage for 2 syllable words')\n",
    "print(wswg_cmu.loc[wswg_cmu.num_vowels <= 2].shape[0] / wswg.shape[0])\n",
    "print('Coverage for 1 syllable words')\n",
    "print(wswg_cmu.loc[wswg_cmu.num_vowels <= 1].shape[0] / wswg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lɑɹi          17\n",
       "hɑk           13\n",
       "kɑɹ           13\n",
       "kɛɹi          13\n",
       "bɑɹ           12\n",
       "              ..\n",
       "lændvjuaət     1\n",
       "ʒaʊpəŋz        1\n",
       "ɡɹəmbəl        1\n",
       "pəɡmɛnt        1\n",
       "neəvə          1\n",
       "Name: ipa_short, Length: 109530, dtype: int64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wswg_cmu.ipa_short.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133852"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cmu_words) #133, 852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "childes_counts = pd.read_csv('data/vocab.csv')\n",
    "childes_counts.columns \n",
    "cmu_in_childes = cmu.loc[(cmu.word.isin(\n",
    "    childes_counts.loc[childes_counts['count'] > 3].word)) & (cmu['num_vowels'] <=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12557, 8)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_childes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "initial_tokenizer = BertTokenizer.from_pretrained('model_output2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer_vocab = initial_tokenizer.get_vocab().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_in_childes = cmu.loc[(cmu.word.isin(\n",
    "    childes_counts.loc[childes_counts['count'] > 3].word)) & (cmu['num_vowels'] <=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12557, 8)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_childes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7904, 8)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_childes_with_tokenizer = cmu.loc[(cmu.word.isin(\n",
    "    childes_counts.loc[childes_counts['count'] > 3].word)) & (cmu['num_vowels'] <=2) &\n",
    "            (cmu.word.isin(bert_tokenizer_vocab))]\n",
    "cmu_in_childes_with_tokenizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13357, 8)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_childes_with_tokenizer = cmu.loc[(cmu['num_vowels'] <=2) &\n",
    "            (cmu.word.isin(bert_tokenizer_vocab))]\n",
    "cmu_in_childes_with_tokenizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plumbing',\n",
       " 'outburst',\n",
       " 'settlers',\n",
       " 'sighs',\n",
       " 'woodward',\n",
       " 'sprint',\n",
       " 'avant',\n",
       " 'launcher',\n",
       " 'geoff',\n",
       " 'seduce',\n",
       " 'flux',\n",
       " 'cote',\n",
       " 'user',\n",
       " 'polls',\n",
       " 'stating',\n",
       " 'battles',\n",
       " 'revised',\n",
       " 'fungus',\n",
       " 'ios',\n",
       " 'gunther',\n",
       " 'riga',\n",
       " 'ethics',\n",
       " 'draped',\n",
       " 'phased',\n",
       " 'arrays',\n",
       " 'hadley',\n",
       " 'patent',\n",
       " 'sandstone',\n",
       " 'impaired',\n",
       " 'laurent',\n",
       " 'coded',\n",
       " 'argyle',\n",
       " 'boardwalk',\n",
       " 'olaf',\n",
       " 'engraved',\n",
       " 'lynx',\n",
       " 'sheppard',\n",
       " 'nobel',\n",
       " 'churchyard',\n",
       " 'dunn',\n",
       " 'peerage',\n",
       " 'fleet',\n",
       " 'flowed',\n",
       " 'oslo',\n",
       " 'escorts',\n",
       " 'sydney',\n",
       " 'bared',\n",
       " 'gershwin',\n",
       " 'iphone',\n",
       " 'gaston',\n",
       " 'mir',\n",
       " 'cache',\n",
       " 'riots',\n",
       " 'weber',\n",
       " 'flawed',\n",
       " 'nightfall',\n",
       " 'prelate',\n",
       " 'squadrons',\n",
       " 'gazed',\n",
       " 'assam',\n",
       " 'molten',\n",
       " 'appeals',\n",
       " 'akron',\n",
       " 'echoes',\n",
       " 'seeded',\n",
       " 'husky',\n",
       " 'memphis',\n",
       " 'yun',\n",
       " 'subset',\n",
       " 'weighted',\n",
       " 'fungal',\n",
       " 'iain',\n",
       " 'carr',\n",
       " 'tasked',\n",
       " 'backlash',\n",
       " 'oakley',\n",
       " 'reuben',\n",
       " 'jerseys',\n",
       " 'keynes',\n",
       " 'finnish',\n",
       " 'paved',\n",
       " 'forecast',\n",
       " 'mirrored',\n",
       " 'fiscal',\n",
       " 'shooters',\n",
       " 'clustered',\n",
       " 'subgroup',\n",
       " 'viewpoint',\n",
       " 'paolo',\n",
       " 'opaque',\n",
       " 'turnbull',\n",
       " 'granville',\n",
       " 'northwest',\n",
       " 'widowed',\n",
       " 'arrests',\n",
       " 'hanson',\n",
       " 'veto',\n",
       " 'fracture',\n",
       " 'myspace',\n",
       " 'whitley',\n",
       " 'starring',\n",
       " 'bingham',\n",
       " 'burrows',\n",
       " 'essen',\n",
       " 'ranged',\n",
       " 'cult',\n",
       " 'raped',\n",
       " 'wharf',\n",
       " 'spectra',\n",
       " 'starred',\n",
       " 'bertrand',\n",
       " 'frankish',\n",
       " 'soundtrack',\n",
       " 'flooding',\n",
       " 'platinum',\n",
       " 'hacked',\n",
       " 'repealed',\n",
       " 'queensland',\n",
       " 'bombings',\n",
       " 'groaned',\n",
       " 'alloy',\n",
       " 'equipped',\n",
       " 'realms',\n",
       " 'vested',\n",
       " 'hatfield',\n",
       " 'urban',\n",
       " 'maris',\n",
       " 'denton',\n",
       " 'yearbook',\n",
       " 'coastal',\n",
       " 'listing',\n",
       " 'presley',\n",
       " 'absence',\n",
       " 'iran',\n",
       " 'lennox',\n",
       " 'restored',\n",
       " 'entries',\n",
       " 'fined',\n",
       " 'weathered',\n",
       " 'roadside',\n",
       " 'brewer',\n",
       " 'maia',\n",
       " 'apps',\n",
       " 'berth',\n",
       " 'donnell',\n",
       " 'dismay',\n",
       " 'performs',\n",
       " 'whitish',\n",
       " 'neal',\n",
       " 'retreat',\n",
       " 'hanoi',\n",
       " 'judd',\n",
       " 'lodging',\n",
       " 'focal',\n",
       " 'gan',\n",
       " 'guillaume',\n",
       " 'anand',\n",
       " 'haiti',\n",
       " 'purdue',\n",
       " 'corbett',\n",
       " 'displaced',\n",
       " 'zen',\n",
       " 'feat',\n",
       " 'aspect',\n",
       " 'sworn',\n",
       " 'sudan',\n",
       " 'poe',\n",
       " 'wolfe',\n",
       " 'welded',\n",
       " 'philipp',\n",
       " 'reflects',\n",
       " 'craftsmen',\n",
       " 'cairo',\n",
       " 'evolve',\n",
       " 'stigma',\n",
       " 'ventured',\n",
       " 'rallies',\n",
       " 'ranked',\n",
       " 'scalp',\n",
       " 'levin',\n",
       " 'blanco',\n",
       " 'repeal',\n",
       " 'zeta',\n",
       " 'hearings',\n",
       " 'prank',\n",
       " 'elgin',\n",
       " 'ritchie',\n",
       " 'broadcasts',\n",
       " 'tabloid',\n",
       " 'jayne',\n",
       " 'emir',\n",
       " 'honors',\n",
       " 'indus',\n",
       " 'ligand',\n",
       " 'font',\n",
       " 'lacks',\n",
       " 'astor',\n",
       " 'lankan',\n",
       " 'drafts',\n",
       " 'gleam',\n",
       " 'judged',\n",
       " 'lacked',\n",
       " 'rhythmic',\n",
       " 'workplace',\n",
       " 'juniors',\n",
       " 'bodied',\n",
       " 'losses',\n",
       " 'talbot',\n",
       " 'stated',\n",
       " 'lawson',\n",
       " 'bane',\n",
       " 'mundo',\n",
       " 'nad',\n",
       " 'chalmers',\n",
       " 'butte',\n",
       " 'clashed',\n",
       " 'noting',\n",
       " 'diaz',\n",
       " 'tempest',\n",
       " 'bridgeport',\n",
       " 'dubbed',\n",
       " 'tessa',\n",
       " 'rahman',\n",
       " 'pitted',\n",
       " 'bromley',\n",
       " 'hilltop',\n",
       " 'reza',\n",
       " 'broadband',\n",
       " 'turrets',\n",
       " 'former',\n",
       " 'modeled',\n",
       " 'pointless',\n",
       " 'tyson',\n",
       " 'allah',\n",
       " 'mendez',\n",
       " 'lambert',\n",
       " 'revolt',\n",
       " 'clan',\n",
       " 'boeing',\n",
       " 'strand',\n",
       " 'biased',\n",
       " 'bern',\n",
       " 'weekly',\n",
       " 'dispute',\n",
       " 'mayors',\n",
       " 'truths',\n",
       " 'mapped',\n",
       " 'smeared',\n",
       " 'miners',\n",
       " 'warped',\n",
       " 'darting',\n",
       " 'clearance',\n",
       " 'sanjay',\n",
       " 'gothic',\n",
       " 'sustained',\n",
       " 'dail',\n",
       " 'granted',\n",
       " 'mohan',\n",
       " 'startling',\n",
       " 'bedrock',\n",
       " 'mahmud',\n",
       " 'polled',\n",
       " 'claremont',\n",
       " 'neared',\n",
       " 'vulcan',\n",
       " 'esteem',\n",
       " 'sipped',\n",
       " 'highlands',\n",
       " 'sunni',\n",
       " 'raceway',\n",
       " 'vector',\n",
       " 'retained',\n",
       " 'hitchcock',\n",
       " 'bowman',\n",
       " 'vendors',\n",
       " 'maclean',\n",
       " 'haste',\n",
       " 'foley',\n",
       " 'belgium',\n",
       " 'michaels',\n",
       " 'grupo',\n",
       " 'epic',\n",
       " 'reeve',\n",
       " 'toni',\n",
       " 'rebelled',\n",
       " 'strata',\n",
       " 'fated',\n",
       " 'noble',\n",
       " 'oblast',\n",
       " 'transformed',\n",
       " 'wherein',\n",
       " 'elite',\n",
       " 'soils',\n",
       " 'crafted',\n",
       " 'output',\n",
       " 'citing',\n",
       " 'thomson',\n",
       " 'yuri',\n",
       " 'redskins',\n",
       " 'azores',\n",
       " 'jaya',\n",
       " 'avoids',\n",
       " 'preview',\n",
       " 'java',\n",
       " 'shan',\n",
       " 'views',\n",
       " 'govern',\n",
       " 'marlene',\n",
       " 'wartime',\n",
       " 'jamestown',\n",
       " 'patents',\n",
       " 'lp',\n",
       " 'sera',\n",
       " 'geek',\n",
       " 'leftist',\n",
       " 'peaks',\n",
       " 'mainline',\n",
       " 'hearted',\n",
       " 'flexed',\n",
       " 'lombard',\n",
       " 'putin',\n",
       " 'rhythms',\n",
       " 'chapters',\n",
       " 'saunders',\n",
       " 'ideals',\n",
       " 'childless',\n",
       " 'ashok',\n",
       " 'weiss',\n",
       " 'thug',\n",
       " 'succeeds',\n",
       " 'pleaded',\n",
       " 'resort',\n",
       " 'formats',\n",
       " 'cochran',\n",
       " 'croft',\n",
       " 'receives',\n",
       " 'grimace',\n",
       " 'plumage',\n",
       " 'yue',\n",
       " 'serge',\n",
       " 'proto',\n",
       " 'onwards',\n",
       " 'jacobs',\n",
       " 'parma',\n",
       " 'commits',\n",
       " 'glaciers',\n",
       " 'affirmed',\n",
       " 'wembley',\n",
       " 'ref',\n",
       " 'rumbled',\n",
       " 'sensors',\n",
       " 'disputes',\n",
       " 'lasers',\n",
       " 'text',\n",
       " 'readings',\n",
       " 'barclay',\n",
       " 'mueller',\n",
       " 'buena',\n",
       " 'poorer',\n",
       " 'hammond',\n",
       " 'hatred',\n",
       " 'gland',\n",
       " 'neurons',\n",
       " 'antoine',\n",
       " 'transforms',\n",
       " 'functions',\n",
       " 'warlord',\n",
       " 'intern',\n",
       " 'richly',\n",
       " 'oilers',\n",
       " 'winslow',\n",
       " 'explores',\n",
       " 'convoys',\n",
       " 'notre',\n",
       " 'orson',\n",
       " 'shrugged',\n",
       " 'nearing',\n",
       " 'layla',\n",
       " 'excel',\n",
       " 'hardwood',\n",
       " 'flanked',\n",
       " 'forums',\n",
       " 'latham',\n",
       " 'nara',\n",
       " 'lesions',\n",
       " 'breakout',\n",
       " 'prepares',\n",
       " 'theories',\n",
       " 'brilliance',\n",
       " 'striker',\n",
       " 'summon',\n",
       " 'pena',\n",
       " 'depicts',\n",
       " 'decrees',\n",
       " 'slogan',\n",
       " 'worcester',\n",
       " 'conserve',\n",
       " 'standings',\n",
       " 'rector',\n",
       " 'wainwright',\n",
       " 'outlets',\n",
       " 'lash',\n",
       " 'voyage',\n",
       " 'fumbled',\n",
       " 'c2',\n",
       " 'mitch',\n",
       " 'flared',\n",
       " 'toulouse',\n",
       " 'preached',\n",
       " 'layton',\n",
       " 'vance',\n",
       " 'colton',\n",
       " 'christoph',\n",
       " 'laude',\n",
       " 'plead',\n",
       " 'beit',\n",
       " 'slovene',\n",
       " 'simplest',\n",
       " 'sumo',\n",
       " 'rite',\n",
       " 'scorer',\n",
       " 'widely',\n",
       " 'arjun',\n",
       " 'flinched',\n",
       " 'gameplay',\n",
       " 'gov',\n",
       " 'caressed',\n",
       " 'ghostly',\n",
       " 'bessie',\n",
       " 'lille',\n",
       " 'sousa',\n",
       " 'und',\n",
       " 'vaccines',\n",
       " 'cosmos',\n",
       " 'immune',\n",
       " 'keenan',\n",
       " 'dating',\n",
       " 'jenkins',\n",
       " 'spatial',\n",
       " 'carmine',\n",
       " 'crewe',\n",
       " 'tortured',\n",
       " 'clark',\n",
       " 'largely',\n",
       " 'henson',\n",
       " 'kahn',\n",
       " 'decreased',\n",
       " 'skimmed',\n",
       " 'thereby',\n",
       " 'hubert',\n",
       " 'haley',\n",
       " 'rhineland',\n",
       " 'opted',\n",
       " 'domes',\n",
       " 'rowe',\n",
       " 'factions',\n",
       " 'prose',\n",
       " 'networks',\n",
       " 'hancock',\n",
       " 'runways',\n",
       " 'thorne',\n",
       " 'galway',\n",
       " 'fremont',\n",
       " 'reg',\n",
       " 'gibbs',\n",
       " 'ogden',\n",
       " 'melee',\n",
       " 'sensing',\n",
       " 'pursue',\n",
       " 'backstage',\n",
       " 'basha',\n",
       " 'bowen',\n",
       " 'landmark',\n",
       " 'hades',\n",
       " 'betray',\n",
       " 'kickoff',\n",
       " 'doubted',\n",
       " 'global',\n",
       " 'sprawled',\n",
       " 'relic',\n",
       " 'routledge',\n",
       " 'monsoon',\n",
       " 'pauline',\n",
       " 'petite',\n",
       " 'christophe',\n",
       " 'guangdong',\n",
       " 'phi',\n",
       " 'programme',\n",
       " 'softness',\n",
       " 'afghan',\n",
       " 'envy',\n",
       " 'tactic',\n",
       " 'honoured',\n",
       " 'trustee',\n",
       " 'sophomore',\n",
       " 'stokes',\n",
       " 'anchored',\n",
       " 'isla',\n",
       " 'fortunes',\n",
       " 'ceded',\n",
       " 'bassist',\n",
       " 'bassett',\n",
       " 'refit',\n",
       " 'nantes',\n",
       " 'classmates',\n",
       " 'outrage',\n",
       " 'conquest',\n",
       " 'greenwood',\n",
       " 'prologue',\n",
       " 'simi',\n",
       " 'edo',\n",
       " 'raiding',\n",
       " 'tibet',\n",
       " 'attempts',\n",
       " 'regions',\n",
       " 'jared',\n",
       " 'wiring',\n",
       " 'majors',\n",
       " 'bathurst',\n",
       " 'complaints',\n",
       " 'riff',\n",
       " 'wilkins',\n",
       " 'ravi',\n",
       " 'raj',\n",
       " 'dunbar',\n",
       " 'shielded',\n",
       " 'frazier',\n",
       " 'beta',\n",
       " 'tenant',\n",
       " 'optics',\n",
       " 'hawthorne',\n",
       " 'trades',\n",
       " 'manga',\n",
       " 'coldly',\n",
       " 'steamship',\n",
       " 'steward',\n",
       " 'charred',\n",
       " 'rand',\n",
       " 'ranges',\n",
       " 'jameson',\n",
       " 'clusters',\n",
       " 'laird',\n",
       " 'teammates',\n",
       " 'drones',\n",
       " 'healthcare',\n",
       " 'surreal',\n",
       " 'published',\n",
       " 'onslaught',\n",
       " 'gestured',\n",
       " 'chieftain',\n",
       " 'shreveport',\n",
       " 'lore',\n",
       " 'achieve',\n",
       " 'subdued',\n",
       " 'schooner',\n",
       " 'remake',\n",
       " 'resumed',\n",
       " 'decor',\n",
       " 'roc',\n",
       " 'fades',\n",
       " 'erich',\n",
       " 'noelle',\n",
       " 'simmons',\n",
       " 'homestead',\n",
       " 'hybrids',\n",
       " 'lars',\n",
       " 'zeus',\n",
       " 'lao',\n",
       " 'hasan',\n",
       " 'daly',\n",
       " 'blazing',\n",
       " 'programmed',\n",
       " 'trusts',\n",
       " 'asphalt',\n",
       " 'coulter',\n",
       " 'malley',\n",
       " 'muse',\n",
       " 'retrieved',\n",
       " 'pratt',\n",
       " 'funded',\n",
       " 'lbs',\n",
       " 'launched',\n",
       " 'narrowed',\n",
       " 'backdrop',\n",
       " 'inward',\n",
       " 'porte',\n",
       " 'succumbed',\n",
       " 'serene',\n",
       " 'eerie',\n",
       " 'greed',\n",
       " 'redding',\n",
       " 'maddox',\n",
       " 'garry',\n",
       " 'euros',\n",
       " 'breakup',\n",
       " 'ponder',\n",
       " 'macau',\n",
       " 'stephens',\n",
       " 'vamp',\n",
       " 'ingram',\n",
       " 'gaunt',\n",
       " 'remade',\n",
       " 'wilhelm',\n",
       " 'zinc',\n",
       " 'astro',\n",
       " 'blackness',\n",
       " 'boroughs',\n",
       " 'raoul',\n",
       " 'hawthorn',\n",
       " 'rematch',\n",
       " 'abused',\n",
       " 'stride',\n",
       " 'defects',\n",
       " 'bounds',\n",
       " 'thorpe',\n",
       " 'horst',\n",
       " 'coping',\n",
       " 'guru',\n",
       " 'accord',\n",
       " 'grossed',\n",
       " 'homage',\n",
       " 'ren',\n",
       " 'lashes',\n",
       " 'steered',\n",
       " 'fools',\n",
       " 'fearing',\n",
       " 'idle',\n",
       " 'vents',\n",
       " 'easton',\n",
       " 'diva',\n",
       " 'baja',\n",
       " 'expressed',\n",
       " 'forsyth',\n",
       " 'operas',\n",
       " 'dunne',\n",
       " 'dismissed',\n",
       " 'moaned',\n",
       " 'bellevue',\n",
       " 'teammate',\n",
       " 'rani',\n",
       " 'ensured',\n",
       " 'tinged',\n",
       " 'sermon',\n",
       " 'sheikh',\n",
       " 'cartridge',\n",
       " 'warrant',\n",
       " 'bracing',\n",
       " 'admits',\n",
       " 'weekdays',\n",
       " 'spirits',\n",
       " 'humble',\n",
       " 'embarked',\n",
       " 'accessed',\n",
       " 'staging',\n",
       " 'cox',\n",
       " 'phillies',\n",
       " 'minsk',\n",
       " 'bearded',\n",
       " 'scrolls',\n",
       " 'prefix',\n",
       " 'prophets',\n",
       " 'calder',\n",
       " 'quest',\n",
       " 'texans',\n",
       " 'threatens',\n",
       " 'goodwill',\n",
       " 'grasslands',\n",
       " 'rumours',\n",
       " 'burmese',\n",
       " 'browning',\n",
       " 'lang',\n",
       " 'campaigns',\n",
       " 'peasant',\n",
       " 'blushed',\n",
       " 'goodwin',\n",
       " 'hurdle',\n",
       " 'proposed',\n",
       " 'inmate',\n",
       " 'ports',\n",
       " 'claimed',\n",
       " 'mortals',\n",
       " 'bordered',\n",
       " 'sobs',\n",
       " 'runes',\n",
       " 'earthly',\n",
       " 'suited',\n",
       " 'cocaine',\n",
       " 'shepard',\n",
       " 'magnus',\n",
       " 'robbed',\n",
       " 'savoy',\n",
       " 'schultz',\n",
       " 'emerged',\n",
       " 'wetlands',\n",
       " 'shrug',\n",
       " 'glamour',\n",
       " 'lana',\n",
       " 'surplus',\n",
       " 'plainly',\n",
       " 'leone',\n",
       " 'warns',\n",
       " 'yoon',\n",
       " 'stil',\n",
       " 'borne',\n",
       " 'lush',\n",
       " 'thinkers',\n",
       " 'cum',\n",
       " 'bauer',\n",
       " 'groin',\n",
       " 'confess',\n",
       " 'strains',\n",
       " 'trembled',\n",
       " 'modes',\n",
       " 'renamed',\n",
       " 'firstly',\n",
       " 'hymns',\n",
       " 'provoke',\n",
       " 'della',\n",
       " 'winked',\n",
       " 'unearthed',\n",
       " 'balfour',\n",
       " 'cues',\n",
       " 'debates',\n",
       " 'scheme',\n",
       " 'beale',\n",
       " 'firms',\n",
       " 'brute',\n",
       " 'sneered',\n",
       " 'shouldered',\n",
       " 'viktor',\n",
       " 'crawley',\n",
       " 'rigged',\n",
       " 'opus',\n",
       " 'coleman',\n",
       " 'classmate',\n",
       " 'produced',\n",
       " 'outlawed',\n",
       " 'trio',\n",
       " 'exhaled',\n",
       " 'starbucks',\n",
       " 'retain',\n",
       " 'robyn',\n",
       " 'jorge',\n",
       " 'gateway',\n",
       " 'sidekick',\n",
       " 'quarrel',\n",
       " 'rumored',\n",
       " 'willard',\n",
       " 'gotham',\n",
       " 'taxes',\n",
       " 'expelled',\n",
       " 'perkins',\n",
       " 'posse',\n",
       " 'rapids',\n",
       " 'onstage',\n",
       " 'hasty',\n",
       " 'leith',\n",
       " 'enlarged',\n",
       " 'travers',\n",
       " 'stairwell',\n",
       " 'youths',\n",
       " 'hague',\n",
       " 'shrill',\n",
       " 'marseille',\n",
       " 'learners',\n",
       " 'paused',\n",
       " 'munoz',\n",
       " 'zagreb',\n",
       " 'apt',\n",
       " 'cowan',\n",
       " 'amore',\n",
       " 'sao',\n",
       " 'legion',\n",
       " 'doctrines',\n",
       " 'rio',\n",
       " 'poole',\n",
       " 'wry',\n",
       " 'ric',\n",
       " 'protests',\n",
       " 'coaching',\n",
       " 'authored',\n",
       " 'unchanged',\n",
       " 'jong',\n",
       " 'marche',\n",
       " 'banning',\n",
       " 'charlton',\n",
       " 'cobb',\n",
       " 'prakash',\n",
       " 'stacey',\n",
       " 'glint',\n",
       " 'leland',\n",
       " 'tulane',\n",
       " 'pristine',\n",
       " 'tenor',\n",
       " 'zombies',\n",
       " 'thrive',\n",
       " 'rents',\n",
       " 'sikh',\n",
       " 'bayer',\n",
       " 'longing',\n",
       " 'keating',\n",
       " 'roth',\n",
       " 'hume',\n",
       " 'lodges',\n",
       " 'commence',\n",
       " 'sited',\n",
       " 'laval',\n",
       " 'demons',\n",
       " 'minors',\n",
       " 'soyuz',\n",
       " 'winfield',\n",
       " 'beaux',\n",
       " 'backbone',\n",
       " 'benoit',\n",
       " 'hallmark',\n",
       " 'enrolled',\n",
       " 'revealed',\n",
       " 'falkland',\n",
       " 'neighbours',\n",
       " 'verlag',\n",
       " 'burden',\n",
       " 'hooded',\n",
       " 'leaps',\n",
       " 'peyton',\n",
       " 'sights',\n",
       " 'hepburn',\n",
       " 'jimmie',\n",
       " 'quentin',\n",
       " 'canton',\n",
       " 'wounded',\n",
       " 'imports',\n",
       " 'textiles',\n",
       " 'honour',\n",
       " 'campaigned',\n",
       " 'braden',\n",
       " 'facade',\n",
       " 'hays',\n",
       " 'mendes',\n",
       " 'excerpt',\n",
       " 'bombing',\n",
       " 'oldham',\n",
       " 'factors',\n",
       " 'atoms',\n",
       " 'sermons',\n",
       " 'forts',\n",
       " 'hastings',\n",
       " 'stilled',\n",
       " 'amounts',\n",
       " 'vein',\n",
       " 'jem',\n",
       " 'sloping',\n",
       " 'deposed',\n",
       " 'rollins',\n",
       " 'curate',\n",
       " 'counties',\n",
       " 'torso',\n",
       " 'reggae',\n",
       " 'fares',\n",
       " 'gunter',\n",
       " 'marquette',\n",
       " 'strive',\n",
       " 'recruit',\n",
       " 'marley',\n",
       " 'cores',\n",
       " 'larvae',\n",
       " 'lew',\n",
       " 'frigate',\n",
       " 'witty',\n",
       " 'devlin',\n",
       " 'lowers',\n",
       " 'leach',\n",
       " 'hampered',\n",
       " 'passions',\n",
       " 'cuthbert',\n",
       " 'oldies',\n",
       " 'slumped',\n",
       " 'diffuse',\n",
       " 'sway',\n",
       " 'lobe',\n",
       " 'balkans',\n",
       " 'upgrades',\n",
       " 'marko',\n",
       " 'cadiz',\n",
       " 'suffers',\n",
       " 'nouvelle',\n",
       " 'bismarck',\n",
       " 'profiles',\n",
       " 'schoolhouse',\n",
       " 'winners',\n",
       " 'sheffield',\n",
       " 'endorsed',\n",
       " 'ata',\n",
       " 'odin',\n",
       " 'swedish',\n",
       " 'warships',\n",
       " 'chorale',\n",
       " 'lux',\n",
       " 'constrained',\n",
       " 'delta',\n",
       " 'walters',\n",
       " 'whorls',\n",
       " 'holstein',\n",
       " 'winkler',\n",
       " 'darryl',\n",
       " 'siege',\n",
       " 'bidding',\n",
       " 'jozef',\n",
       " 'walton',\n",
       " 'galen',\n",
       " 'irving',\n",
       " 'sprinted',\n",
       " 'lectures',\n",
       " 'fragment',\n",
       " 'kassel',\n",
       " 'faintly',\n",
       " 'snowfall',\n",
       " 'albans',\n",
       " 'vortex',\n",
       " 'meanings',\n",
       " 'trojan',\n",
       " 'brent',\n",
       " 'lal',\n",
       " 'chao',\n",
       " 'jonas',\n",
       " 'bombay',\n",
       " 'gaul',\n",
       " 'voss',\n",
       " 'nunez',\n",
       " 'barrie',\n",
       " 'consume',\n",
       " 'crimson',\n",
       " 'skilled',\n",
       " 'uber',\n",
       " 'drifting',\n",
       " 'converts',\n",
       " 'walden',\n",
       " 'alma',\n",
       " 'dharma',\n",
       " 'reefs',\n",
       " 'duo',\n",
       " 'guarded',\n",
       " 'ensures',\n",
       " 'typhoon',\n",
       " 'slaughtered',\n",
       " 'myanmar',\n",
       " 'neural',\n",
       " 'promo',\n",
       " 'talon',\n",
       " 'nan',\n",
       " 'verdi',\n",
       " 'chopin',\n",
       " 'scotia',\n",
       " 'imam',\n",
       " 'prefect',\n",
       " 'sonic',\n",
       " 'morse',\n",
       " 'kapoor',\n",
       " 'yields',\n",
       " 'graf',\n",
       " 'faulkner',\n",
       " 'backstroke',\n",
       " 'defunct',\n",
       " 'drummond',\n",
       " 'landau',\n",
       " 'ceased',\n",
       " 'bel',\n",
       " 'sino',\n",
       " 'jagger',\n",
       " 'torres',\n",
       " 'dane',\n",
       " 'rasped',\n",
       " 'deployed',\n",
       " 'roma',\n",
       " 'hindus',\n",
       " 'mating',\n",
       " 'forbade',\n",
       " 'grading',\n",
       " 'sichuan',\n",
       " 'squads',\n",
       " 'bishops',\n",
       " 'steiner',\n",
       " 'xiang',\n",
       " 'labour',\n",
       " 'implant',\n",
       " 'aide',\n",
       " 'clayton',\n",
       " 'moines',\n",
       " 'castes',\n",
       " 'expense',\n",
       " 'obtain',\n",
       " 'quakers',\n",
       " 'weakened',\n",
       " 'nasa',\n",
       " 'temperate',\n",
       " 'yemen',\n",
       " 'arson',\n",
       " 'horsemen',\n",
       " 'orbit',\n",
       " 'laos',\n",
       " 'inlet',\n",
       " ...}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(cmu_in_childes_with_tokenizer.word) - set(cmu_in_childes.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a aa aah aardvark aardvarks aaron aaron's ab abba abbey abbie abby abe able aboard about above abra abroad absent absorb abstract absurd abu abuse ac accent accept access account accused ace aces ache aches aching achoo acid ack acorn acorns acre acres across act acted acting action actions active actor actress acts ad ada adah adam adam's adams adar aday add added adder addict addie adding address addressed adds ade adele adele's adjust admire admit ado adopt adore adores adrift ads adult adults advance advanced advent advice ady ae aero afar affect affects afford afloat afraid afro aft after ag aga again against age aged agent ages aggie aggy agnes ago agra agree agreed agrees agua ah ahah ahead ahh ahn ahold ahoy ai aid aidan aiden aids aiken aim aimed aimee aiming ain't air air's airborne aircraft airing airline airmail airplane airplane's airplanes airport airports airship ais aisha aisle aisles aislinn ajax aka akbar al al's ala alan alan's alarm alarm's alarms albert album albums alcove ale alec alert alex alf alfa alfie alfred algae ali ali's alice alight alike alive all all's alla allan allen alley alleys alli allie allow allowed alls ally almond almonds almost alone along aloud alpha alright als also alter although alvin always aly am amazed amber ambrose ambush amen ames amherst amish among amongst amount amused amy amy's an ana anchor anchors ancient and andre andrew andrew's ands andy andy's ang angel angel's angels anger angie angle angles angry ankle ankles ann ann's anna anna's anne anne's annette annie annie's announced annoy annoyed ano answer answered answers ant anthill anti antique antlers ants antsy anxious any ap apart ape apes aphids apiece app appalled appeal appear appeared appears appel applause apple apple's apples applied apply approach approached approve april april's apron aprons aqua ar ara aran arbor arc arcade arch arched archers arches archie archway arctic are aren't ares argh argon argue argued ari arise ark arlene arm arm's armband armbands armchair armed armies armor armored armpit arms army arnold around arrange arranged array arrest arrive arrived arrives arrow arrow's arrows art arthur arthur's artist artists arts artwork as asda ash ashamed asher ashes ashley ashore ashton ashtray ashworth asia asian aside ask asked asking asks asleep aspirin ass assume assumed assure asthma aston astra astrid at ate aten atlas atta attach attached attack attacked attacks attempt attend attic attract attracts au auburn auch auction audrey august aunt aunt's auntie aunts austin author author's authors autumn ava ave avi avis avoid avon avril aw awake award aware away aways awe awesome awful awhile awkward ax axe axel axes axle ay aye ayo ayres azar b ba bab baba baba's babar babar's babble babe babes babette babies babies' baboon baboons baby baby's back backed backer background backhoe backing backpack backpacks backs backside backup backward backwards backyard bacon bad bada badge badger badger's badgers badges badly bae baek baffled bag bagel bagels baggage bagged baggie bagging baggy bagpipes bags bah bail bailey bailey's bails bait bak bake baked baker baker's bakers bakes baking bal balance balanced bald bales ball ball's baller ballet ballgame balling ballon balloon balloons ballroom balls bally bam bambi bamboo ban band bandage bandaged bandaid bandit bandits bands bandy bang banged banger banging bangle bangles bangor bangs banjo bank banks banner banners banquet bantam bar barb barbell barbells barber barber's barbers barbie barbie's barbies barbra bare barefoot barely bargain barge bark barked barking barkley barks barley barn barnes barney barney's barneys barns barnyard baron barr barrel barrels barret barrette barron barrow barry bars bart base baseball baseball's based basement bases bash bashed basher bashes bashful bashing basic basil basin basis basket baskets baskin bass bassoon bat batch bath bathe bathed bathing bathrobe bathroom bathrooms baths bathtub bathtubs batman baton bats batter battered batters batting battle batty bauble baubles bauch baum bawl bax baxter bay be bea beach beaches beacon bead beads beady beagle beagles beak beaker beam beams bean beans bear bear's beard beards bearer bearing bears bears' beast beastie beastly beasts beat beaten beater beaters beating beatle beatles beats beauty beaver beavers bebe bec became because becca beck becka becky become becomes bed bedding bedroom bedrooms beds bedside bedtime bee bee's beech beechy beef beehive beek beem been beep beeped beeper beeping beeps beer beers bees beet beetle beetles beets before beg began beggar beggars begged begging begin begins begot begun behave behaved behind behold beige being beings belch belfast believe believed believes bell bell's bella belle bellies bellow bellowed bellows bells belly belong belonged belongs below belt belts ben ben's bena bench benches bend bended bending bends beneath bennett benny bent bentley benton beret berkeley berlin bernard bernice bernie berries berry berserk bert bertie bertram bes beside besides bess bessy best bet betcha beth beth's betsy betta better betting betty betty's between beulah bev beware bewitched beyond bi bib bibby bible bibs bic bick bid biddle biddy biff big bigger biggest biggie bigs bike biker bikes bil bilby bill bill's billed billet billie billions bills billy billy's bin binder binding bing bingo bink bins bip biplane bir bird bird's birdhouse birdie birdies birds birdy biro biros birt birth birthday birthdays bis biscuit biscuits bish bishop bit bitch bite biter bites biting bits bitsy bitten bitter bitty biz bizarre bizzy black black's blackbird blackbirds blackboard blackie blackpool blacks blade blades blading blah blair blake blakey blame blamed blaming blanche bland blank blanket blankets blast blasted blaster blasting blasts blaze blazer bleach blech bled bleed bleeding bleeds bleep blend blender blending blends bless blessed blessing blessings blew blick blimp blind blindfold blinds blink blinked blinking blinks blip blips bliss blister blisters blitzen blizzard blob blobby blobs block block's blocked blocking blocks bloke blond blonde blondie blood blooded bloody bloom bloomer blooming blose blossom blossoms blot blotted blouse blouses blow blowed blower blowing blown blows blowy blue blue's bluebell bluebells bluebird bluebirds blueish bluejay bluejeans blues bluey blum blumstein blunt blur blurred blurry bo boa boar board board's boarded boarder boarding boards\""
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(cmu_in_childes.word[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index              71\n",
       "word                a\n",
       "pronunciation     AH0\n",
       "phones           [AH]\n",
       "ipa               [ə]\n",
       "ipa_short           ə\n",
       "structure         [v]\n",
       "num_vowels          1\n",
       "Name: 70, dtype: object"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_childes.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>phones</th>\n",
       "      <th>ipa</th>\n",
       "      <th>ipa_short</th>\n",
       "      <th>structure</th>\n",
       "      <th>num_vowels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48256</th>\n",
       "      <td>48257</td>\n",
       "      <td>goat</td>\n",
       "      <td>G OW1 T</td>\n",
       "      <td>[G, OW, T]</td>\n",
       "      <td>[ɡ, oʊ, t]</td>\n",
       "      <td>ɡoʊt</td>\n",
       "      <td>[c, v, c]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  word pronunciation      phones         ipa ipa_short  structure  \\\n",
       "48256  48257  goat       G OW1 T  [G, OW, T]  [ɡ, oʊ, t]      ɡoʊt  [c, v, c]   \n",
       "\n",
       "       num_vowels  \n",
       "48256           1  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_childes.loc[cmu_in_childes.word == 'goat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_in_childes.to_csv('phon/cmu_in_childes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levdist</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>1</td>\n",
       "      <td>boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85141</th>\n",
       "      <td>1</td>\n",
       "      <td>oat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131327</th>\n",
       "      <td>1</td>\n",
       "      <td>wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22381</th>\n",
       "      <td>1</td>\n",
       "      <td>coat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131340</th>\n",
       "      <td>1</td>\n",
       "      <td>woe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47706</th>\n",
       "      <td>10</td>\n",
       "      <td>girlfriends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14887</th>\n",
       "      <td>10</td>\n",
       "      <td>bridesmaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113531</th>\n",
       "      <td>10</td>\n",
       "      <td>sprinklers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121981</th>\n",
       "      <td>10</td>\n",
       "      <td>transcribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121982</th>\n",
       "      <td>11</td>\n",
       "      <td>transcribed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12557 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        levdist    candidate\n",
       "12650         1         boat\n",
       "85141         1          oat\n",
       "131327        1           wo\n",
       "22381         1         coat\n",
       "131340        1          woe\n",
       "...         ...          ...\n",
       "47706        10  girlfriends\n",
       "14887        10   bridesmaid\n",
       "113531       10   sprinklers\n",
       "121981       10   transcribe\n",
       "121982       11  transcribed\n",
       "\n",
       "[12557 rows x 2 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_levidsts(target, cmu):\n",
    "    distances = [Levenshtein.distance(target,x) for x in cmu_in_childes.ipa_short]\n",
    "    dist_df = pd.DataFrame({'levdist':distances,'candidate':cmu_in_childes.word})\n",
    "    return(dist_df.sort_values(by=['levdist']))\n",
    "\n",
    "get_levidsts('woʊt', cmu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-directed-listening",
   "language": "python",
   "name": "child-directed-listening"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
