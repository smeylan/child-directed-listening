{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fc9578e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_rep_dir = './finetune_rep'\n",
    "prov_rep_dir = './prov_rep'\n",
    "\n",
    "finetune_true_dir = './finetune'\n",
    "prov_true_dir = './prov'\n",
    "\n",
    "fill_na = '______'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3d218440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All on months = 36.\n",
    "# I don't recall specifically if the code was exactly the same on both runs\n",
    "# but am testing replication and don't recall making any changes to code logic (I think at most to imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f561053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_gen, load_splits\n",
    "from utils_child import child_models\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "import config\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7d5a1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_args = config.childes_model_args + [('child', name) for name in child_models.get_child_names()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ff2d82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_na(df1, df2):\n",
    "    return df1.fillna(fill_na).equals(df2.fillna(fill_na))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10553dd",
   "metadata": {},
   "source": [
    "Need to manually set the finetune_dir and prov_dir in config.py, then run these functions after total regeneration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f95e3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# Check that the text files match for all of the splits, for the tags version.\n",
    "# Young and old are implicit in the checks.\n",
    "\n",
    "def get_texts(split, name, phase, base_dir):\n",
    "    \n",
    "    this_split_loc = split_gen.get_split_folder(split, name, base_dir)\n",
    "    with open(join(this_split_loc, f\"{phase}.txt\"), 'r') as f:\n",
    "        return f.readlines()\n",
    "        \n",
    "for s, d in all_args:\n",
    "    for this_phase in ['train', 'val']:\n",
    "        assert get_texts(s, d, this_phase, finetune_rep_dir) == get_texts(s, d, this_phase, finetune_true_dir), f\"Failed on: {s}, {d}\"\n",
    "\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0bb4ce3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "# Check that the vocabulary file (from CHILDES) also matches everything\n",
    "\n",
    "def get_vocab(base_dir):\n",
    "    this_folder = split_gen.get_split_folder('all', 'all', base_dir)\n",
    "    # Drop index, leave the two data columns (word, count) -- or pd.equals will try to compare on non-data parts.\n",
    "    return pd.read_csv(join(this_folder, 'chi_vocab_train.csv')).sort_values(by = ['count', 'word'], ascending = False).reset_index(drop = True)[['word', 'count']]\n",
    "\n",
    "dfv1 = get_vocab(finetune_rep_dir)\n",
    "dfv2 = get_vocab(finetune_true_dir)\n",
    "\n",
    "assert compare_with_na(dfv1, dfv2)\n",
    "\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69514c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the all_tokens_phono dataframe matches -- be careful for NaN issues here.\n",
    "\n",
    "def get_this_phono(base_dir):\n",
    "    return pd.read_pickle(join(base_dir, 'pvd_all_tokens_phono_for_eval.pkl'))\n",
    "    \n",
    "assert compare_with_na(get_this_phono(prov_rep_dir), get_this_phono(prov_true_dir))\n",
    "\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ed7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_paths(folder):\n",
    "    return sorted(glob.glob(join(folder, '*')))\n",
    "    \n",
    "base_time = 'across_time_samples'\n",
    "\n",
    "all_rep = sorted(get_paths(join(prov_rep_dir, base_time)))\n",
    "all_compare = sorted(get_paths(join(prov_true_dir, base_time)))\n",
    "\n",
    "for p1, p2 in zip(all_rep, all_compare):\n",
    "    assert pd.read_csv(p1).equals(pd.read_csv(p2)), f\"Failed on path: {p1}\"\n",
    "    \n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919cd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare loading the beta values\n",
    "\n",
    "def get_beta_paths(base_prov_dir, arg_set = all_args):\n",
    "    \n",
    "    all_beta_samples = [\n",
    "        pd.read_csv(join(split_gen.get_split_folder(s, d, base_prov_dir), 'success_utts_beta_5000_val.csv'))\n",
    "        for s, d in arg_set\n",
    "    ]\n",
    "        \n",
    "    return all_beta_samples\n",
    "\n",
    "for sample1, sample2 in zip(get_beta_paths(prov_true_dir), get_beta_paths(prov_rep_dir)):\n",
    "    assert sample1.equals(sample2)\n",
    "\n",
    "print(\"Passed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-listening-env",
   "language": "python",
   "name": "child-listening-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
