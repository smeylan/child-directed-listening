{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/home/stephan/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstalling childesr version 0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/childesr_0.2.3.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 22865 bytes (22 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 22 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/Rtmpy0l71W/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "import childespy\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import re\n",
    "import unicodedata\n",
    "import scipy.stats\n",
    "import copy\n",
    "from string import punctuation\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "from src.utils import configuration, load_models, transformers_bert_completions, data_cleaning, phonology\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify \"Communicative Successes\" and \"Communicative Failures\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defintions:  \n",
    "`xxx`: no lexical label, phonetically un-transcribable  \n",
    "`yyy`: no lexical label, phonetically transcribable  \n",
    "`Communicative success`: token from utterances with no xxx's or yyy's   \n",
    "`Communicative failure`: a yyy token from an utterance with no other xxx's or yyy's\n",
    "\n",
    "Later, we'll further restrict both to tokens that are monosyllabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"', db_version = \"2020.1\").iloc[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phono_glosses = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, actual_phonology, model_phonology, transcript_id, utterance_id, \\\n",
    "    token_order, corpus_name, collection_name, language from token where \\\n",
    "    actual_phonology != \"\" and model_phonology != \"\" and speaker_code in (\"MOT\", \"FAT\",\"CHI\") and collection_name = \"Eng-NA\" \\\n",
    "    and corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Providence    396621\n",
       "Name: corpus_name, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phono_glosses.corpus_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*              26736\n",
       "ə                 10\n",
       "(.)                7\n",
       "aɪ                 4\n",
       "hiɡh               2\n",
       "               ...  \n",
       "maɪː               1\n",
       "ʊijæwɪdʒpaʊ        1\n",
       "noises             1\n",
       "maɪ                1\n",
       "səmaɪn             1\n",
       "Name: actual_phonology, Length: 76, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phono_glosses.loc[phono_glosses.gloss == 'xxx'].actual_phonology.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual phonology is almost always * for xxx items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ɛ          3206\n",
       "ʌ          2132\n",
       "ɪ          1881\n",
       "ə           512\n",
       "o           507\n",
       "           ... \n",
       "m̩seɪt        1\n",
       "waɪwaɪ        1\n",
       "aɪbəm         1\n",
       "hukɪk         1\n",
       "twæːɡoː       1\n",
       "Name: actual_phonology, Length: 30293, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phono_glosses.loc[phono_glosses.gloss == 'yyy'].actual_phonology.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual phonology *is* populated for tokens with `yyy` lexical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_phono = phono_glosses.loc[(phono_glosses.speaker_code == 'CHI') & \n",
    "    (phono_glosses.target_child_age < (365*5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_transmission_errors(utt_vector, error_codes):\n",
    "    return(np.sum([x in error_codes for x in  utt_vector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxs_per_utt = chi_phono.groupby('utterance_id').gloss.agg(\n",
    "    lambda x: count_transmission_errors(x, ['xxx'])).reset_index()\n",
    "xxxs_per_utt.columns = ['utterance_id', 'num_xxx']\n",
    "yyys_per_utt = chi_phono.groupby('utterance_id').gloss.agg(\n",
    "    lambda x: count_transmission_errors(x, ['yyy'])).reset_index()\n",
    "yyys_per_utt.columns = ['utterance_id', 'num_yyy']\n",
    "failures_per_utt = xxxs_per_utt.merge(yyys_per_utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_utts = failures_per_utt.loc[(failures_per_utt.num_xxx == 0) &  (failures_per_utt.num_yyy == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31457, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_utts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_utts = failures_per_utt.loc[(failures_per_utt.num_xxx == 0) &  \n",
    "    (failures_per_utt.num_yyy == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83880, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_utts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_from_errorless_utts = chi_phono.loc[chi_phono.utterance_id.isin(success_utts.utterance_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude un-transcribed tokens and syllabically transcribed tokens\n",
    "excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "tokens_from_errorless_utts = tokens_from_errorless_utts.loc[~(tokens_from_errorless_utts.actual_phonology.isin(excludes) |\n",
    "    tokens_from_errorless_utts.model_phonology.isin(excludes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214239, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_from_errorless_utts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          ɑmɪ\n",
       "3          wiː\n",
       "4          wiː\n",
       "5           uː\n",
       "52           ɛ\n",
       "          ... \n",
       "396606       o\n",
       "396607     waɪ\n",
       "396608     liʔ\n",
       "396609       ɪ\n",
       "396610    hɪpo\n",
       "Name: actual_phonology, Length: 214239, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example phonology\n",
    "tokens_from_errorless_utts.actual_phonology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31,457 transmission errors (from 31,457 utterances)\n",
    "# 214,239 transmission successes (from 83,880 utterances)\n",
    "# this will be further decreased later by the need to test monosyllabic forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BERT Models + CMU Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the CMU Pronunciation Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(configuration)\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_in_childes = pd.read_pickle(config.cmu_path)\n",
    "cmu_2syl_inchildes = cmu_in_childes.loc[cmu_in_childes.num_vowels <=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8943, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_childes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Utterances / Tokens for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load utterances from the Providence corpus from childs-db\n",
    "\n",
    "this_path = join(config.prov_csv_dir, 'pvd_utt_glosses.csv')\n",
    "if config.regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, target_child_name, speaker_code, type from utterance where speaker_code in (\"MOT\", \"FAT\",\"CHI\") and corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv(this_path, index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv(this_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses = utt_glosses.rename(columns = {'id' : 'utterance_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep the utterances for tokenization with BERT. Importantly, add back the appropriate punctutation for the sentence type\n",
    "utt_glosses = utt_glosses[~utt_glosses.gloss.isna()]\n",
    "utt_glosses = data_cleaning.clean_glosses(utt_glosses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils.transformers_bert_completions' from '/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/transformers_bert_completions.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(load_models)\n",
    "imp.reload(transformers_bert_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tokenizer = load_models.get_primary_tokenizer()\n",
    "initial_vocab, cmu_in_initial_vocab, cmu_indices_for_initial_vocab = load_models.get_initial_vocab_info(initial_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab mask contains 7997 entries (written words)\n",
      "CMU pronuncitaiton dictionary has 8943 entries\n",
      "CMU pronuncitaiton dictionary may have multiple entries for each word\n"
     ]
    }
   ],
   "source": [
    "print('Vocab mask contains '+str(len(initial_vocab))+' entries (written words)') \n",
    "print('CMU pronuncitaiton dictionary has '+str(cmu_in_initial_vocab.shape[0])+ ' entries')\n",
    "print('CMU pronuncitaiton dictionary may have multiple entries for each word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm yyy treated as a separate character\n",
    "if 'yyy' not in initial_tokenizer.tokenize('this is a yyy.'):\n",
    "    raise ValueError('yyy must be treated as a separate character; check the tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataframe of tokens \n",
    "# this is slow, because tokenization is slow and single-core\n",
    "def inflate(row):\n",
    "    tokens = initial_tokenizer.tokenize(row['gloss_with_punct'])\n",
    "    return(pd.DataFrame({'token':tokens, 'utterance_id':row['utterance_id']}) )\n",
    "\n",
    "inflate_path = join(config.prov_csv_dir, 'pvd_utt_glosses_inflated.csv')\n",
    "if config.regenerate:\n",
    "    all_tokens = pd.concat([inflate(x) for x in utt_glosses.to_dict('records')])\n",
    "    all_tokens = all_tokens.merge(utt_glosses)\n",
    "    all_tokens.to_csv(inflate_path)\n",
    "\n",
    "else:\n",
    "    all_tokens = pd.read_csv(inflate_path, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "      <th>punct</th>\n",
       "      <th>speaker_code_simple</th>\n",
       "      <th>gloss_with_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cgv]</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anywhere</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ll</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feel</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comfortable</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>um</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anywhere</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  utterance_id                                         gloss  \\\n",
       "0        [cgv]      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "1     anywhere      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "2          you      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "3            '      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "4           ll      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "5         feel      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "6  comfortable      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "7           um      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "8     anywhere      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "9            .      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "\n",
       "   transcript_id  utterance_order target_child_name speaker_code         type  \\\n",
       "0          42204                2              Alex          MOT  declarative   \n",
       "1          42204                2              Alex          MOT  declarative   \n",
       "2          42204                2              Alex          MOT  declarative   \n",
       "3          42204                2              Alex          MOT  declarative   \n",
       "4          42204                2              Alex          MOT  declarative   \n",
       "5          42204                2              Alex          MOT  declarative   \n",
       "6          42204                2              Alex          MOT  declarative   \n",
       "7          42204                2              Alex          MOT  declarative   \n",
       "8          42204                2              Alex          MOT  declarative   \n",
       "9          42204                2              Alex          MOT  declarative   \n",
       "\n",
       "  punct speaker_code_simple                                   gloss_with_punct  \n",
       "0     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "1     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "2     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "3     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "4     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "5     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "6     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "7     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "8     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "9     .               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a token_id (integer in the BERT vocabulary). \n",
    "# Because these are from the tokenized utterances, there is no correpsondence \n",
    "# with childes-db token ids\n",
    "all_tokens['token_id'] = initial_tokenizer.convert_tokens_to_ids(all_tokens['token'])\n",
    "# assigns utterances a 0-indexed index column\n",
    "all_tokens['seq_utt_id'] = all_tokens['utterance_id'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add back IPA, syllable structure, and child ages for child productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/child-directed-listening-env/lib/python3.8/site-packages/pandas/core/frame.py:1485: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% complete...\n",
      "2.0% complete...\n",
      "3.0% complete...\n",
      "4.0% complete...\n",
      "5.0% complete...\n",
      "6.0% complete...\n",
      "7.0% complete...\n",
      "8.0% complete...\n",
      "9.0% complete...\n",
      "10.0% complete...\n",
      "11.0% complete...\n",
      "12.0% complete...\n",
      "13.0% complete...\n",
      "14.0% complete...\n",
      "15.0% complete...\n",
      "16.0% complete...\n",
      "17.0% complete...\n",
      "18.0% complete...\n",
      "19.0% complete...\n",
      "20.0% complete...\n",
      "21.0% complete...\n",
      "22.0% complete...\n",
      "23.0% complete...\n",
      "24.0% complete...\n",
      "25.0% complete...\n",
      "26.0% complete...\n",
      "27.0% complete...\n",
      "28.0% complete...\n",
      "29.0% complete...\n",
      "30.0% complete...\n",
      "31.0% complete...\n",
      "32.0% complete...\n",
      "33.0% complete...\n",
      "33.99% complete...\n",
      "34.99% complete...\n",
      "35.99% complete...\n",
      "36.99% complete...\n",
      "37.99% complete...\n",
      "38.99% complete...\n",
      "39.99% complete...\n",
      "40.99% complete...\n",
      "41.99% complete...\n",
      "42.99% complete...\n",
      "43.99% complete...\n",
      "44.99% complete...\n",
      "45.99% complete...\n",
      "46.99% complete...\n",
      "47.99% complete...\n",
      "48.99% complete...\n",
      "49.99% complete...\n",
      "50.99% complete...\n",
      "51.99% complete...\n",
      "52.99% complete...\n",
      "53.99% complete...\n",
      "54.99% complete...\n",
      "55.99% complete...\n",
      "56.99% complete...\n",
      "57.99% complete...\n",
      "58.99% complete...\n",
      "59.99% complete...\n",
      "60.99% complete...\n",
      "61.99% complete...\n",
      "62.99% complete...\n",
      "63.99% complete...\n",
      "64.99% complete...\n",
      "65.99% complete...\n",
      "66.99% complete...\n",
      "67.99% complete...\n",
      "68.99% complete...\n",
      "69.99% complete...\n",
      "70.99% complete...\n",
      "71.99% complete...\n",
      "72.99% complete...\n",
      "73.99% complete...\n",
      "74.99% complete...\n",
      "75.99% complete...\n",
      "76.99% complete...\n",
      "77.99% complete...\n",
      "78.99% complete...\n",
      "79.99% complete...\n",
      "80.99% complete...\n",
      "81.99% complete...\n",
      "82.99% complete...\n",
      "83.99% complete...\n",
      "84.99% complete...\n",
      "85.99% complete...\n",
      "86.99% complete...\n",
      "87.99% complete...\n",
      "88.99% complete...\n",
      "89.99% complete...\n",
      "90.99% complete...\n",
      "91.99% complete...\n",
      "92.99% complete...\n",
      "93.99% complete...\n",
      "94.99% complete...\n",
      "95.99% complete...\n",
      "96.99% complete...\n",
      "97.99% complete...\n",
      "98.99% complete...\n",
      "99.98% complete...\n"
     ]
    }
   ],
   "source": [
    "# get the token-level data, esp phonology\n",
    "\n",
    "save_phono_inflated_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_inflated.pkl')\n",
    "\n",
    "if config.regenerate:\n",
    "\n",
    "    # get token-level information for Providence\n",
    "    pvd_chi_tokens = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, actual_phonology, model_phonology, transcript_id, utterance_id, \\\n",
    "    token_order from token where speaker_code = \"CHI\" and corpus_id = '+str(pvd_idx),\n",
    "        db_version = \"2020.1\")\n",
    "    pvd_chi_tokens['gloss'] = [data_cleaning.fix_gloss(x) for x in pvd_chi_tokens.gloss]\n",
    "    \n",
    "    # prep the tokens generated from segmenting the utterances\n",
    "    all_tokens_test = copy.deepcopy(all_tokens) \n",
    "\n",
    "    # initialize the fields that need to be populated\n",
    "    all_tokens_test['actual_phonology'] = ''\n",
    "    all_tokens_test['model_phonology'] = ''\n",
    "    all_tokens_test['target_child_age'] = np.nan\n",
    "    \n",
    "    # get a set of unique utterances\n",
    "    _, idx = np.unique(all_tokens_test.utterance_id, return_index=True)\n",
    "    all_utt_indices = all_tokens_test.utterance_id[np.sort(idx)]\n",
    "    \n",
    "    # For fast retrieval of IPA, split pvd_chi_tokens into a dictionary\n",
    "    pvd_chi_tokens_list = pvd_chi_tokens.groupby(['utterance_id'])\n",
    "    pvd_chi_tokens_dict = dict(zip(\n",
    "        [x[0] for x in pvd_chi_tokens_list], \n",
    "        [x[1] for x in pvd_chi_tokens_list], \n",
    "    ))\n",
    "    \n",
    "    # For fast retrival of BERT tokenization\n",
    "    all_tokens_test_list = all_tokens_test.groupby(['utterance_id'])\n",
    "    all_tokens_test_dict = dict(zip(\n",
    "        [x[0] for x in all_tokens_test_list], \n",
    "        [x[1] for x in all_tokens_test_list], \n",
    "    ))\n",
    "        \n",
    "    # Augment the tokens from all_tokens with the IPA from pvd_chi_tokens \n",
    "    rvs = [] \n",
    "    utts_to_retrieve = yyy_utts.utterance_id.to_list() + success_utts.utterance_id.to_list()\n",
    "    i=-1\n",
    "    for utt_index in all_utt_indices: #utts_to_retrieve: #[16760331]:       \n",
    "        i+=1\n",
    "        if i % int(len(all_utt_indices) / 100) == 0:\n",
    "            print(str(np.round((i / (len(all_utt_indices)) * 100),2))+'% complete...')    \n",
    "            # should learn to use tqdm instead\n",
    "        if utt_index in utts_to_retrieve:        \n",
    "            utt_df = copy.deepcopy(all_tokens_test_dict[utt_index])\n",
    "            utt_df['model_phonology'] = transformers_bert_completions.augment_with_ipa(\n",
    "              utt_df, pvd_chi_tokens_dict[utt_index],initial_tokenizer, 'model_phonology')\n",
    "            utt_df['actual_phonology'] = transformers_bert_completions.augment_with_ipa(\n",
    "              utt_df, pvd_chi_tokens_dict[utt_index],initial_tokenizer, 'actual_phonology')\n",
    "            utt_df['target_child_age'] = pvd_chi_tokens_dict[utt_index].iloc[0].target_child_age    \n",
    "            rvs.append(utt_df)  \n",
    "        else:\n",
    "            rvs.append(all_tokens_test_dict[utt_index])  \n",
    "            \n",
    "    # get the resulting augmented forms back into a dataframe\n",
    "    all_tokens_phono = pd.concat(rvs)\n",
    "    \n",
    "    # add a unique identifier to the BERT tokens\n",
    "    all_tokens_phono['bert_token_id'] = range(all_tokens_phono.shape[0])\n",
    "    \n",
    "    #save the results\n",
    "    all_tokens_phono.to_pickle(save_phono_inflated_path)\n",
    "else:\n",
    "    all_tokens_phono = pd.read_pickle(save_phono_inflated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in set(list(' '.join(pvd_chi_tokens['actual_phonology'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mommy</td>\n",
       "      <td>ɑmɪ</td>\n",
       "      <td>mɑmiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>yyy</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>wee</td>\n",
       "      <td>wiː</td>\n",
       "      <td>wiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>yyy</td>\n",
       "      <td>aʊ</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>wee</td>\n",
       "      <td>wiː</td>\n",
       "      <td>wiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991828</th>\n",
       "      <td>nobody</td>\n",
       "      <td>nobɑɾi</td>\n",
       "      <td>noʊbɑdiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991829</th>\n",
       "      <td>hates</td>\n",
       "      <td>heɪs</td>\n",
       "      <td>heɪts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991834</th>\n",
       "      <td>oh</td>\n",
       "      <td>o</td>\n",
       "      <td>oʊ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991835</th>\n",
       "      <td>why</td>\n",
       "      <td>waɪ</td>\n",
       "      <td>waɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991836</th>\n",
       "      <td>lick</td>\n",
       "      <td>liʔ</td>\n",
       "      <td>lɪk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254517 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          token actual_phonology model_phonology\n",
       "23        mommy              ɑmɪ           mɑmiː\n",
       "55          yyy                ʌ               *\n",
       "125         wee              wiː             wiː\n",
       "128         yyy               aʊ               *\n",
       "151         wee              wiː             wiː\n",
       "...         ...              ...             ...\n",
       "2991828  nobody           nobɑɾi        noʊbɑdiː\n",
       "2991829   hates             heɪs           heɪts\n",
       "2991834      oh                o              oʊ\n",
       "2991835     why              waɪ             waɪ\n",
       "2991836    lick              liʔ             lɪk\n",
       "\n",
       "[254517 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the IPA\n",
    "all_tokens_phono.loc[all_tokens_phono.actual_phonology != ''][['token','actual_phonology','model_phonology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently handling * in IPA by dropping from consideration in num_vowels.\n",
      "Currently handling * in IPA by dropping from consideration in num_vowels.\n"
     ]
    }
   ],
   "source": [
    "cleaned_inflated_save = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated.pkl')\n",
    "\n",
    "if config.regenerate:    \n",
    "\n",
    "    # Do the same excludes as were used to identify appropriate utterances\n",
    "    excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "    all_tokens_phono.loc[all_tokens_phono.actual_phonology.isin(excludes),'actual_phonology'] =''\n",
    "    all_tokens_phono.loc[all_tokens_phono.actual_phonology.str.contains('V'),'actual_phonology'] =''\n",
    "    \n",
    "    # remap phonology from narrow phonetic transcription to broad phonological transcription\n",
    "    all_tokens_phono['model_phonology_clean'] = [phonology.phone_remap(x) for x in all_tokens_phono['model_phonology']]\n",
    "    all_tokens_phono['actual_phonology_clean'] = [phonology.phone_remap(x) for x in all_tokens_phono['actual_phonology']]\n",
    "\n",
    "    # remove any non-combining diacritical marks\n",
    "    all_tokens_phono['model_phonology_no_dia'] = [phonology.strip_accents(x) for x in \\\n",
    "    all_tokens_phono['model_phonology_clean']]\n",
    "    all_tokens_phono['actual_phonology_no_dia'] = [phonology.strip_accents(x) for x in \\\n",
    "    all_tokens_phono['actual_phonology_clean']]\n",
    "    \n",
    "    \n",
    "    # 8/13/21: Changes to limit num vowels on both actual and model phonology.\n",
    "    # Note will not regen this until later, even if this shows up in near future commits\n",
    "\n",
    "    all_tokens_phono = data_cleaning.assign_num_vowels_per_phonology(all_tokens_phono, 'actual')\n",
    "    all_tokens_phono = data_cleaning.assign_num_vowels_per_phonology(all_tokens_phono, 'model')\n",
    "    \n",
    "    all_tokens_phono = data_cleaning.combine_num_vowels_phonology(all_tokens_phono)\n",
    "    \n",
    "    all_tokens_phono.to_pickle(cleaned_inflated_save)\n",
    "else:\n",
    "    all_tokens_phono = pd.read_pickle(cleaned_inflated_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23            ɑmə\n",
       "55              ə\n",
       "125            wi\n",
       "128            aʊ\n",
       "151            wi\n",
       "            ...  \n",
       "2991828    nobɑɾi\n",
       "2991829      heəs\n",
       "2991834         o\n",
       "2991835       waə\n",
       "2991836       liʔ\n",
       "Name: actual_phonology_no_dia, Length: 254440, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.actual_phonology_no_dia != '']['actual_phonology_no_dia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2991865, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the tokens that can be evaluated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the tokens in the resulting dataframe that belong to the utterances identified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c', ..., 'hideout', 'pudding', 'stalks'], dtype='<U18')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "successful_utt_ids = set(success_utts['utterance_id'])\n",
    "\n",
    "initial_vocab_set = set(initial_vocab)\n",
    "\n",
    "yyy_utt_ids = set(yyy_utts['utterance_id'])\n",
    "\n",
    "all_tokens_phono['in_vocab'] = all_tokens_phono['token'].isin(initial_vocab_set)\n",
    "\n",
    "# 8/1/21: Changed this line to include the vocab constraint.\n",
    "all_tokens_phono['success_token'] = [(x in successful_utt_ids) and (y) for x, y in \n",
    "    zip(all_tokens_phono['utterance_id'], all_tokens_phono['in_vocab'])]\n",
    "# end changes\n",
    "\n",
    "all_tokens_phono['yyy_token'] = [x in yyy_utt_ids for x in \n",
    "    all_tokens_phono['utterance_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2991865, 31)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert '' not in set(all_tokens_phono[all_tokens_phono['num_vowels'] <= 2].actual_phonology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the subset of success and failure utterances that have transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono['partition'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185740, 32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_tokens = all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2) ]\n",
    "all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2), 'partition'] = 'success'     \n",
    "success_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successes conditions\n",
    "\n",
    "success_tokens_check = all_tokens_phono[all_tokens_phono.partition == 'success']\n",
    "assert all(success_tokens_check['in_vocab'])\n",
    "assert all(success_tokens_check.utterance_id.isin(successful_utt_ids))\n",
    "assert all(success_tokens_check['num_vowels'] <= 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "      <th>punct</th>\n",
       "      <th>speaker_code_simple</th>\n",
       "      <th>...</th>\n",
       "      <th>cv_collapsed_actual</th>\n",
       "      <th>num_vowels_actual</th>\n",
       "      <th>cv_raw_model</th>\n",
       "      <th>cv_collapsed_model</th>\n",
       "      <th>num_vowels_model</th>\n",
       "      <th>num_vowels</th>\n",
       "      <th>in_vocab</th>\n",
       "      <th>success_token</th>\n",
       "      <th>yyy_token</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mommy</td>\n",
       "      <td>16759315</td>\n",
       "      <td>Mommy</td>\n",
       "      <td>42204</td>\n",
       "      <td>6</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>vcv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cvcv</td>\n",
       "      <td>cvcv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>wee</td>\n",
       "      <td>16759467</td>\n",
       "      <td>wee</td>\n",
       "      <td>42204</td>\n",
       "      <td>24</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>wee</td>\n",
       "      <td>16759501</td>\n",
       "      <td>wee</td>\n",
       "      <td>42204</td>\n",
       "      <td>28</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>woo</td>\n",
       "      <td>16759549</td>\n",
       "      <td>woo</td>\n",
       "      <td>42204</td>\n",
       "      <td>33</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>ernie</td>\n",
       "      <td>16759752</td>\n",
       "      <td>Ernie</td>\n",
       "      <td>42204</td>\n",
       "      <td>58</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>vccv</td>\n",
       "      <td>vcv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991815</th>\n",
       "      <td>help</td>\n",
       "      <td>17280891</td>\n",
       "      <td>help</td>\n",
       "      <td>42569</td>\n",
       "      <td>752</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>vc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cvcc</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991829</th>\n",
       "      <td>hates</td>\n",
       "      <td>17280946</td>\n",
       "      <td>nobody hates Simba</td>\n",
       "      <td>42569</td>\n",
       "      <td>755</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cvvcc</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991834</th>\n",
       "      <td>oh</td>\n",
       "      <td>17280964</td>\n",
       "      <td>oh why lick hippo</td>\n",
       "      <td>42569</td>\n",
       "      <td>756</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>vv</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991835</th>\n",
       "      <td>why</td>\n",
       "      <td>17280964</td>\n",
       "      <td>oh why lick hippo</td>\n",
       "      <td>42569</td>\n",
       "      <td>756</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cvv</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991836</th>\n",
       "      <td>lick</td>\n",
       "      <td>17280964</td>\n",
       "      <td>oh why lick hippo</td>\n",
       "      <td>42569</td>\n",
       "      <td>756</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cvc</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185740 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  utterance_id               gloss  transcript_id  \\\n",
       "23       mommy      16759315               Mommy          42204   \n",
       "125        wee      16759467                 wee          42204   \n",
       "151        wee      16759501                 wee          42204   \n",
       "189        woo      16759549                 woo          42204   \n",
       "685      ernie      16759752               Ernie          42204   \n",
       "...        ...           ...                 ...            ...   \n",
       "2991815   help      17280891                help          42569   \n",
       "2991829  hates      17280946  nobody hates Simba          42569   \n",
       "2991834     oh      17280964   oh why lick hippo          42569   \n",
       "2991835    why      17280964   oh why lick hippo          42569   \n",
       "2991836   lick      17280964   oh why lick hippo          42569   \n",
       "\n",
       "         utterance_order target_child_name speaker_code               type  \\\n",
       "23                     6              Alex          CHI        declarative   \n",
       "125                   24              Alex          CHI        declarative   \n",
       "151                   28              Alex          CHI        declarative   \n",
       "189                   33              Alex          CHI        declarative   \n",
       "685                   58              Alex          CHI        declarative   \n",
       "...                  ...               ...          ...                ...   \n",
       "2991815              752           William          CHI        declarative   \n",
       "2991829              755           William          CHI        declarative   \n",
       "2991834              756           William          CHI  self interruption   \n",
       "2991835              756           William          CHI  self interruption   \n",
       "2991836              756           William          CHI  self interruption   \n",
       "\n",
       "        punct speaker_code_simple  ... cv_collapsed_actual  num_vowels_actual  \\\n",
       "23          .               [CHI]  ...                 vcv                2.0   \n",
       "125         .               [CHI]  ...                  cv                1.0   \n",
       "151         .               [CHI]  ...                  cv                1.0   \n",
       "189         .               [CHI]  ...                   v                1.0   \n",
       "685         .               [CHI]  ...                   v                1.0   \n",
       "...       ...                 ...  ...                 ...                ...   \n",
       "2991815     .               [CHI]  ...                  vc                1.0   \n",
       "2991829     .               [CHI]  ...                 cvc                1.0   \n",
       "2991834     .               [CHI]  ...                   v                1.0   \n",
       "2991835     .               [CHI]  ...                  cv                1.0   \n",
       "2991836     .               [CHI]  ...                 cvc                1.0   \n",
       "\n",
       "         cv_raw_model cv_collapsed_model num_vowels_model  num_vowels  \\\n",
       "23               cvcv               cvcv              2.0         2.0   \n",
       "125                cv                 cv              1.0         1.0   \n",
       "151                cv                 cv              1.0         1.0   \n",
       "189                cv                 cv              1.0         1.0   \n",
       "685              vccv                vcv              2.0         2.0   \n",
       "...               ...                ...              ...         ...   \n",
       "2991815          cvcc                cvc              1.0         1.0   \n",
       "2991829         cvvcc                cvc              1.0         1.0   \n",
       "2991834            vv                  v              1.0         1.0   \n",
       "2991835           cvv                 cv              1.0         1.0   \n",
       "2991836           cvc                cvc              1.0         1.0   \n",
       "\n",
       "         in_vocab success_token yyy_token partition  \n",
       "23           True          True     False   success  \n",
       "125          True          True     False   success  \n",
       "151          True          True     False   success  \n",
       "189          True          True     False   success  \n",
       "685          True          True     False   success  \n",
       "...           ...           ...       ...       ...  \n",
       "2991815      True          True     False   success  \n",
       "2991829      True          True     False   success  \n",
       "2991834      True          True     False   success  \n",
       "2991835      True          True     False   success  \n",
       "2991836      True          True     False   success  \n",
       "\n",
       "[185740 rows x 32 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27692, 32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_tokens = all_tokens_phono.loc[(all_tokens_phono['yyy_token']) & \n",
    "(all_tokens_phono['token'] == 'yyy') & (all_tokens_phono.num_vowels <= 2) ]\n",
    "all_tokens_phono.loc[(all_tokens_phono['yyy_token']) & \n",
    "(all_tokens_phono['token'] == 'yyy') & (all_tokens_phono.num_vowels <= 2),'partition'] = 'yyy'\n",
    "yyy_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none       2778433\n",
       "success     185740\n",
       "yyy          27692\n",
       "Name: partition, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.partition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.token == 'xxx','token_id'] = initial_tokenizer.unk_token_id\n",
    "all_tokens_phono.loc[all_tokens_phono.token == 'yyy','token_id'] = initial_tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this adds the partition information\n",
    "final_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated_to_next_notebook.pkl')\n",
    "all_tokens_phono.to_pickle(final_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prevalence of Successes and Failures Across Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-e26fc16c2e1c>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  success_utts['set'] = 'success'\n",
      "<ipython-input-53-e26fc16c2e1c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  yyy_utts['set'] = 'failure'\n"
     ]
    }
   ],
   "source": [
    "# get number of tokens per age\n",
    "success_utts['set'] = 'success'\n",
    "yyy_utts['set'] = 'failure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get child age in days associated with each utterance id and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_age = chi_phono.groupby('utterance_id').target_child_age.agg(np.unique).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "utts_with_ages = pd.concat([success_utts, yyy_utts]).merge(utt_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5    9919\n",
      "2.0    7261\n",
      "1.0    6693\n",
      "2.5    4895\n",
      "3.0    2097\n",
      "3.5     414\n",
      "0.5     167\n",
      "4.0      11\n",
      "Name: year, dtype: int64\n",
      "2.0    22432\n",
      "2.5    21194\n",
      "1.5    16798\n",
      "3.0    12564\n",
      "1.0     6697\n",
      "3.5     3683\n",
      "4.0      379\n",
      "0.5      133\n",
      "Name: year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "utts_with_ages['year'] = .5*np.floor(utts_with_ages['target_child_age'] / (365. /2) ) \n",
    "print(utts_with_ages.loc[utts_with_ages.set == 'failure'].year.value_counts())\n",
    "print(utts_with_ages.loc[utts_with_ages.set == 'success'].year.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_utts_save_path = join(config.prov_csv_dir, 'utts_with_ages.csv')\n",
    "utts_with_ages.to_csv(final_utts_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'yyy' not in set(success_tokens_check['token'])\n",
    "# This was the problem that was observed in my iteration of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-directed-listening",
   "language": "python",
   "name": "child-directed-listening"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
