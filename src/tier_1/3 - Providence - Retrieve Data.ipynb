{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/home/stephan/R/x86_64-pc-linux-gnu-library/4.2’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstalling childesr version 0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/childesr_0.2.3.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 22865 bytes (22 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 22 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpcV5GNg/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "import childespy\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import re\n",
    "import unicodedata\n",
    "import scipy.stats\n",
    "import copy\n",
    "from string import punctuation\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "from src.utils import configuration, load_models, transformers_bert_completions, data_cleaning, phonology\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify \"Communicative Successes\" and \"Communicative Failures\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defintions:  \n",
    "`xxx`: no lexical label, phonetically un-transcribable  \n",
    "`yyy`: no lexical label, phonetically transcribable  \n",
    "`Communicative success`: token from utterances with no xxx's or yyy's   \n",
    "`Communicative failure`: a yyy token from an utterance with no other xxx's or yyy's\n",
    "\n",
    "Later, we'll further restrict both to tokens that are monosyllabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"', db_version = \"2020.1\").iloc[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phono_glosses = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, actual_phonology, model_phonology, transcript_id, utterance_id, \\\n",
    "    token_order, corpus_name, collection_name, language from token where \\\n",
    "    actual_phonology != \"\" and model_phonology != \"\" and speaker_code in (\"MOT\", \"FAT\",\"CHI\") and collection_name = \"Eng-NA\" \\\n",
    "    and corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Providence    396621\n",
       "Name: corpus_name, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phono_glosses.corpus_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*          26736\n",
       "ə             10\n",
       "(.)            7\n",
       "aɪ             4\n",
       "pitched        2\n",
       "           ...  \n",
       "maɪ            1\n",
       "tʃid           1\n",
       "faɪ            1\n",
       "noises         1\n",
       "dʒeɪ           1\n",
       "Name: actual_phonology, Length: 76, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phono_glosses.loc[phono_glosses.gloss == 'xxx'].actual_phonology.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual phonology is almost always * for xxx items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ɛ           3206\n",
       "ʌ           2132\n",
       "ɪ           1881\n",
       "ə            512\n",
       "o            507\n",
       "            ... \n",
       "wɑjɪ           1\n",
       "juhæhɪɡə       1\n",
       "bəhɑʊ          1\n",
       "waɪtæ          1\n",
       "iːɪːoː         1\n",
       "Name: actual_phonology, Length: 30293, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phono_glosses.loc[phono_glosses.gloss == 'yyy'].actual_phonology.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual phonology *is* populated for tokens with `yyy` lexical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_phono = phono_glosses.loc[(phono_glosses.speaker_code == 'CHI') & \n",
    "    (phono_glosses.target_child_age < (365*5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_transmission_errors(utt_vector, error_codes):\n",
    "    return(np.sum([x in error_codes for x in  utt_vector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxs_per_utt = chi_phono.groupby('utterance_id').gloss.agg(\n",
    "    lambda x: count_transmission_errors(x, ['xxx'])).reset_index()\n",
    "xxxs_per_utt.columns = ['utterance_id', 'num_xxx']\n",
    "yyys_per_utt = chi_phono.groupby('utterance_id').gloss.agg(\n",
    "    lambda x: count_transmission_errors(x, ['yyy'])).reset_index()\n",
    "yyys_per_utt.columns = ['utterance_id', 'num_yyy']\n",
    "failures_per_utt = xxxs_per_utt.merge(yyys_per_utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_utts = failures_per_utt.loc[(failures_per_utt.num_xxx == 0) &  (failures_per_utt.num_yyy == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31457, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_utts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_utts = failures_per_utt.loc[(failures_per_utt.num_xxx == 0) &  \n",
    "    (failures_per_utt.num_yyy == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83880, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_utts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_from_errorless_utts = chi_phono.loc[chi_phono.utterance_id.isin(success_utts.utterance_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude un-transcribed tokens and syllabically transcribed tokens\n",
    "excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "tokens_from_errorless_utts = tokens_from_errorless_utts.loc[~(tokens_from_errorless_utts.actual_phonology.isin(excludes) |\n",
    "    tokens_from_errorless_utts.model_phonology.isin(excludes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214239, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_from_errorless_utts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          ɑmɪ\n",
       "3          wiː\n",
       "4          wiː\n",
       "5           uː\n",
       "52           ɛ\n",
       "          ... \n",
       "396606       o\n",
       "396607     waɪ\n",
       "396608     liʔ\n",
       "396609       ɪ\n",
       "396610    hɪpo\n",
       "Name: actual_phonology, Length: 214239, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example phonology\n",
    "tokens_from_errorless_utts.actual_phonology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31,457 transmission errors (from 31,457 utterances)\n",
    "# 214,239 transmission successes (from 83,880 utterances)\n",
    "# this will be further decreased later by the need to test monosyllabic forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BERT Models + CMU Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the CMU Pronunciation Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(configuration)\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_in_childes = pd.read_pickle(config.cmu_path)\n",
    "cmu_2syl_inchildes = cmu_in_childes.loc[cmu_in_childes.num_vowels <=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8943, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_in_childes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Utterances / Tokens for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load utterances from the Providence corpus from childs-db\n",
    "\n",
    "this_path = join(config.prov_csv_dir, 'pvd_utt_glosses.csv')\n",
    "if config.regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, target_child_name, speaker_code, type from utterance where speaker_code in (\"MOT\", \"FAT\",\"CHI\") and corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv(this_path, index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv(this_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_glosses = utt_glosses.rename(columns = {'id' : 'utterance_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep the utterances for tokenization with BERT. Importantly, add back the appropriate punctutation for the sentence type\n",
    "utt_glosses = utt_glosses[~utt_glosses.gloss.isna()]\n",
    "utt_glosses = data_cleaning.clean_glosses_and_add_speaker_label(utt_glosses, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "      <th>punct</th>\n",
       "      <th>speaker_code_simple</th>\n",
       "      <th>gloss_with_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759261</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759270</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759279</td>\n",
       "      <td>4</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] this is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mommy</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759315</td>\n",
       "      <td>6</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>[CHI] mommy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>okay that's fine</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759322</td>\n",
       "      <td>7</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] okay that's fine.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gloss  transcript_id  utterance_id  \\\n",
       "1  anywhere you'll feel comfortable um anywhere          42204      16759261   \n",
       "2                          please don't do that          42204      16759270   \n",
       "3                                       this is          42204      16759279   \n",
       "4                                         Mommy          42204      16759315   \n",
       "5                              okay that's fine          42204      16759322   \n",
       "\n",
       "   utterance_order target_child_name speaker_code               type punct  \\\n",
       "1                2              Alex          MOT        declarative     .   \n",
       "2                3              Alex          MOT        declarative     .   \n",
       "3                4              Alex          MOT  self interruption     .   \n",
       "4                6              Alex          CHI        declarative     .   \n",
       "5                7              Alex          MOT        declarative     .   \n",
       "\n",
       "  speaker_code_simple                                   gloss_with_punct  \n",
       "1               [CGV]  [CGV] anywhere you'll feel comfortable um anyw...  \n",
       "2               [CGV]                        [CGV] please don't do that.  \n",
       "3               [CGV]                                     [CGV] this is.  \n",
       "4               [CHI]                                       [CHI] mommy.  \n",
       "5               [CGV]                            [CGV] okay that's fine.  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_glosses.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils.transformers_bert_completions' from '/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/transformers_bert_completions.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(load_models)\n",
    "imp.reload(transformers_bert_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13017624ef6647c6bbdd0f1d94ef3b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de82e8420f50403f8205434b6968a9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b369b91a4327434896be91d18452d2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "initial_tokenizer = load_models.get_primary_tokenizer()\n",
    "initial_vocab, cmu_in_initial_vocab, cmu_indices_for_initial_vocab = load_models.get_initial_vocab_info(initial_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab mask contains 7997 entries (written words)\n",
      "CMU pronunciation dictionary has 8943 entries\n",
      "CMU pronunciation dictionary may have multiple entries for each word\n"
     ]
    }
   ],
   "source": [
    "print('Vocab mask contains '+str(len(initial_vocab))+' entries (written words)') \n",
    "print('CMU pronunciation dictionary has '+str(cmu_in_initial_vocab.shape[0])+ ' entries')\n",
    "print('CMU pronunciation dictionary may have multiple entries for each word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm yyy treated as a separate character\n",
    "if 'yyy' not in initial_tokenizer.tokenize('this is a yyy.'):\n",
    "    raise ValueError('yyy must be treated as a separate character; check the tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataframe of tokens \n",
    "# this is slow, because tokenization is slow and single-core\n",
    "def inflate(row):\n",
    "    tokens = initial_tokenizer.tokenize(row['gloss_with_punct'])\n",
    "    return(pd.DataFrame({'token':tokens, 'utterance_id':row['utterance_id']}) )\n",
    "\n",
    "inflate_path = join(config.prov_csv_dir, 'pvd_utt_glosses_inflated.csv')\n",
    "if config.regenerate:\n",
    "    all_tokens = pd.concat([inflate(x) for x in utt_glosses.to_dict('records')])\n",
    "    all_tokens = all_tokens.merge(utt_glosses)\n",
    "    all_tokens.to_csv(inflate_path)\n",
    "\n",
    "else:\n",
    "    all_tokens = pd.read_csv(inflate_path, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = all_tokens.sort_values(by= ['transcript_id','utterance_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a token_id (integer in the BERT vocabulary). \n",
    "# Because these are from the tokenized utterances, there is no correpsondence with childes-db token ids.\n",
    "all_tokens['token_id'] = initial_tokenizer.convert_tokens_to_ids(all_tokens['token'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "      <th>punct</th>\n",
       "      <th>speaker_code_simple</th>\n",
       "      <th>gloss_with_punct</th>\n",
       "      <th>token_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cgv]</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>30523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anywhere</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>5973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ll</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feel</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comfortable</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>um</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>8529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anywhere</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>5973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>42204</td>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] anywhere you'll feel comfortable um anyw...</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[cgv]</td>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "      <td>30523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>please</td>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "      <td>3531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>don</td>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "      <td>2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'</td>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t</td>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>do</td>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "      <td>2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>that</td>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.</td>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>42204</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] please don't do that.</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[cgv]</td>\n",
       "      <td>16759279</td>\n",
       "      <td>this is</td>\n",
       "      <td>42204</td>\n",
       "      <td>4</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] this is.</td>\n",
       "      <td>30523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>this</td>\n",
       "      <td>16759279</td>\n",
       "      <td>this is</td>\n",
       "      <td>42204</td>\n",
       "      <td>4</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CGV]</td>\n",
       "      <td>[CGV] this is.</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  utterance_id                                         gloss  \\\n",
       "0         [cgv]      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "1      anywhere      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "2           you      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "3             '      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "4            ll      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "5          feel      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "6   comfortable      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "7            um      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "8      anywhere      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "9             .      16759261  anywhere you'll feel comfortable um anywhere   \n",
       "10        [cgv]      16759270                          please don't do that   \n",
       "11       please      16759270                          please don't do that   \n",
       "12          don      16759270                          please don't do that   \n",
       "13            '      16759270                          please don't do that   \n",
       "14            t      16759270                          please don't do that   \n",
       "15           do      16759270                          please don't do that   \n",
       "16         that      16759270                          please don't do that   \n",
       "17            .      16759270                          please don't do that   \n",
       "18        [cgv]      16759279                                       this is   \n",
       "19         this      16759279                                       this is   \n",
       "\n",
       "    transcript_id  utterance_order target_child_name speaker_code  \\\n",
       "0           42204                2              Alex          MOT   \n",
       "1           42204                2              Alex          MOT   \n",
       "2           42204                2              Alex          MOT   \n",
       "3           42204                2              Alex          MOT   \n",
       "4           42204                2              Alex          MOT   \n",
       "5           42204                2              Alex          MOT   \n",
       "6           42204                2              Alex          MOT   \n",
       "7           42204                2              Alex          MOT   \n",
       "8           42204                2              Alex          MOT   \n",
       "9           42204                2              Alex          MOT   \n",
       "10          42204                3              Alex          MOT   \n",
       "11          42204                3              Alex          MOT   \n",
       "12          42204                3              Alex          MOT   \n",
       "13          42204                3              Alex          MOT   \n",
       "14          42204                3              Alex          MOT   \n",
       "15          42204                3              Alex          MOT   \n",
       "16          42204                3              Alex          MOT   \n",
       "17          42204                3              Alex          MOT   \n",
       "18          42204                4              Alex          MOT   \n",
       "19          42204                4              Alex          MOT   \n",
       "\n",
       "                 type punct speaker_code_simple  \\\n",
       "0         declarative     .               [CGV]   \n",
       "1         declarative     .               [CGV]   \n",
       "2         declarative     .               [CGV]   \n",
       "3         declarative     .               [CGV]   \n",
       "4         declarative     .               [CGV]   \n",
       "5         declarative     .               [CGV]   \n",
       "6         declarative     .               [CGV]   \n",
       "7         declarative     .               [CGV]   \n",
       "8         declarative     .               [CGV]   \n",
       "9         declarative     .               [CGV]   \n",
       "10        declarative     .               [CGV]   \n",
       "11        declarative     .               [CGV]   \n",
       "12        declarative     .               [CGV]   \n",
       "13        declarative     .               [CGV]   \n",
       "14        declarative     .               [CGV]   \n",
       "15        declarative     .               [CGV]   \n",
       "16        declarative     .               [CGV]   \n",
       "17        declarative     .               [CGV]   \n",
       "18  self interruption     .               [CGV]   \n",
       "19  self interruption     .               [CGV]   \n",
       "\n",
       "                                     gloss_with_punct  token_id  \n",
       "0   [CGV] anywhere you'll feel comfortable um anyw...     30523  \n",
       "1   [CGV] anywhere you'll feel comfortable um anyw...      5973  \n",
       "2   [CGV] anywhere you'll feel comfortable um anyw...      2017  \n",
       "3   [CGV] anywhere you'll feel comfortable um anyw...      1005  \n",
       "4   [CGV] anywhere you'll feel comfortable um anyw...      2222  \n",
       "5   [CGV] anywhere you'll feel comfortable um anyw...      2514  \n",
       "6   [CGV] anywhere you'll feel comfortable um anyw...      6625  \n",
       "7   [CGV] anywhere you'll feel comfortable um anyw...      8529  \n",
       "8   [CGV] anywhere you'll feel comfortable um anyw...      5973  \n",
       "9   [CGV] anywhere you'll feel comfortable um anyw...      1012  \n",
       "10                        [CGV] please don't do that.     30523  \n",
       "11                        [CGV] please don't do that.      3531  \n",
       "12                        [CGV] please don't do that.      2123  \n",
       "13                        [CGV] please don't do that.      1005  \n",
       "14                        [CGV] please don't do that.      1056  \n",
       "15                        [CGV] please don't do that.      2079  \n",
       "16                        [CGV] please don't do that.      2008  \n",
       "17                        [CGV] please don't do that.      1012  \n",
       "18                                     [CGV] this is.     30523  \n",
       "19                                     [CGV] this is.      2023  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens.iloc[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add back IPA, syllable structure, and child ages for child productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%capture\n",
    "# get the token-level data, esp phonology\n",
    "\n",
    "save_phono_inflated_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_inflated.pkl')\n",
    "\n",
    "if config.regenerate:\n",
    "\n",
    "    # get token-level information for Providence\n",
    "    pvd_chi_tokens = childespy.get_sql_query('select gloss, target_child_name, target_child_age, \\\n",
    "    speaker_code, actual_phonology, model_phonology, transcript_id, utterance_id, \\\n",
    "    token_order from token where speaker_code = \"CHI\" and corpus_id = '+str(pvd_idx),\n",
    "        db_version = \"2020.1\")\n",
    "    pvd_chi_tokens['gloss'] = [data_cleaning.fix_gloss(x) for x in pvd_chi_tokens.gloss]\n",
    "    \n",
    "    # prep the tokens generated from segmenting the utterances\n",
    "    all_tokens_test = copy.deepcopy(all_tokens) \n",
    "\n",
    "    # initialize the fields that need to be populated\n",
    "    all_tokens_test['actual_phonology'] = ''\n",
    "    all_tokens_test['model_phonology'] = ''\n",
    "    all_tokens_test['target_child_age'] = np.nan\n",
    "    \n",
    "    # get a set of unique utterances\n",
    "    _, idx = np.unique(all_tokens_test.utterance_id, return_index=True)\n",
    "    all_utt_indices = all_tokens_test.utterance_id[np.sort(idx)]\n",
    "    \n",
    "    # For fast retrieval of IPA, split pvd_chi_tokens into a dictionary\n",
    "    pvd_chi_tokens_list = pvd_chi_tokens.groupby(['utterance_id'])\n",
    "    pvd_chi_tokens_dict = dict(zip(\n",
    "        [x[0] for x in pvd_chi_tokens_list], \n",
    "        [x[1] for x in pvd_chi_tokens_list], \n",
    "    ))\n",
    "    \n",
    "    # For fast retrival of BERT tokenization\n",
    "    all_tokens_test_list = all_tokens_test.groupby(['utterance_id'])\n",
    "    all_tokens_test_dict = dict(zip(\n",
    "        [x[0] for x in all_tokens_test_list], \n",
    "        [x[1] for x in all_tokens_test_list], \n",
    "    ))\n",
    "        \n",
    "    # Augment the tokens from all_tokens with the IPA from pvd_chi_tokens \n",
    "    rvs = [] \n",
    "    utts_to_retrieve = yyy_utts.utterance_id.to_list() + success_utts.utterance_id.to_list()\n",
    "    i=-1\n",
    "    for utt_index in all_utt_indices: #utts_to_retrieve: #[16760331]:       \n",
    "        i+=1\n",
    "        if i % int(len(all_utt_indices) / 100) == 0:\n",
    "            print(str(np.round((i / (len(all_utt_indices)) * 100),2))+'% complete...')    \n",
    "            # should learn to use tqdm instead\n",
    "        if utt_index in utts_to_retrieve:        \n",
    "            utt_df = copy.deepcopy(all_tokens_test_dict[utt_index])\n",
    "            utt_df['model_phonology'] = transformers_bert_completions.augment_with_ipa(\n",
    "              utt_df, pvd_chi_tokens_dict[utt_index],initial_tokenizer, 'model_phonology')\n",
    "            utt_df['actual_phonology'] = transformers_bert_completions.augment_with_ipa(\n",
    "              utt_df, pvd_chi_tokens_dict[utt_index],initial_tokenizer, 'actual_phonology')\n",
    "            utt_df['target_child_age'] = pvd_chi_tokens_dict[utt_index].iloc[0].target_child_age    \n",
    "            rvs.append(utt_df)  \n",
    "        else:\n",
    "            rvs.append(all_tokens_test_dict[utt_index])  \n",
    "            \n",
    "    # get the resulting augmented forms back into a dataframe\n",
    "    all_tokens_phono = pd.concat(rvs)\n",
    "    \n",
    "    # add a unique identifier to the BERT tokens\n",
    "    all_tokens_phono['bert_token_id'] = range(all_tokens_phono.shape[0])\n",
    "    \n",
    "    #save the results\n",
    "    all_tokens_phono.to_pickle(save_phono_inflated_path)\n",
    "else:\n",
    "    all_tokens_phono = pd.read_pickle(save_phono_inflated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mommy</td>\n",
       "      <td>ɑmɪ</td>\n",
       "      <td>mɑmiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>yyy</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>wee</td>\n",
       "      <td>wiː</td>\n",
       "      <td>wiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>yyy</td>\n",
       "      <td>aʊ</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>wee</td>\n",
       "      <td>wiː</td>\n",
       "      <td>wiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991828</th>\n",
       "      <td>nobody</td>\n",
       "      <td>nobɑɾi</td>\n",
       "      <td>noʊbɑdiː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991829</th>\n",
       "      <td>hates</td>\n",
       "      <td>heɪs</td>\n",
       "      <td>heɪts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991834</th>\n",
       "      <td>oh</td>\n",
       "      <td>o</td>\n",
       "      <td>oʊ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991835</th>\n",
       "      <td>why</td>\n",
       "      <td>waɪ</td>\n",
       "      <td>waɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991836</th>\n",
       "      <td>lick</td>\n",
       "      <td>liʔ</td>\n",
       "      <td>lɪk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251343 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          token actual_phonology model_phonology\n",
       "23        mommy              ɑmɪ           mɑmiː\n",
       "55          yyy                ʌ               *\n",
       "125         wee              wiː             wiː\n",
       "128         yyy               aʊ               *\n",
       "151         wee              wiː             wiː\n",
       "...         ...              ...             ...\n",
       "2991828  nobody           nobɑɾi        noʊbɑdiː\n",
       "2991829   hates             heɪs           heɪts\n",
       "2991834      oh                o              oʊ\n",
       "2991835     why              waɪ             waɪ\n",
       "2991836    lick              liʔ             lɪk\n",
       "\n",
       "[251343 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the IPA\n",
    "all_tokens_phono.loc[all_tokens_phono.actual_phonology != ''][['token','actual_phonology','model_phonology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently handling * in IPA by dropping from consideration in num_vowels.\n",
      "Currently handling * in IPA by dropping from consideration in num_vowels.\n"
     ]
    }
   ],
   "source": [
    "cleaned_inflated_save = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated.pkl')\n",
    "\n",
    "if config.regenerate:    \n",
    "\n",
    "    # Do the same excludes as were used to identify appropriate utterances\n",
    "    excludes = ['*','(.)','(..)', '(...)','(....)','(.....)']\n",
    "    all_tokens_phono.loc[all_tokens_phono.actual_phonology.isin(excludes),'actual_phonology'] =''\n",
    "    all_tokens_phono.loc[all_tokens_phono.actual_phonology.str.contains('V'),'actual_phonology'] =''\n",
    "    \n",
    "    # remap phonology from narrow phonetic transcription to broad phonological transcription\n",
    "    all_tokens_phono['model_phonology_clean'] = [phonology.phone_remap(x) for x in all_tokens_phono['model_phonology']]\n",
    "    all_tokens_phono['actual_phonology_clean'] = [phonology.phone_remap(x) for x in all_tokens_phono['actual_phonology']]\n",
    "\n",
    "    # remove any non-combining diacritical marks\n",
    "    all_tokens_phono['model_phonology_no_dia'] = [phonology.strip_accents(x) for x in \\\n",
    "    all_tokens_phono['model_phonology_clean']]\n",
    "    all_tokens_phono['actual_phonology_no_dia'] = [phonology.strip_accents(x) for x in \\\n",
    "    all_tokens_phono['actual_phonology_clean']]\n",
    "    \n",
    "    \n",
    "    # 8/13/21: Changes to limit num vowels on both actual and model phonology.\n",
    "    # Note will not regen this until later, even if this shows up in near future commits\n",
    "\n",
    "    all_tokens_phono = data_cleaning.assign_num_vowels_per_phonology(all_tokens_phono, 'actual')\n",
    "    all_tokens_phono = data_cleaning.assign_num_vowels_per_phonology(all_tokens_phono, 'model')\n",
    "    \n",
    "    all_tokens_phono = data_cleaning.combine_num_vowels_phonology(all_tokens_phono)\n",
    "    \n",
    "    all_tokens_phono.to_pickle(cleaned_inflated_save)\n",
    "else:\n",
    "    all_tokens_phono = pd.read_pickle(cleaned_inflated_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23            ɑmə\n",
       "55              ə\n",
       "125            wi\n",
       "128            aʊ\n",
       "151            wi\n",
       "            ...  \n",
       "2991828    nobɑɾi\n",
       "2991829      heəs\n",
       "2991834         o\n",
       "2991835       waə\n",
       "2991836       liʔ\n",
       "Name: actual_phonology_no_dia, Length: 251243, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.actual_phonology_no_dia != '']['actual_phonology_no_dia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4189555, 27)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the tokens that can be evaluated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the tokens in the resulting dataframe that belong to the utterances identified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c', ..., 'hideout', 'pudding', 'stalks'], dtype='<U18')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "successful_utt_ids = set(success_utts['utterance_id'])\n",
    "\n",
    "initial_vocab_set = set(initial_vocab)\n",
    "\n",
    "yyy_utt_ids = set(yyy_utts['utterance_id'])\n",
    "\n",
    "all_tokens_phono['in_vocab'] = all_tokens_phono['token'].isin(initial_vocab_set)\n",
    "\n",
    "# 8/1/21: Changed this line to include the vocab constraint.\n",
    "all_tokens_phono['success_token'] = [(x in successful_utt_ids) and (y) for x, y in \n",
    "    zip(all_tokens_phono['utterance_id'], all_tokens_phono['in_vocab'])]\n",
    "# end changes\n",
    "\n",
    "all_tokens_phono['yyy_token'] = [x in yyy_utt_ids for x in \n",
    "    all_tokens_phono['utterance_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4189555, 30)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert '' not in set(all_tokens_phono[all_tokens_phono['num_vowels'] <= 2].actual_phonology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the subset of success and failure utterances that have transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono['partition'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187068, 31)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_tokens = all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2) ]\n",
    "all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2), 'partition'] = 'success'     \n",
    "success_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successes conditions\n",
    "\n",
    "success_tokens_check = all_tokens_phono[all_tokens_phono.partition == 'success']\n",
    "assert all(success_tokens_check['in_vocab'])\n",
    "assert all(success_tokens_check.utterance_id.isin(successful_utt_ids))\n",
    "assert all(success_tokens_check['num_vowels'] <= 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "      <th>punct</th>\n",
       "      <th>speaker_code_simple</th>\n",
       "      <th>...</th>\n",
       "      <th>cv_collapsed_actual</th>\n",
       "      <th>num_vowels_actual</th>\n",
       "      <th>cv_raw_model</th>\n",
       "      <th>cv_collapsed_model</th>\n",
       "      <th>num_vowels_model</th>\n",
       "      <th>num_vowels</th>\n",
       "      <th>in_vocab</th>\n",
       "      <th>success_token</th>\n",
       "      <th>yyy_token</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mommy</td>\n",
       "      <td>16759315</td>\n",
       "      <td>Mommy</td>\n",
       "      <td>42204</td>\n",
       "      <td>6</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>vcv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cvcv</td>\n",
       "      <td>cvcv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>wee</td>\n",
       "      <td>16759467</td>\n",
       "      <td>wee</td>\n",
       "      <td>42204</td>\n",
       "      <td>24</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>wee</td>\n",
       "      <td>16759501</td>\n",
       "      <td>wee</td>\n",
       "      <td>42204</td>\n",
       "      <td>28</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>blue</td>\n",
       "      <td>16759917</td>\n",
       "      <td>blue</td>\n",
       "      <td>42209</td>\n",
       "      <td>28</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>vcv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ccv</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>uh</td>\n",
       "      <td>16759987</td>\n",
       "      <td>uh</td>\n",
       "      <td>42209</td>\n",
       "      <td>34</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>question</td>\n",
       "      <td>?</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991812</th>\n",
       "      <td>help</td>\n",
       "      <td>17280876</td>\n",
       "      <td>help</td>\n",
       "      <td>42569</td>\n",
       "      <td>751</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>vc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cvcc</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991829</th>\n",
       "      <td>hates</td>\n",
       "      <td>17280946</td>\n",
       "      <td>nobody hates Simba</td>\n",
       "      <td>42569</td>\n",
       "      <td>755</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cvvcc</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991834</th>\n",
       "      <td>oh</td>\n",
       "      <td>17280964</td>\n",
       "      <td>oh why lick hippo</td>\n",
       "      <td>42569</td>\n",
       "      <td>756</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>vv</td>\n",
       "      <td>v</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991835</th>\n",
       "      <td>why</td>\n",
       "      <td>17280964</td>\n",
       "      <td>oh why lick hippo</td>\n",
       "      <td>42569</td>\n",
       "      <td>756</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cvv</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991836</th>\n",
       "      <td>lick</td>\n",
       "      <td>17280964</td>\n",
       "      <td>oh why lick hippo</td>\n",
       "      <td>42569</td>\n",
       "      <td>756</td>\n",
       "      <td>William</td>\n",
       "      <td>CHI</td>\n",
       "      <td>self interruption</td>\n",
       "      <td>.</td>\n",
       "      <td>[CHI]</td>\n",
       "      <td>...</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cvc</td>\n",
       "      <td>cvc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187068 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  utterance_id               gloss  transcript_id  \\\n",
       "23       mommy      16759315               Mommy          42204   \n",
       "125        wee      16759467                 wee          42204   \n",
       "151        wee      16759501                 wee          42204   \n",
       "1255      blue      16759917                blue          42209   \n",
       "1461        uh      16759987                  uh          42209   \n",
       "...        ...           ...                 ...            ...   \n",
       "2991812   help      17280876                help          42569   \n",
       "2991829  hates      17280946  nobody hates Simba          42569   \n",
       "2991834     oh      17280964   oh why lick hippo          42569   \n",
       "2991835    why      17280964   oh why lick hippo          42569   \n",
       "2991836   lick      17280964   oh why lick hippo          42569   \n",
       "\n",
       "         utterance_order target_child_name speaker_code               type  \\\n",
       "23                     6              Alex          CHI        declarative   \n",
       "125                   24              Alex          CHI        declarative   \n",
       "151                   28              Alex          CHI        declarative   \n",
       "1255                  28              Alex          CHI        declarative   \n",
       "1461                  34              Alex          CHI           question   \n",
       "...                  ...               ...          ...                ...   \n",
       "2991812              751           William          CHI        declarative   \n",
       "2991829              755           William          CHI        declarative   \n",
       "2991834              756           William          CHI  self interruption   \n",
       "2991835              756           William          CHI  self interruption   \n",
       "2991836              756           William          CHI  self interruption   \n",
       "\n",
       "        punct speaker_code_simple  ... cv_collapsed_actual  num_vowels_actual  \\\n",
       "23          .               [CHI]  ...                 vcv                2.0   \n",
       "125         .               [CHI]  ...                  cv                1.0   \n",
       "151         .               [CHI]  ...                  cv                1.0   \n",
       "1255        .               [CHI]  ...                 vcv                2.0   \n",
       "1461        ?               [CHI]  ...                  cv                1.0   \n",
       "...       ...                 ...  ...                 ...                ...   \n",
       "2991812     .               [CHI]  ...                  vc                1.0   \n",
       "2991829     .               [CHI]  ...                 cvc                1.0   \n",
       "2991834     .               [CHI]  ...                   v                1.0   \n",
       "2991835     .               [CHI]  ...                  cv                1.0   \n",
       "2991836     .               [CHI]  ...                 cvc                1.0   \n",
       "\n",
       "        cv_raw_model cv_collapsed_model  num_vowels_model  num_vowels  \\\n",
       "23              cvcv               cvcv               2.0         2.0   \n",
       "125               cv                 cv               1.0         1.0   \n",
       "151               cv                 cv               1.0         1.0   \n",
       "1255             ccv                 cv               1.0         2.0   \n",
       "1461               v                  v               1.0         1.0   \n",
       "...              ...                ...               ...         ...   \n",
       "2991812         cvcc                cvc               1.0         1.0   \n",
       "2991829        cvvcc                cvc               1.0         1.0   \n",
       "2991834           vv                  v               1.0         1.0   \n",
       "2991835          cvv                 cv               1.0         1.0   \n",
       "2991836          cvc                cvc               1.0         1.0   \n",
       "\n",
       "        in_vocab success_token yyy_token partition  \n",
       "23          True          True     False   success  \n",
       "125         True          True     False   success  \n",
       "151         True          True     False   success  \n",
       "1255        True          True     False   success  \n",
       "1461        True          True     False   success  \n",
       "...          ...           ...       ...       ...  \n",
       "2991812     True          True     False   success  \n",
       "2991829     True          True     False   success  \n",
       "2991834     True          True     False   success  \n",
       "2991835     True          True     False   success  \n",
       "2991836     True          True     False   success  \n",
       "\n",
       "[187068 rows x 31 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.loc[(all_tokens_phono['success_token']) & \n",
    "    (all_tokens_phono['num_vowels'] <= 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18233, 31)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_tokens = all_tokens_phono.loc[(all_tokens_phono['yyy_token']) & \n",
    "(all_tokens_phono['token'] == 'yyy') & (all_tokens_phono.num_vowels <= 2) ]\n",
    "all_tokens_phono.loc[(all_tokens_phono['yyy_token']) & \n",
    "(all_tokens_phono['token'] == 'yyy') & (all_tokens_phono.num_vowels <= 2),'partition'] = 'yyy'\n",
    "yyy_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none       3984254\n",
       "success     187068\n",
       "yyy          18233\n",
       "Name: partition, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.partition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.token == 'xxx','token_id'] = initial_tokenizer.unk_token_id\n",
    "all_tokens_phono.loc[all_tokens_phono.token == 'yyy','token_id'] = initial_tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this adds the partition information\n",
    "final_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated_to_next_notebook.pkl')\n",
    "all_tokens_phono.to_pickle(final_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prevalence of Successes and Failures Across Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-72-e26fc16c2e1c>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  success_utts['set'] = 'success'\n",
      "<ipython-input-72-e26fc16c2e1c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  yyy_utts['set'] = 'failure'\n"
     ]
    }
   ],
   "source": [
    "# get number of tokens per age\n",
    "success_utts['set'] = 'success'\n",
    "yyy_utts['set'] = 'failure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get child age in days associated with each utterance id and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_age = chi_phono.groupby('utterance_id').target_child_age.agg(lambda x: np.unique(x)[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "utts_with_ages = pd.concat([success_utts, yyy_utts]).merge(utt_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5    9919\n",
      "2.0    7261\n",
      "1.0    6693\n",
      "2.5    4895\n",
      "3.0    2097\n",
      "3.5     414\n",
      "0.5     167\n",
      "4.0      11\n",
      "Name: year, dtype: int64\n",
      "2.0    22432\n",
      "2.5    21194\n",
      "1.5    16798\n",
      "3.0    12564\n",
      "1.0     6697\n",
      "3.5     3683\n",
      "4.0      379\n",
      "0.5      133\n",
      "Name: year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "utts_with_ages['year'] = .5*np.floor(utts_with_ages['target_child_age'] / (365. /2) ) \n",
    "print(utts_with_ages.loc[utts_with_ages.set == 'failure'].year.value_counts())\n",
    "print(utts_with_ages.loc[utts_with_ages.set == 'success'].year.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_utts_save_path = join(config.prov_csv_dir, 'utts_with_ages.csv')\n",
    "utts_with_ages.to_csv(final_utts_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'yyy' not in set(success_tokens_check['token'])\n",
    "# This was the problem that was observed in my iteration of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-14 09:35:53.843803\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-directed-listening",
   "language": "python",
   "name": "child-directed-listening"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
