{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "from src.utils import split_gen, sampling, data_cleaning, load_models, data_cleaning, transformers_bert_completions, configuration, child_split_gen, child_models\n",
    "config = configuration.Config()\n",
    "np.random.seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated_to_next_notebook.pkl')\n",
    "all_tokens_phono = pd.read_pickle(final_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the samples and splits for age/all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for each of success and yyy, then merge them together.\n",
    "\n",
    "all_tokens_phono_valid = data_cleaning.find_transcripts_with_successes_and_yyy(all_tokens_phono)\n",
    "\n",
    "# Split train/val/test: 25/50/50.\n",
    "\n",
    "split_attr = 'transcript_id'\n",
    "\n",
    "phono_train_val_idxs, phono_eval_idxs = split_gen.determine_split_idxs(all_tokens_phono_valid, split_attr, 0.5)\n",
    "\n",
    "phono_train_val = all_tokens_phono_valid[all_tokens_phono_valid.transcript_id.isin(phono_train_val_idxs)]\n",
    "phono_train_idxs, phono_val_idxs = split_gen.determine_split_idxs(phono_train_val, split_attr, 0.5)\n",
    "\n",
    "for phase, idx_set in zip(['train', 'val', 'eval'], [phono_train_idxs, phono_val_idxs, phono_eval_idxs]):\n",
    "\n",
    "    # It's on transcript_id, not actual idx, so this is OK.\n",
    "    # all_tokens_phono will receive the val/eval phase marking where it applies.\n",
    "\n",
    "    this_phase_data, all_tokens_phono = split_gen.assign_and_find_phase_data(phase, split_attr, idx_set, all_tokens_phono, 'phase_sample')\n",
    "\n",
    "all_tokens_phono = data_cleaning.augment_target_child_year(all_tokens_phono)\n",
    "\n",
    "# Below: For debugging only\n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval_before_child.pkl')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(sampling)\n",
    "from src.utils import paths\n",
    "imp.reload(paths)\n",
    "imp.reload(configuration)\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a random sample for fitting the likelihood hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Providence all\n",
      "\t sample for fitting: (5000, 1)\n",
      "Processing Providence-Age young\n",
      "\t sample for fitting: (5000, 1)\n",
      "Processing Providence-Age old\n",
      "\t sample for fitting: (5000, 1)\n",
      "Processing Switchboard all\n",
      "\t sample for fitting: (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "young_phono, old_phono = split_gen.get_age_split_data(all_tokens_phono)\n",
    "\n",
    "phono_pool = [\n",
    "    all_tokens_phono,\n",
    "    young_phono,\n",
    "    old_phono,\n",
    "    all_tokens_phono # validate switchboard on all tokens phono\n",
    "]\n",
    "\n",
    "model_args = [('Providence', 'all'), ('Providence-Age', 'young'), ('Providence-Age', 'old'), ('Switchboard','all')]\n",
    "\n",
    "for (test_split, test_dataset), this_phono_raw in zip(model_args, phono_pool):\n",
    "    \n",
    "    print('Processing', test_split, test_dataset)\n",
    "    phono_data_for_phase = this_phono_raw[(this_phono_raw.phase_sample == 'val') & (this_phono_raw.partition == 'success')]\n",
    "\n",
    "    # age = None means don't filter on a given age\n",
    "    result_beta_sample = sampling.sample_successes( \n",
    "            task_phase_to_sample_for = 'fit',\n",
    "            test_split = test_split,\n",
    "            test_dataset = test_dataset,\n",
    "            raw_phono = phono_data_for_phase,\n",
    "            age = None)        \n",
    "\n",
    "    print('\\t sample for fitting:', result_beta_sample.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample across ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for success\n",
      "\tage sample (87, 1)\n",
      "for yyy\n",
      "\tage sample (105, 1)\n",
      "for success\n",
      "\tage sample (87, 1)\n",
      "for yyy\n",
      "\tage sample (105, 1)\n",
      "for success\n",
      "\tage sample (2364, 1)\n",
      "for yyy\n",
      "\tage sample (2369, 1)\n",
      "for success\n",
      "\tage sample (2364, 1)\n",
      "for yyy\n",
      "\tage sample (2369, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (4524, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (4524, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (2971, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (2971, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (1994, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (1994, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (810, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (810, 1)\n",
      "for success\n",
      "\tage sample (1580, 1)\n",
      "for yyy\n",
      "\tage sample (118, 1)\n",
      "for success\n",
      "\tage sample (1580, 1)\n",
      "for yyy\n",
      "\tage sample (118, 1)\n",
      "for success\n",
      "\tage sample (0, 1)\n",
      "for yyy\n",
      "\tage sample (0, 1)\n",
      "for success\n",
      "\tage sample (0, 1)\n",
      "for yyy\n",
      "\tage sample (0, 1)\n"
     ]
    }
   ],
   "source": [
    "used_ages = data_cleaning.get_years(all_tokens_phono)\n",
    "\n",
    "for age in used_ages:\n",
    "    for eval_phase in ['val', 'test']:\n",
    "        for sample_func, sample_name in zip([sampling.sample_successes, sampling.sample_yyy], ['success', 'yyy']):\n",
    "\n",
    "            print(f'for {sample_name}')\n",
    "\n",
    "            phono_data_for_phase = all_tokens_phono[(all_tokens_phono.phase_sample == phase) & (all_tokens_phono.partition == sample_name)]\n",
    "            \n",
    "            this_age_sample = sample_func(\n",
    "                task_phase_to_sample_for= 'eval',\n",
    "                test_split = 'Providence',\n",
    "            test_dataset = 'all',\n",
    "            raw_phono = phono_data_for_phase,\n",
    "            age = age)       \n",
    "            \n",
    "            print('\\tage sample', this_age_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils.child_split_gen' from '/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/child_split_gen.py'>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(child_split_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_attr = 'transcript_id'\n",
    "\n",
    "# 7/25/21: https://www.kite.com/python/answers/how-to-create-an-empty-column-in-a-pandas-dataframe-in-python\n",
    "all_tokens_phono['phase_child_sample'] = np.nan\n",
    "all_tokens_phono['phase_child_finetune'] = np.nan\n",
    "# end cite\n",
    "\n",
    "for name in sorted(list(set(all_tokens_phono.target_child_name))):\n",
    "    \n",
    "    this_partition_folder = split_gen.get_split_folder('child', name, config.finetune_dir)\n",
    "    \n",
    "    ## -------- Restricted sampling section\n",
    "    \n",
    "    print(f'Processing: {name}')\n",
    "    \n",
    "    this_child_phono = all_tokens_phono[(all_tokens_phono.target_child_name == name)]\n",
    "    \n",
    "    this_valid_phono = data_cleaning.find_transcripts_with_successes_and_yyy(this_child_phono)\n",
    " \n",
    "    # Sample across ages\n",
    "    \n",
    "    complete_phase_idxs = child_split_gen.find_splits_across_ages(this_valid_phono)\n",
    "        \n",
    "    for phase_name, idx_set in complete_phase_idxs.items():\n",
    "        \n",
    "        # Make a new attribute for all_tokens_phono parallel to phase (which is the val/eval split defined above)\n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(phase_name, split_attr, idx_set, all_tokens_phono, phase_label = 'phase_child_sample')\n",
    "    \n",
    "    # Beta samples\n",
    "    \n",
    "    val_success_pool = all_tokens_phono[\n",
    "        (all_tokens_phono.partition == 'success')\n",
    "        & (all_tokens_phono.target_child_name == name)\n",
    "        & (all_tokens_phono.phase_child_sample == 'val')\n",
    "    ]\n",
    "    \n",
    "    # Note: get_beta_idxs does NOT internally filter things.\n",
    "    # It's necessary to pass all_tokens_phono-based filtering because all_tokens_phono has the phase information\n",
    "    # associated with it.\n",
    "    \n",
    "    val_sample = child_split_gen.get_beta_idxs(val_success_pool, 'transcript_id')\n",
    "    \n",
    "    this_path = sampling.get_sample_path('success', 'beta', 'child', name, eval_phase = 'val')\n",
    "    val_sample.to_csv(this_path)\n",
    "\n",
    "    print(f'\\tWriting beta samples for phase {phase}, to {this_path}, sample size: {val_sample.shape}, pool size: {len(set(val_success_pool.utterance_id))}')\n",
    "    \n",
    "    ## -------- Unrestricted sampling section\n",
    "    \n",
    "    # Identify everything that isn't in the sample.\n",
    "    \n",
    "    complete_sample_idxs = np.concatenate([complete_phase_idxs[phase] for phase in ['train', 'val', 'eval']])\n",
    "    \n",
    "    # Checked that all_tokens_phono is unfiltered pool of information.\n",
    "    \n",
    "    train_val_finetune_phono_new = this_child_phono[~this_child_phono.transcript_id.isin(complete_sample_idxs)]\n",
    "\n",
    "    train_val_finetune_phono_new = data_cleaning.drop_errors(train_val_finetune_phono_new)\n",
    "    # prepped glosses already done above in Pvd logic\n",
    "    \n",
    "    train_merge_out_pool = {}\n",
    "    \n",
    "    avail_train_val_finetune_ids = set(train_val_finetune_phono_new.transcript_id)\n",
    "    num_train_val_finetune_new_ids = len(avail_train_val_finetune_ids)\n",
    "    \n",
    "    if num_train_val_finetune_new_ids >= 2:\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = split_gen.determine_split_idxs(train_val_finetune_phono_new, 'transcript_id', val_ratio = config.val_ratio)\n",
    "    elif num_train_val_finetune_new_ids == 1:\n",
    "        # Prioritize validation because train will receive a larger merge from the previous data.\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = np.array([]), np.array(list(avail_train_val_finetune_ids))\n",
    "    else:\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = np.array([]), np.array([])\n",
    "    \n",
    "    # Complete_phase_idxs still has some yyy in it.\n",
    "    # Isolate the parts of train_sample that can be merged with the finetune train phase.\n",
    "    \n",
    "    no_errors_phono = data_cleaning.drop_errors(this_child_phono)\n",
    "    \n",
    "    train_merge_in_pool = {}\n",
    "    for phase in ['train', 'val']:\n",
    "        train_merge_in_pool[phase] = np.unique(no_errors_phono[no_errors_phono.transcript_id.isin(complete_phase_idxs[phase])].transcript_id)\n",
    "    \n",
    "    finetune_idxs = {}\n",
    "    for phase in ['train', 'val']:\n",
    "        finetune_idxs[phase] = np.concatenate([train_merge_out_pool[phase], train_merge_in_pool[phase]])\n",
    "    \n",
    "    ## Identify and write the finetune phases relative to partition information.\n",
    "    \n",
    "    for finetune_phase, finetune_idx_set in finetune_idxs.items():\n",
    "        \n",
    "        split_gen.write_data_partitions_text(this_child_phono, this_partition_folder, finetune_phase, finetune_idx_set, 'transcript_id', 'phase_child_finetune')\n",
    "        \n",
    "        # Re-assign phase information all_tokens_phono\n",
    "        # because need to limit to this_child_phono above for the writing.\n",
    "        \n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(finetune_phase, split_attr, finetune_idx_set, all_tokens_phono, phase_label = 'phase_child_finetune')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the subsampling for the child cross scoring\n",
    "\n",
    "all_tokens_phono = child_split_gen.split_child_subsampling(all_tokens_phono)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final all_tokens_phono with all split information to the proper place.\n",
    "if not exists(config.prov_dir):\n",
    "    os.makedirs(config.prov_dir)\n",
    "    \n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, exists\n",
    "\n",
    "join(config.prov_dir, 'pvd_all_tokens_phono_for_eval.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-directed-listening",
   "language": "python",
   "name": "child-directed-listening"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
