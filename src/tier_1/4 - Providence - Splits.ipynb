{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "from src.utils import split_gen, sampling, data_cleaning, load_models, data_cleaning, transformers_bert_completions, configuration, child_split_gen, child_models\n",
    "config = configuration.Config()\n",
    "np.random.seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_save_path = join(config.prov_csv_dir, 'pvd_utt_glosses_phono_cleaned_inflated_to_next_notebook.pkl')\n",
    "all_tokens_phono = pd.read_pickle(final_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the samples and splits for age/all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for each of success and yyy, then merge them together.\n",
    "\n",
    "all_tokens_phono_valid = data_cleaning.find_transcripts_with_successes_and_yyy(all_tokens_phono)\n",
    "\n",
    "# Split train/val/test: 25/50/50.\n",
    "\n",
    "split_attr = 'transcript_id'\n",
    "\n",
    "phono_train_val_idxs, phono_eval_idxs = split_gen.determine_split_idxs(all_tokens_phono_valid, split_attr, 0.5)\n",
    "\n",
    "phono_train_val = all_tokens_phono_valid[all_tokens_phono_valid.transcript_id.isin(phono_train_val_idxs)]\n",
    "phono_train_idxs, phono_val_idxs = split_gen.determine_split_idxs(phono_train_val, split_attr, 0.5)\n",
    "\n",
    "for phase, idx_set in zip(['train', 'val', 'eval'], [phono_train_idxs, phono_val_idxs, phono_eval_idxs]):\n",
    "\n",
    "    # It's on transcript_id, not actual idx, so this is OK.\n",
    "    # all_tokens_phono will receive the val/eval phase marking where it applies.\n",
    "\n",
    "    this_phase_data, all_tokens_phono = split_gen.assign_and_find_phase_data(phase, split_attr, idx_set, all_tokens_phono)\n",
    "\n",
    "all_tokens_phono = data_cleaning.augment_target_child_year(all_tokens_phono)\n",
    "\n",
    "# Below: For debugging only\n",
    "\n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval_before_child.pkl')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(sampling)\n",
    "from src.utils import paths\n",
    "imp.reload(paths)\n",
    "imp.reload(configuration)\n",
    "imp.reload(split_gen)\n",
    "config = configuration.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a random sample for fitting the likelihood hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Providence all\n",
      "\t sample for fitting: (5000, 1)\n",
      "Processing Providence-Age young\n",
      "\t sample for fitting: (5000, 1)\n",
      "Processing Providence-Age old\n",
      "\t sample for fitting: (5000, 1)\n",
      "Processing Switchboard all\n",
      "\t sample for fitting: (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "young_phono, old_phono = split_gen.get_age_split_data(all_tokens_phono)\n",
    "\n",
    "phono_pool = [\n",
    "    all_tokens_phono,\n",
    "    young_phono,\n",
    "    old_phono,\n",
    "    all_tokens_phono # validate switchboard on all tokens phono\n",
    "]\n",
    "\n",
    "model_args = [('Providence', 'all'), ('Providence-Age', 'young'), ('Providence-Age', 'old'), ('Switchboard','all')]\n",
    "\n",
    "for (test_split, test_dataset), this_phono_raw in zip(model_args, phono_pool):\n",
    "    \n",
    "    print('Processing', test_split, test_dataset)\n",
    "    phono_data_for_phase = this_phono_raw[(this_phono_raw.phase_sample == 'val') & (this_phono_raw.partition == 'success')]\n",
    "\n",
    "    # age = None means don't filter on a given age\n",
    "    result_beta_sample = sampling.sample_successes( \n",
    "            task_phase_to_sample_for = 'fit',\n",
    "            test_split = test_split,\n",
    "            test_dataset = test_dataset,\n",
    "            raw_phono = phono_data_for_phase,\n",
    "            age = None)        \n",
    "\n",
    "    print('\\t sample for fitting:', result_beta_sample.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample across ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for success\n",
      "\tage sample (87, 1)\n",
      "for yyy\n",
      "\tage sample (105, 1)\n",
      "for success\n",
      "\tage sample (87, 1)\n",
      "for yyy\n",
      "\tage sample (105, 1)\n",
      "for success\n",
      "\tage sample (2364, 1)\n",
      "for yyy\n",
      "\tage sample (2369, 1)\n",
      "for success\n",
      "\tage sample (2364, 1)\n",
      "for yyy\n",
      "\tage sample (2369, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (4524, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (4524, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (2971, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (2971, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (1994, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (1994, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (810, 1)\n",
      "for success\n",
      "\tage sample (5000, 1)\n",
      "for yyy\n",
      "\tage sample (810, 1)\n",
      "for success\n",
      "\tage sample (1580, 1)\n",
      "for yyy\n",
      "\tage sample (118, 1)\n",
      "for success\n",
      "\tage sample (1580, 1)\n",
      "for yyy\n",
      "\tage sample (118, 1)\n",
      "for success\n",
      "\tage sample (0, 1)\n",
      "for yyy\n",
      "\tage sample (0, 1)\n",
      "for success\n",
      "\tage sample (0, 1)\n",
      "for yyy\n",
      "\tage sample (0, 1)\n"
     ]
    }
   ],
   "source": [
    "used_ages = data_cleaning.get_years(all_tokens_phono)\n",
    "\n",
    "for age in used_ages:\n",
    "    for eval_phase in ['val', 'test']:\n",
    "        for sample_func, sample_name in zip([sampling.sample_successes, sampling.sample_yyy], ['success', 'yyy']):\n",
    "\n",
    "            print(f'for {sample_name}')\n",
    "\n",
    "            phono_data_for_phase = all_tokens_phono[(all_tokens_phono.phase_sample == phase) & (all_tokens_phono.partition == sample_name)]\n",
    "            \n",
    "            this_age_sample = sample_func(\n",
    "                task_phase_to_sample_for= 'eval',\n",
    "                test_split = 'Providence',\n",
    "            test_dataset = 'all',\n",
    "            raw_phono = phono_data_for_phase,\n",
    "            age = age)       \n",
    "            \n",
    "            print('\\tage sample', this_age_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils.split_gen' from '/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/split_gen.py'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save these to \n",
    "import imp\n",
    "imp.reload(split_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['token', 'utterance_id', 'gloss', 'transcript_id', 'utterance_order',\n",
       "       'target_child_name', 'speaker_code', 'type', 'punct',\n",
       "       'speaker_code_simple', 'gloss_with_punct', 'token_id', 'seq_utt_id',\n",
       "       'actual_phonology', 'model_phonology', 'target_child_age',\n",
       "       'bert_token_id', 'model_phonology_clean', 'actual_phonology_clean',\n",
       "       'model_phonology_no_dia', 'actual_phonology_no_dia', 'cv_raw_actual',\n",
       "       'cv_collapsed_actual', 'num_vowels_actual', 'cv_raw_model',\n",
       "       'cv_collapsed_model', 'num_vowels_model', 'num_vowels', 'in_vocab',\n",
       "       'success_token', 'yyy_token', 'partition', 'phase', 'year',\n",
       "       'phase_child_sample', 'phase_child_finetune',\n",
       "       'phase_child_sample_n=2_type=success_name=Alex',\n",
       "       'phase_child_sample_n=2_type=success_name=Ethan',\n",
       "       'phase_child_sample_n=2_type=success_name=Lily',\n",
       "       'phase_child_sample_n=2_type=success_name=Naima',\n",
       "       'phase_child_sample_n=2_type=success_name=Violet',\n",
       "       'phase_child_sample_n=2_type=success_name=William',\n",
       "       'phase_child_sample_n=2_type=yyy_name=Alex',\n",
       "       'phase_child_sample_n=2_type=yyy_name=Ethan',\n",
       "       'phase_child_sample_n=2_type=yyy_name=Lily',\n",
       "       'phase_child_sample_n=2_type=yyy_name=Naima',\n",
       "       'phase_child_sample_n=2_type=yyy_name=Violet',\n",
       "       'phase_child_sample_n=2_type=yyy_name=William',\n",
       "       'phase_child_sample_n=1000_type=success_name=Alex',\n",
       "       'phase_child_sample_n=1000_type=success_name=Ethan',\n",
       "       'phase_child_sample_n=1000_type=success_name=Lily',\n",
       "       'phase_child_sample_n=1000_type=success_name=Naima',\n",
       "       'phase_child_sample_n=1000_type=success_name=Violet',\n",
       "       'phase_child_sample_n=1000_type=success_name=William',\n",
       "       'phase_child_sample_n=1000_type=yyy_name=Alex',\n",
       "       'phase_child_sample_n=1000_type=yyy_name=Ethan',\n",
       "       'phase_child_sample_n=1000_type=yyy_name=Lily',\n",
       "       'phase_child_sample_n=1000_type=yyy_name=Naima',\n",
       "       'phase_child_sample_n=1000_type=yyy_name=Violet',\n",
       "       'phase_child_sample_n=1000_type=yyy_name=William',\n",
       "       'phase_child_sample_n=5000_type=success_name=Alex',\n",
       "       'phase_child_sample_n=5000_type=success_name=Ethan',\n",
       "       'phase_child_sample_n=5000_type=success_name=Lily',\n",
       "       'phase_child_sample_n=5000_type=success_name=Naima',\n",
       "       'phase_child_sample_n=5000_type=success_name=Violet',\n",
       "       'phase_child_sample_n=5000_type=success_name=William',\n",
       "       'phase_child_sample_n=5000_type=yyy_name=Alex',\n",
       "       'phase_child_sample_n=5000_type=yyy_name=Ethan',\n",
       "       'phase_child_sample_n=5000_type=yyy_name=Lily',\n",
       "       'phase_child_sample_n=5000_type=yyy_name=Naima',\n",
       "       'phase_child_sample_n=5000_type=yyy_name=Violet',\n",
       "       'phase_child_sample_n=5000_type=yyy_name=William'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    1960626\n",
       "val      1002741\n",
       "eval       28498\n",
       "Name: phase, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_phono.phase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Alex\n",
      "\tWriting beta samples for phase val, to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/sample/n=5000/Providence-Child_Alex/fit_success_utts_5000.csv, sample size: (2745, 1), pool size: 2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/data_cleaning.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/stephan/notebooks/child-directed-listening/child-directed-listening-env/lib/python3.8/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Alex_with_tags/train.txt\n",
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Alex_with_tags/val.txt\n",
      "Processing: Ethan\n",
      "\tWriting beta samples for phase val, to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/sample/n=5000/Providence-Child_Ethan/fit_success_utts_5000.csv, sample size: (1938, 1), pool size: 1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/data_cleaning.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/stephan/notebooks/child-directed-listening/child-directed-listening-env/lib/python3.8/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Ethan_with_tags/train.txt\n",
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Ethan_with_tags/val.txt\n",
      "Processing: Lily\n",
      "\tWriting beta samples for phase val, to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/sample/n=5000/Providence-Child_Lily/fit_success_utts_5000.csv, sample size: (4142, 1), pool size: 4142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/data_cleaning.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/stephan/notebooks/child-directed-listening/child-directed-listening-env/lib/python3.8/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Lily_with_tags/train.txt\n",
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Lily_with_tags/val.txt\n",
      "Processing: Naima\n",
      "\tWriting beta samples for phase val, to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/sample/n=5000/Providence-Child_Naima/fit_success_utts_5000.csv, sample size: (3423, 1), pool size: 3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/data_cleaning.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/stephan/notebooks/child-directed-listening/child-directed-listening-env/lib/python3.8/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Naima_with_tags/train.txt\n",
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Naima_with_tags/val.txt\n",
      "Processing: Violet\n",
      "\tWriting beta samples for phase val, to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/sample/n=5000/Providence-Child_Violet/fit_success_utts_5000.csv, sample size: (2115, 1), pool size: 2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/data_cleaning.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/stephan/notebooks/child-directed-listening/child-directed-listening-env/lib/python3.8/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Violet_with_tags/train.txt\n",
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_Violet_with_tags/val.txt\n",
      "Processing: William\n",
      "\tWriting beta samples for phase val, to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/sample/n=5000/Providence-Child_William/fit_success_utts_5000.csv, sample size: (2944, 1), pool size: 2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_1/../../src/utils/data_cleaning.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utt_data['contains_error'] = ['xxx' in str(x) or 'yyy' in str(x) for x in all_lowercase]\n",
      "/home/stephan/notebooks/child-directed-listening/child-directed-listening-env/lib/python3.8/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_William_with_tags/train.txt\n",
      "File written to /home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/extract_data/n=5000/Providence-Child_William_with_tags/val.txt\n"
     ]
    }
   ],
   "source": [
    "split_attr = 'transcript_id'\n",
    "\n",
    "# 7/25/21: https://www.kite.com/python/answers/how-to-create-an-empty-column-in-a-pandas-dataframe-in-python\n",
    "all_tokens_phono['phase_child_sample'] = np.nan\n",
    "all_tokens_phono['phase_child_finetune'] = np.nan\n",
    "# end cite\n",
    "\n",
    "for name in sorted(list(set(all_tokens_phono.target_child_name))):\n",
    "    \n",
    "    sample_spec_dict = {\n",
    "        'task_name': 'child',\n",
    "        'task_phase' : 'sample',\n",
    "        'training_split' : 'Providence-Child',\n",
    "        'training_dataset' : name,\n",
    "        'test_split' : None,\n",
    "        'test_dataset' : None,\n",
    "        'model_type': None,\n",
    "        'use_tags': None,\n",
    "        'context_width': None,\n",
    "        'n_samples' : config.n_beta\n",
    "        \n",
    "    }\n",
    "        \n",
    "    sample_folder = paths.get_directory(sample_spec_dict)\n",
    "    if not os.path.exists(sample_folder):\n",
    "        os.makedirs(sample_folder)\n",
    "    \n",
    "    ## -------- Restricted sampling section\n",
    "    \n",
    "    print(f'Processing: {name}')\n",
    "    \n",
    "    this_child_phono = all_tokens_phono[(all_tokens_phono.target_child_name == name)]\n",
    "    \n",
    "    this_valid_phono = data_cleaning.find_transcripts_with_successes_and_yyy(this_child_phono)\n",
    " \n",
    "    # Sample across ages\n",
    "    \n",
    "    complete_phase_idxs = child_split_gen.find_splits_across_ages(this_valid_phono)\n",
    "        \n",
    "    for phase_name, idx_set in complete_phase_idxs.items():\n",
    "        \n",
    "        # Make a new attribute for all_tokens_phono parallel to phase (which is the val/eval split defined above)\n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(phase_name, split_attr, idx_set, all_tokens_phono, phase_label = 'phase_child_sample')\n",
    "    \n",
    "    # Beta samples\n",
    "    \n",
    "    val_success_pool = all_tokens_phono[\n",
    "        (all_tokens_phono.partition == 'success')\n",
    "        & (all_tokens_phono.target_child_name == name)\n",
    "        & (all_tokens_phono.phase_child_sample == 'val')\n",
    "    ]\n",
    "    \n",
    "    # Note: get_beta_idxs does NOT internally filter things.\n",
    "    # It's necessary to pass all_tokens_phono-based filtering because all_tokens_phono has the phase information\n",
    "    # associated with it.\n",
    "    \n",
    "    val_sample = child_split_gen.get_beta_idxs(val_success_pool, 'transcript_id')\n",
    "    \n",
    "    #this_path = sampling.get_sample_path('success', 'beta', 'child', name, eval_phase = 'val')\n",
    "    this_path = os.path.join(sample_folder, \n",
    "        'fit_success_utts_'+str(config.n_beta)+'.csv')\n",
    "    val_sample.to_csv(this_path)\n",
    "\n",
    "    print(f'\\tWriting beta samples for phase {phase}, to {this_path}, sample size: {val_sample.shape}, pool size: {len(set(val_success_pool.utterance_id))}')\n",
    "    \n",
    "    ## -------- Unrestricted sampling section\n",
    "    \n",
    "    # Identify everything that isn't in the sample.\n",
    "    \n",
    "    complete_sample_idxs = np.concatenate([complete_phase_idxs[phase] for phase in ['train', 'val', 'eval']])\n",
    "    \n",
    "    # Checked that all_tokens_phono is unfiltered pool of information.\n",
    "    \n",
    "    train_val_finetune_phono_new = this_child_phono[~this_child_phono.transcript_id.isin(complete_sample_idxs)]\n",
    "\n",
    "    train_val_finetune_phono_new = data_cleaning.drop_errors(train_val_finetune_phono_new)\n",
    "    # prepped glosses already done above in Pvd logic\n",
    "    \n",
    "    train_merge_out_pool = {}\n",
    "    \n",
    "    avail_train_val_finetune_ids = set(train_val_finetune_phono_new.transcript_id)\n",
    "    num_train_val_finetune_new_ids = len(avail_train_val_finetune_ids)\n",
    "    \n",
    "    if num_train_val_finetune_new_ids >= 2:\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = split_gen.determine_split_idxs(train_val_finetune_phono_new, 'transcript_id', val_ratio = config.val_ratio)\n",
    "    elif num_train_val_finetune_new_ids == 1:\n",
    "        # Prioritize validation because train will receive a larger merge from the previous data.\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = np.array([]), np.array(list(avail_train_val_finetune_ids))\n",
    "    else:\n",
    "        train_merge_out_pool['train'], train_merge_out_pool['val'] = np.array([]), np.array([])\n",
    "    \n",
    "    # Complete_phase_idxs still has some yyy in it.\n",
    "    # Isolate the parts of train_sample that can be merged with the finetune train phase.\n",
    "    \n",
    "    no_errors_phono = data_cleaning.drop_errors(this_child_phono)\n",
    "    \n",
    "    train_merge_in_pool = {}\n",
    "    for phase in ['train', 'val']:\n",
    "        train_merge_in_pool[phase] = np.unique(no_errors_phono[no_errors_phono.transcript_id.isin(complete_phase_idxs[phase])].transcript_id)\n",
    "    \n",
    "    finetune_idxs = {}\n",
    "    for phase in ['train', 'val']:\n",
    "        finetune_idxs[phase] = np.concatenate([train_merge_out_pool[phase], train_merge_in_pool[phase]])\n",
    "    \n",
    "    ## Identify and write the finetune phases relative to partition information.\n",
    "    \n",
    "    data_spec_dict = copy.copy(sample_spec_dict)\n",
    "    data_spec_dict['task_phase'] = 'extract_data'\n",
    "    data_spec_dict['use_tags'] = True\n",
    "    data_folder = paths.get_directory(data_spec_dict)\n",
    "    \n",
    "    \n",
    "    for finetune_phase, finetune_idx_set in finetune_idxs.items():\n",
    "        \n",
    "        split_gen.write_data_partitions_text(this_child_phono, data_folder, finetune_phase, finetune_idx_set, 'transcript_id')\n",
    "        \n",
    "        # Re-assign phase information all_tokens_phono\n",
    "        # because need to limit to this_child_phono above for the writing.\n",
    "        \n",
    "        _, all_tokens_phono = split_gen.assign_and_find_phase_data(finetune_phase, split_attr, finetune_idx_set, all_tokens_phono)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in augment with subsamples train 2 success Alex\n",
      "in augment with subsamples train 2 success Ethan\n",
      "in augment with subsamples train 2 success Lily\n",
      "in augment with subsamples train 2 success Naima\n",
      "in augment with subsamples train 2 success Violet\n",
      "in augment with subsamples train 2 success William\n",
      "in augment with subsamples train 2 yyy Alex\n",
      "in augment with subsamples train 2 yyy Ethan\n",
      "in augment with subsamples train 2 yyy Lily\n",
      "in augment with subsamples train 2 yyy Naima\n",
      "in augment with subsamples train 2 yyy Violet\n",
      "in augment with subsamples train 2 yyy William\n",
      "in augment with subsamples train 1000 success Alex\n",
      "in augment with subsamples train 1000 success Ethan\n",
      "in augment with subsamples train 1000 success Lily\n",
      "in augment with subsamples train 1000 success Naima\n",
      "in augment with subsamples train 1000 success Violet\n",
      "in augment with subsamples train 1000 success William\n",
      "in augment with subsamples train 1000 yyy Alex\n",
      "in augment with subsamples train 1000 yyy Ethan\n",
      "in augment with subsamples train 1000 yyy Lily\n",
      "in augment with subsamples train 1000 yyy Naima\n",
      "in augment with subsamples train 1000 yyy Violet\n",
      "in augment with subsamples train 1000 yyy William\n",
      "in augment with subsamples train 5000 success Alex\n",
      "in augment with subsamples train 5000 success Ethan\n",
      "in augment with subsamples train 5000 success Lily\n",
      "in augment with subsamples train 5000 success Naima\n",
      "in augment with subsamples train 5000 success Violet\n",
      "in augment with subsamples train 5000 success William\n",
      "in augment with subsamples train 5000 yyy Alex\n",
      "in augment with subsamples train 5000 yyy Ethan\n",
      "in augment with subsamples train 5000 yyy Lily\n",
      "in augment with subsamples train 5000 yyy Naima\n",
      "in augment with subsamples train 5000 yyy Violet\n",
      "in augment with subsamples train 5000 yyy William\n",
      "in augment with subsamples val 2 success Alex\n",
      "in augment with subsamples val 2 success Ethan\n",
      "in augment with subsamples val 2 success Lily\n",
      "in augment with subsamples val 2 success Naima\n",
      "in augment with subsamples val 2 success Violet\n",
      "in augment with subsamples val 2 success William\n",
      "in augment with subsamples val 2 yyy Alex\n",
      "in augment with subsamples val 2 yyy Ethan\n",
      "in augment with subsamples val 2 yyy Lily\n",
      "in augment with subsamples val 2 yyy Naima\n",
      "in augment with subsamples val 2 yyy Violet\n",
      "in augment with subsamples val 2 yyy William\n",
      "in augment with subsamples val 1000 success Alex\n",
      "in augment with subsamples val 1000 success Ethan\n",
      "in augment with subsamples val 1000 success Lily\n",
      "in augment with subsamples val 1000 success Naima\n",
      "in augment with subsamples val 1000 success Violet\n",
      "in augment with subsamples val 1000 success William\n",
      "in augment with subsamples val 1000 yyy Alex\n",
      "in augment with subsamples val 1000 yyy Ethan\n",
      "in augment with subsamples val 1000 yyy Lily\n",
      "in augment with subsamples val 1000 yyy Naima\n",
      "in augment with subsamples val 1000 yyy Violet\n",
      "in augment with subsamples val 1000 yyy William\n",
      "in augment with subsamples val 5000 success Alex\n",
      "in augment with subsamples val 5000 success Ethan\n",
      "in augment with subsamples val 5000 success Lily\n",
      "in augment with subsamples val 5000 success Naima\n",
      "in augment with subsamples val 5000 success Violet\n",
      "in augment with subsamples val 5000 success William\n",
      "in augment with subsamples val 5000 yyy Alex\n",
      "in augment with subsamples val 5000 yyy Ethan\n",
      "in augment with subsamples val 5000 yyy Lily\n",
      "in augment with subsamples val 5000 yyy Naima\n",
      "in augment with subsamples val 5000 yyy Violet\n",
      "in augment with subsamples val 5000 yyy William\n",
      "in augment with subsamples eval 2 success Alex\n",
      "in augment with subsamples eval 2 success Ethan\n",
      "in augment with subsamples eval 2 success Lily\n",
      "in augment with subsamples eval 2 success Naima\n",
      "in augment with subsamples eval 2 success Violet\n",
      "in augment with subsamples eval 2 success William\n",
      "in augment with subsamples eval 2 yyy Alex\n",
      "in augment with subsamples eval 2 yyy Ethan\n",
      "in augment with subsamples eval 2 yyy Lily\n",
      "in augment with subsamples eval 2 yyy Naima\n",
      "in augment with subsamples eval 2 yyy Violet\n",
      "in augment with subsamples eval 2 yyy William\n",
      "in augment with subsamples eval 1000 success Alex\n",
      "in augment with subsamples eval 1000 success Ethan\n",
      "in augment with subsamples eval 1000 success Lily\n",
      "in augment with subsamples eval 1000 success Naima\n",
      "in augment with subsamples eval 1000 success Violet\n",
      "in augment with subsamples eval 1000 success William\n",
      "in augment with subsamples eval 1000 yyy Alex\n",
      "in augment with subsamples eval 1000 yyy Ethan\n",
      "in augment with subsamples eval 1000 yyy Lily\n",
      "in augment with subsamples eval 1000 yyy Naima\n",
      "in augment with subsamples eval 1000 yyy Violet\n",
      "in augment with subsamples eval 1000 yyy William\n",
      "in augment with subsamples eval 5000 success Alex\n",
      "in augment with subsamples eval 5000 success Ethan\n",
      "in augment with subsamples eval 5000 success Lily\n",
      "in augment with subsamples eval 5000 success Naima\n",
      "in augment with subsamples eval 5000 success Violet\n",
      "in augment with subsamples eval 5000 success William\n",
      "in augment with subsamples eval 5000 yyy Alex\n",
      "in augment with subsamples eval 5000 yyy Ethan\n",
      "in augment with subsamples eval 5000 yyy Lily\n",
      "in augment with subsamples eval 5000 yyy Naima\n",
      "in augment with subsamples eval 5000 yyy Violet\n",
      "in augment with subsamples eval 5000 yyy William\n"
     ]
    }
   ],
   "source": [
    "# Mark the subsampling for the child cross scoring\n",
    "all_tokens_phono = child_split_gen.split_child_subsampling(all_tokens_phono)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final all_tokens_phono with all split information to the proper place.\n",
    "if not exists(config.prov_dir):\n",
    "    os.makedirs(config.prov_dir)\n",
    "    \n",
    "all_tokens_phono.to_pickle(join(config.prov_dir, 'pvd_all_tokens_phono_for_eval.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-26 06:31:34.580581\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-directed-listening",
   "language": "python",
   "name": "child-directed-listening"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
