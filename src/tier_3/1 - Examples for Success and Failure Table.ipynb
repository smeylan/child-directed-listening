{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/home/stephan/R/x86_64-pc-linux-gnu-library/4.2’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstalling childesr version 0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/childesr_0.2.3.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 22865 bytes (22 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 22 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpWeZ5sz/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join, exists\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import childespy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "time: 3.18 ms (started: 2023-03-05 13:59:18 -08:00)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../../')\n",
    "from src.utils import load_splits, load_models\n",
    "from src.analysis import examples_figure\n",
    "from src.utils import sample_models_across_time, configuration\n",
    "config = configuration.Config()\n",
    "\n",
    "\n",
    "%load_ext autotime\n",
    "%load_ext line_profiler\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.12 s (started: 2023-03-05 13:59:18 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Make this config regenerate controlled later\n",
    "\n",
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"', db_version = \"2020.1\").iloc[0]['id']\n",
    "\n",
    "regenerate = False\n",
    "this_path = join(config.prov_csv_dir, 'pvd_utt_glosses.csv')\n",
    "\n",
    "if regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, type from utterance where corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv(this_path, index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv(this_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phonology and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.23 s (started: 2023-03-05 13:59:20 -08:00)\n"
     ]
    }
   ],
   "source": [
    "all_tokens_phono = load_splits.load_phono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>transcript_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997717</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997717</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997718</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>aə</td>\n",
       "      <td>aə</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997718</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997719</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wɑn</td>\n",
       "      <td>wɑnt</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997719</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997720</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>də</td>\n",
       "      <td>tu</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997720</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wid</td>\n",
       "      <td>ɹid</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997721</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997722</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997722</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gloss actual_phonology_no_dia model_phonology_no_dia  \\\n",
       "997717  I want to read                                                  \n",
       "997718  I want to read                      aə                     aə   \n",
       "997719  I want to read                     wɑn                   wɑnt   \n",
       "997720  I want to read                      də                     tu   \n",
       "997721  I want to read                     wid                    ɹid   \n",
       "997722  I want to read                                                  \n",
       "\n",
       "        utterance_id  bert_token_id  utterance_order  transcript_id  \n",
       "997717      16928243         997717              310          42336  \n",
       "997718      16928243         997718              310          42336  \n",
       "997719      16928243         997719              310          42336  \n",
       "997720      16928243         997720              310          42336  \n",
       "997721      16928243         997721              310          42336  \n",
       "997722      16928243         997722              310          42336  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.3 ms (started: 2023-03-05 13:59:28 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_idx = 16928243\n",
    "\n",
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == success_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 311 µs (started: 2023-03-05 13:59:28 -08:00)\n"
     ]
    }
   ],
   "source": [
    "target_transcript_id = 42336 # Corresponds to the success_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162628</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928069</td>\n",
       "      <td>300</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162639</th>\n",
       "      <td>a ballet</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928081</td>\n",
       "      <td>301</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162656</th>\n",
       "      <td>is Jasmine a ballerina</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928098</td>\n",
       "      <td>302</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162670</th>\n",
       "      <td>yeah</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928113</td>\n",
       "      <td>303</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162686</th>\n",
       "      <td>oh I didn't know that</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928129</td>\n",
       "      <td>304</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162710</th>\n",
       "      <td>I ready now yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928154</td>\n",
       "      <td>305</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162730</th>\n",
       "      <td>whoa</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928174</td>\n",
       "      <td>306</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162744</th>\n",
       "      <td>yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928189</td>\n",
       "      <td>307</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162760</th>\n",
       "      <td>yyy yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928205</td>\n",
       "      <td>308</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162779</th>\n",
       "      <td>you want mamma let's see</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928225</td>\n",
       "      <td>309</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162797</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928243</td>\n",
       "      <td>310</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162814</th>\n",
       "      <td>okay mommy's gonna pick out a book</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928261</td>\n",
       "      <td>311</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     gloss  transcript_id        id  \\\n",
       "162628                             Jasmine          42336  16928069   \n",
       "162639                            a ballet          42336  16928081   \n",
       "162656              is Jasmine a ballerina          42336  16928098   \n",
       "162670                                yeah          42336  16928113   \n",
       "162686               oh I didn't know that          42336  16928129   \n",
       "162710                     I ready now yyy          42336  16928154   \n",
       "162730                                whoa          42336  16928174   \n",
       "162744                                 yyy          42336  16928189   \n",
       "162760                             yyy yyy          42336  16928205   \n",
       "162779            you want mamma let's see          42336  16928225   \n",
       "162797                      I want to read          42336  16928243   \n",
       "162814  okay mommy's gonna pick out a book          42336  16928261   \n",
       "\n",
       "        utterance_order target_child_name speaker_code         type  \n",
       "162628              300              Lily          MOT  declarative  \n",
       "162639              301              Lily          CHI  declarative  \n",
       "162656              302              Lily          MOT     question  \n",
       "162670              303              Lily          CHI  declarative  \n",
       "162686              304              Lily          MOT  declarative  \n",
       "162710              305              Lily          CHI  declarative  \n",
       "162730              306              Lily          MOT  declarative  \n",
       "162744              307              Lily          CHI  declarative  \n",
       "162760              308              Lily          CHI  declarative  \n",
       "162779              309              Lily          MOT  declarative  \n",
       "162797              310              Lily          CHI  declarative  \n",
       "162814              311              Lily          MOT  declarative  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 50.2 ms (started: 2023-03-05 13:59:28 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Broader context of sentences\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == target_transcript_id) &\n",
    "                (utt_glosses.utterance_order.isin(range(310-10, 310+2)))] # Note to self: changed the range here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Prior and Posterior Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/analysis/examples_figure.py:3: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/sample_models_across_time.py:11: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/load_models.py:12: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'src.utils.load_models' from '/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/load_models.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.71 ms (started: 2023-03-05 16:40:03 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(examples_figure)\n",
    "imp.reload(sample_models_across_time)\n",
    "imp.reload(load_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 501 µs (started: 2023-03-05 16:40:04 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# how to select the models to run under the new system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 937 µs (started: 2023-03-05 16:40:05 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model_args = load_models.gen_all_model_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'training_split': 'adult-written',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'adult-written',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'adult-written',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 1,\n",
       "  'use_tags': True,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 1,\n",
       "  'use_tags': True,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 1,\n",
       "  'use_tags': True,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 1,\n",
       "  'use_tags': False,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 1,\n",
       "  'use_tags': False,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 1,\n",
       "  'use_tags': False,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 0,\n",
       "  'use_tags': True,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 0,\n",
       "  'use_tags': True,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 0,\n",
       "  'use_tags': True,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 0,\n",
       "  'use_tags': False,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 0,\n",
       "  'use_tags': False,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'GPT-2',\n",
       "  'contextualized': 0,\n",
       "  'use_tags': False,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'young',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'young',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'young',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'young',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'young',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'young',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'old',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'old',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'old',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': True,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'old',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'old',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Providence-Age',\n",
       "  'training_dataset': 'old',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': [20, 0]},\n",
       " {'training_split': 'Switchboard',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 0},\n",
       " {'training_split': 'Switchboard',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': 20},\n",
       " {'training_split': 'Switchboard',\n",
       "  'training_dataset': 'all',\n",
       "  'model_type': 'BERT',\n",
       "  'use_tags': False,\n",
       "  'context_width': [20, 0]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.8 ms (started: 2023-03-05 16:40:05 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model eval_adult-written_all_no_tags_BERT_Providence_all_0... at age 0\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Getting the Levenshtein distance matrix\n",
      "Getting posteriors\n",
      "Running model eval_adult-written_all_no_tags_BERT_Providence_all_0... at age 0\n",
      "Computing failure scores\n",
      "Computing success scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[1] = -1 * np.log(1)\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:312: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[2] = [int(x) if not np.isnan(x) else '' for x in tail[2]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[3] = [int(x) if not np.isnan(x) else '' for x in tail[3]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:314: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[4] = [int(x) if not np.isnan(x) else '' for x in tail[4]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_section[j] = ats_section[j].astype('int')\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][2] = ''\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][3] = ''\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][4] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded transducer\n",
      "Getting posteriors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model eval_adult-written_all_no_tags_BERT_Providence_all_20... at age 0\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Getting the Levenshtein distance matrix\n",
      "Getting posteriors\n",
      "Running model eval_adult-written_all_no_tags_BERT_Providence_all_20... at age 0\n",
      "Computing failure scores\n",
      "Computing success scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[1] = -1 * np.log(1)\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:312: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[2] = [int(x) if not np.isnan(x) else '' for x in tail[2]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[3] = [int(x) if not np.isnan(x) else '' for x in tail[3]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:314: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[4] = [int(x) if not np.isnan(x) else '' for x in tail[4]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_section[j] = ats_section[j].astype('int')\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][2] = ''\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][3] = ''\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][4] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded transducer\n",
      "Getting posteriors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model eval_adult-written_all_no_tags_BERT_Providence_all_[20, 0]... at age 0\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Getting the Levenshtein distance matrix\n",
      "Getting posteriors\n",
      "Running model eval_adult-written_all_no_tags_BERT_Providence_all_[20, 0]... at age 0\n",
      "Computing failure scores\n",
      "Computing success scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[1] = -1 * np.log(1)\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:312: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[2] = [int(x) if not np.isnan(x) else '' for x in tail[2]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[3] = [int(x) if not np.isnan(x) else '' for x in tail[3]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:314: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tail[4] = [int(x) if not np.isnan(x) else '' for x in tail[4]]\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_section[j] = ats_section[j].astype('int')\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][2] = ''\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][3] = ''\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/likelihoods.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ats_end.iloc[0][4] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded transducer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/paths.py:75: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/stephan/notebooks/child-directed-listening/config.json' mode='r' encoding='UTF-8'>\n",
      "  config = configuration.Config()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting posteriors\n",
      "Loading a GPT-2 model...\n",
      "> \u001b[0;32m/home/stephan/notebooks/child-directed-listening/src/utils/load_models.py\u001b[0m(355)\u001b[0;36mget_model_from_split\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    353 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    354 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 355 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    356 \u001b[0;31m            \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoHuggingFaceModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    357 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  fast_tokenizer_file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'fast_tokenizer_file' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  quit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3f0e67c561f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_scores_across_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples_figure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores_across_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccess_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/notebooks/child-directed-listening/src/tier_3/../../src/analysis/examples_figure.py\u001b[0m in \u001b[0;36mget_scores_across_models\u001b[0;34m(test_idx, model_dicts, is_success)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Beta value is too low; examine the range for Levenshtein Distance scaling.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mthis_model_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fitted_model_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbest_beta_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_models_across_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccesses_and_failures_across_time_per_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myyy_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_model_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tokens_phono\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_beta_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'levdist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/child-directed-listening/src/tier_3/../../src/utils/load_models.py\u001b[0m in \u001b[0;36mget_fitted_model_dict\u001b[0;34m(fitted_dict)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfitted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPT-2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_finetune_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'[CHI]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'[CGV]'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwargs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/child-directed-listening/src/tier_3/../../src/utils/load_models.py\u001b[0m in \u001b[0;36mget_finetune_dict\u001b[0;34m(fitted_dict)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mfitted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_identifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0mfitted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwargs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_from_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0mfitted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwargs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context_width_in_utts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_context_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context_width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mfitted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwargs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_speaker_labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/child-directed-listening/src/tier_3/../../src/utils/load_models.py\u001b[0m in \u001b[0;36mget_model_from_split\u001b[0;34m(model_dict)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoHuggingFaceModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mAutoHuggingFaceModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# no cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/child-directed-listening/src/tier_3/../../src/utils/load_models.py\u001b[0m in \u001b[0;36mget_model_from_split\u001b[0;34m(model_dict)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoHuggingFaceModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mAutoHuggingFaceModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# no cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m(113)\u001b[0;36mdispatch_line\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    111 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    112 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 113 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    115 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  quit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 29s (started: 2023-03-05 16:40:06 -08:00)\n"
     ]
    }
   ],
   "source": [
    "raw_scores_across_models = examples_figure.get_scores_across_models(success_idx, model_args, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [X] figure out why the token is double masked in this case and therefore not found.\n",
    "# how is this different than when this is called from the command line in the regular fashion\n",
    "# utt_df.loc[utt_df.token == '[MASK]'] #the more robust way to do this is with token_id = 103\n",
    "# [ ] An issue with the FST\n",
    "#    df[[4]] = -1 * np.log(normalize_log_probs(df[[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(scores_across_models.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_across_models = scores_across_models.loc[scores_across_models.likelihood_type == 'wfst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "childes_all_title = 'eval_Providence_all_with_tags_BERT_Providence_all_20'\n",
    "adult_all_title = 'eval_adult-written_all_no_tags_BERT_Providence_all_20'\n",
    "unigram_title = 'eval_Providence_all_no_tags_data_unigram_Providence_all_0'\n",
    "flat_title = 'eval_no-split_no-dataset_no_tags_flat_unigram_Providence_all_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','posterior_probability','token','likelihood_type','prior_rank','posterior_rank']]\n",
    "success_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "print('CDL+Context Prior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "print('CDL+Context Posterior')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],3))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == adult_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "\n",
    "print('BERT+Context Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_all_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "print('BERT+Context Posterior')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],4))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == unigram_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token', 'prior_rank', 'posterior_rank']]\n",
    "#print(success_example)\n",
    "print('CHILDES-1Gram Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "print('CHILDES-1gram Posterior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == flat_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "print('UniformPrior Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "print('UniformPrior Posterior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_idx = 16813515\n",
    "\n",
    "raw_scores_across_models = examples_figure.get_scores_across_models(yyy_idx, model_args, False)\n",
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == yyy_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_across_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token','likelihood_type','posterior_rank']]\n",
    "yyy_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == adult_all_title ) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == unigram_title) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == flat_title) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the surrounding context\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == 42253) &\n",
    "                (utt_glosses.utterance_order.isin(range(112-3, 112+3)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-directed-listening",
   "language": "python",
   "name": "child-directed-listening"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
