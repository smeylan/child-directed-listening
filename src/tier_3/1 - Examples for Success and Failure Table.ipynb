{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/home/stephan/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstalling childesr version 0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/childesr_0.2.3.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 22865 bytes (22 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 22 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpMRuQkq/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join, exists\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import childespy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "Automatic pdb calling has been turned ON\n",
      "time: 5.81 ms (started: 2022-02-14 04:37:34 -08:00)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../../')\n",
    "from src.utils import transformers_bert_completions, load_splits, load_models\n",
    "from src.utils import sample_across_models, hyperparameter_utils, configuration, likelihoods\n",
    "config = configuration.Config()\n",
    "from src.analysis import examples_figure\n",
    "\n",
    "%load_ext autotime\n",
    "%load_ext line_profiler\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.98 s (started: 2022-02-14 04:36:26 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Make this config regenerate controlled later\n",
    "\n",
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"', db_version = \"2020.1\").iloc[0]['id']\n",
    "\n",
    "regenerate = False\n",
    "this_path = join(config.prov_csv_dir, 'pvd_utt_glosses.csv')\n",
    "\n",
    "if regenerate:\n",
    "    utt_glosses = childespy.get_sql_query('select gloss, transcript_id, id, \\\n",
    "    utterance_order, speaker_code, type from utterance where corpus_id = '+str(pvd_idx) ,\n",
    "        db_version = \"2020.1\")\n",
    "    utt_glosses.to_csv(this_path, index=False)\n",
    "else: \n",
    "    utt_glosses = pd.read_csv(this_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phonology and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.24 s (started: 2022-02-14 04:36:28 -08:00)\n"
     ]
    }
   ],
   "source": [
    "all_tokens_phono = load_splits.load_phono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>transcript_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997717</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997717</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997718</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>aə</td>\n",
       "      <td>aə</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997718</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997719</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wɑn</td>\n",
       "      <td>wɑnt</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997719</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997720</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>də</td>\n",
       "      <td>tu</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997720</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>wid</td>\n",
       "      <td>ɹid</td>\n",
       "      <td>16928243</td>\n",
       "      <td>997721</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997722</th>\n",
       "      <td>I want to read</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16928243</td>\n",
       "      <td>997722</td>\n",
       "      <td>310</td>\n",
       "      <td>42336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gloss actual_phonology_no_dia model_phonology_no_dia  \\\n",
       "997717  I want to read                                                  \n",
       "997718  I want to read                      aə                     aə   \n",
       "997719  I want to read                     wɑn                   wɑnt   \n",
       "997720  I want to read                      də                     tu   \n",
       "997721  I want to read                     wid                    ɹid   \n",
       "997722  I want to read                                                  \n",
       "\n",
       "        utterance_id  bert_token_id  utterance_order  transcript_id  \n",
       "997717      16928243         997717              310          42336  \n",
       "997718      16928243         997718              310          42336  \n",
       "997719      16928243         997719              310          42336  \n",
       "997720      16928243         997720              310          42336  \n",
       "997721      16928243         997721              310          42336  \n",
       "997722      16928243         997722              310          42336  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 74.3 ms (started: 2022-02-14 04:36:35 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_idx = 16928243\n",
    "\n",
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == success_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 487 µs (started: 2022-02-14 04:36:35 -08:00)\n"
     ]
    }
   ],
   "source": [
    "target_transcript_id = 42336 # Corresponds to the success_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162628</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928069</td>\n",
       "      <td>300</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162639</th>\n",
       "      <td>a ballet</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928081</td>\n",
       "      <td>301</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162656</th>\n",
       "      <td>is Jasmine a ballerina</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928098</td>\n",
       "      <td>302</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162670</th>\n",
       "      <td>yeah</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928113</td>\n",
       "      <td>303</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162686</th>\n",
       "      <td>oh I didn't know that</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928129</td>\n",
       "      <td>304</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162710</th>\n",
       "      <td>I ready now yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928154</td>\n",
       "      <td>305</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162730</th>\n",
       "      <td>whoa</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928174</td>\n",
       "      <td>306</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162744</th>\n",
       "      <td>yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928189</td>\n",
       "      <td>307</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162760</th>\n",
       "      <td>yyy yyy</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928205</td>\n",
       "      <td>308</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162779</th>\n",
       "      <td>you want mamma let's see</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928225</td>\n",
       "      <td>309</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162797</th>\n",
       "      <td>I want to read</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928243</td>\n",
       "      <td>310</td>\n",
       "      <td>Lily</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162814</th>\n",
       "      <td>okay mommy's gonna pick out a book</td>\n",
       "      <td>42336</td>\n",
       "      <td>16928261</td>\n",
       "      <td>311</td>\n",
       "      <td>Lily</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     gloss  transcript_id        id  \\\n",
       "162628                             Jasmine          42336  16928069   \n",
       "162639                            a ballet          42336  16928081   \n",
       "162656              is Jasmine a ballerina          42336  16928098   \n",
       "162670                                yeah          42336  16928113   \n",
       "162686               oh I didn't know that          42336  16928129   \n",
       "162710                     I ready now yyy          42336  16928154   \n",
       "162730                                whoa          42336  16928174   \n",
       "162744                                 yyy          42336  16928189   \n",
       "162760                             yyy yyy          42336  16928205   \n",
       "162779            you want mamma let's see          42336  16928225   \n",
       "162797                      I want to read          42336  16928243   \n",
       "162814  okay mommy's gonna pick out a book          42336  16928261   \n",
       "\n",
       "        utterance_order target_child_name speaker_code         type  \n",
       "162628              300              Lily          MOT  declarative  \n",
       "162639              301              Lily          CHI  declarative  \n",
       "162656              302              Lily          MOT     question  \n",
       "162670              303              Lily          CHI  declarative  \n",
       "162686              304              Lily          MOT  declarative  \n",
       "162710              305              Lily          CHI  declarative  \n",
       "162730              306              Lily          MOT  declarative  \n",
       "162744              307              Lily          CHI  declarative  \n",
       "162760              308              Lily          CHI  declarative  \n",
       "162779              309              Lily          MOT  declarative  \n",
       "162797              310              Lily          CHI  declarative  \n",
       "162814              311              Lily          MOT  declarative  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 38.2 ms (started: 2022-02-14 04:37:55 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Broader context of sentences\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == target_transcript_id) &\n",
    "                (utt_glosses.utterance_order.isin(range(310-10, 310+2)))] # Note to self: changed the range here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Prior and Posterior Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.18 ms (started: 2022-02-14 04:36:35 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Changed this notebook to use the +/- 20 context newly generated versions.\n",
    "\n",
    "# Written to match load_models.query_model_title\n",
    "child_args = {\n",
    "    'split' : 'all',\n",
    "    'dataset' : 'all', \n",
    "    'is_tags' : True,\n",
    "    'context_num' : 20,\n",
    "}\n",
    "\n",
    "adult_args = {\n",
    "    'split' : 'all',\n",
    "    'dataset' : 'all', \n",
    "    'is_tags' : False,\n",
    "    'context_num' : 20,\n",
    "}\n",
    "\n",
    "childes_all_title = load_models.query_model_title(model_type = 'childes', **child_args)\n",
    "adult_all_title = load_models.query_model_title(model_type = 'adult', **adult_args)\n",
    "unigram_title = 'CHILDES Unigram'\n",
    "flat_title = 'Flat Unigram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHILDES BERT with tags, , +-20 utts context'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.2 ms (started: 2022-02-14 04:36:35 -08:00)\n"
     ]
    }
   ],
   "source": [
    "childes_all_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils.hyperparameter_utils' from '/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/hyperparameter_utils.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.2 ms (started: 2022-02-14 05:40:06 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(examples_figure)\n",
    "imp.reload(transformers_bert_completions)\n",
    "imp.reload(sample_across_models)\n",
    "imp.reload(load_models)\n",
    "imp.reload(likelihoods)\n",
    "imp.reload(hyperparameter_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.42 ms (started: 2022-02-14 05:40:07 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# CDL + Context +/- 20 is needed\n",
    "# BERT + Context +/- 20 is needed\n",
    "# Childes on train data.\n",
    "\n",
    "# How to load properly with sample across models?\n",
    "which_models = [\n",
    "    ('all', 'all', False, 0, 'data_unigram'),\n",
    "    ('all', 'all', True, 20, 'childes'), # only the fine-tuned one can have tags\n",
    "    ('all', 'all', False, 20, 'adult'),\n",
    "    ('all', 'all', False, 0, 'flat_unigram'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model CHILDES Unigram...\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Running model CHILDES BERT with tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model Adult BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "Running model Flat Unigram...\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "time: 59.5 s (started: 2022-02-14 05:40:07 -08:00)\n"
     ]
    }
   ],
   "source": [
    "raw_scores_across_models = examples_figure.get_scores_across_models(success_idx, which_models, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.6 ms (started: 2022-02-14 05:41:45 -08:00)\n"
     ]
    }
   ],
   "source": [
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.32 ms (started: 2022-02-14 05:41:46 -08:00)\n"
     ]
    }
   ],
   "source": [
    "scores_across_models = scores_across_models.loc[scores_across_models.likelihood_type == 'wfst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wfst'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.92 ms (started: 2022-02-14 05:41:47 -08:00)\n"
     ]
    }
   ],
   "source": [
    "np.unique(scores_across_models.likelihood_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>highest_posterior_words</th>\n",
       "      <th>highest_posterior_probabilities</th>\n",
       "      <th>highest_prior_words</th>\n",
       "      <th>highest_prior_probabilities</th>\n",
       "      <th>prior_probability</th>\n",
       "      <th>posterior_probability</th>\n",
       "      <th>token</th>\n",
       "      <th>likelihood_type</th>\n",
       "      <th>prior_rank</th>\n",
       "      <th>posterior_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997721</th>\n",
       "      <td>CHILDES BERT with tags, , +-20 utts context</td>\n",
       "      <td>read weed wait with what watch write lead ride...</td>\n",
       "      <td>0.9964688298463213 0.0004157385151096034 0.000...</td>\n",
       "      <td>see go read play do watch look write draw come</td>\n",
       "      <td>0.32852945 0.079577334 0.069445 0.066612884 0....</td>\n",
       "      <td>0.069445</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>read</td>\n",
       "      <td>wfst</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model  \\\n",
       "997721  CHILDES BERT with tags, , +-20 utts context   \n",
       "\n",
       "                                  highest_posterior_words  \\\n",
       "997721  read weed wait with what watch write lead ride...   \n",
       "\n",
       "                          highest_posterior_probabilities  \\\n",
       "997721  0.9964688298463213 0.0004157385151096034 0.000...   \n",
       "\n",
       "                                   highest_prior_words  \\\n",
       "997721  see go read play do watch look write draw come   \n",
       "\n",
       "                              highest_prior_probabilities  prior_probability  \\\n",
       "997721  0.32852945 0.079577334 0.069445 0.066612884 0....           0.069445   \n",
       "\n",
       "        posterior_probability token likelihood_type  prior_rank  \\\n",
       "997721               0.996469  read            wfst           2   \n",
       "\n",
       "        posterior_rank  \n",
       "997721             0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.4 ms (started: 2022-02-14 05:41:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','posterior_probability','token','likelihood_type','prior_rank','posterior_rank']]\n",
    "success_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDL+Context Prior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'see (0.33) go (0.08) read (0.07) play (0.07) do (0.03) watch (0.02) look (0.02) write (0.02) draw (0.01) come (0.01)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.2 ms (started: 2022-02-14 05:41:53 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "print('CDL+Context Prior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDL+Context Posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'read (0.996) weed (0.0) wait (0.0) with (0.0) what (0.0) watch (0.0) write (0.0) lead (0.0) ride (0.0) reading (0.0)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22 ms (started: 2022-02-14 05:42:03 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "print('CDL+Context Posterior')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],3))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT+Context Prior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'read (0.49) see (0.28) play (0.04) know (0.04) look (0.02) go (0.01) watch (0.01) help (0.01) try (0.01) talk (0.01)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.5 ms (started: 2022-02-14 05:42:06 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == adult_all_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "\n",
    "print('BERT+Context Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adult BERT without tags, , +-20 utts context'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.21 ms (started: 2022-02-14 05:42:13 -08:00)\n"
     ]
    }
   ],
   "source": [
    "adult_all_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT+Context Posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'read (0.9997) wait (0.0001) weed (0.0001) lead (0.0) reads (0.0) reading (0.0) wonder (0.0) watch (0.0) write (0.0) reader (0.0)'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.6 ms (started: 2022-02-14 05:42:14 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "print('BERT+Context Posterior')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],4))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHILDES-1Gram Prior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i (0.04) a (0.03) the (0.03) yeah (0.03) no (0.03) it (0.03) you (0.02) and (0.02) that (0.02) this (0.01)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.7 ms (started: 2022-02-14 05:42:16 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == unigram_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token', 'prior_rank', 'posterior_rank']]\n",
    "#print(success_example)\n",
    "print('CHILDES-1Gram Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHILDES-1gram Posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'read (0.46) with (0.24) what (0.1) would (0.04) we (0.03) weed (0.02) word (0.01) one (0.01) wood (0.01) wait (0.01)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.6 ms (started: 2022-02-14 05:42:20 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "print('CHILDES-1gram Posterior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniformPrior Prior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'stalks (0.0) rarely (0.0) harbor (0.0) dust (0.0) josh (0.0) milk (0.0) leon (0.0) pitch (0.0) blake (0.0) girlfriend (0.0)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.2 ms (started: 2022-02-14 05:42:24 -08:00)\n"
     ]
    }
   ],
   "source": [
    "success_example = scores_across_models.loc[(scores_across_models.model == flat_title) &\n",
    "    (scores_across_models.token == 'read')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "success_example\n",
    "print('UniformPrior Prior')\n",
    "words = success_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniformPrior Posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'weed (0.37) worried (0.17) reed (0.06) read (0.06) wheeled (0.05) wheat (0.03) weeds (0.03) reader (0.03) hurried (0.03) lead (0.02)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18 ms (started: 2022-02-14 05:42:25 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = success_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in success_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "print('UniformPrior Posterior')\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils.load_models' from '/home/stephan/notebooks/child-directed-listening/src/tier_3/../../src/utils/load_models.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.87 ms (started: 2022-02-14 05:42:34 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(examples_figure)\n",
    "imp.reload(transformers_bert_completions)\n",
    "imp.reload(sample_across_models)\n",
    "imp.reload(load_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model CHILDES Unigram...\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Running model CHILDES BERT with tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model Adult BERT without tags, , +-20 utts context...\n",
      "Computing failure scores\n",
      "Computing success scores\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "Running model Flat Unigram...\n",
      "Computing WFST path lengths...\n",
      "Processing lambda value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "Computing edit distances...\n",
      "Getting the Levenshtein distance matrix\n",
      "Processing beta value 1 of 20\n",
      "If possible compare the bert_token_id in sample_across_models to the bert_token_id in one of the other scores sets from bert.\n",
      "time: 49.2 s (started: 2022-02-14 05:42:37 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_idx = 16813515\n",
    "\n",
    "raw_scores_across_models = examples_figure.get_scores_across_models(yyy_idx, which_models, False)\n",
    "scores_across_models = pd.concat(raw_scores_across_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>actual_phonology_no_dia</th>\n",
       "      <th>model_phonology_no_dia</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>transcript_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289678</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16813515</td>\n",
       "      <td>289678</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289679</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>ju</td>\n",
       "      <td>ju</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289679</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289680</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>meək</td>\n",
       "      <td>meək</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289680</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289681</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>jɜ</td>\n",
       "      <td>jɑɹ</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289681</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>fɜt</td>\n",
       "      <td>*</td>\n",
       "      <td>16813515</td>\n",
       "      <td>289682</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289683</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16813515</td>\n",
       "      <td>289683</td>\n",
       "      <td>112</td>\n",
       "      <td>42253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    gloss actual_phonology_no_dia model_phonology_no_dia  \\\n",
       "289678  you make your yyy                                                  \n",
       "289679  you make your yyy                      ju                     ju   \n",
       "289680  you make your yyy                    meək                   meək   \n",
       "289681  you make your yyy                      jɜ                    jɑɹ   \n",
       "289682  you make your yyy                     fɜt                      *   \n",
       "289683  you make your yyy                                                  \n",
       "\n",
       "        utterance_id  bert_token_id  utterance_order  transcript_id  \n",
       "289678      16813515         289678              112          42253  \n",
       "289679      16813515         289679              112          42253  \n",
       "289680      16813515         289680              112          42253  \n",
       "289681      16813515         289681              112          42253  \n",
       "289682      16813515         289682              112          42253  \n",
       "289683      16813515         289683              112          42253  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.3 ms (started: 2022-02-14 05:43:26 -08:00)\n"
     ]
    }
   ],
   "source": [
    "all_tokens_phono.loc[all_tokens_phono.utterance_id == yyy_idx][['gloss','actual_phonology_no_dia',\n",
    " 'model_phonology_no_dia', 'utterance_id','bert_token_id','utterance_order','transcript_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>bert_token_id</th>\n",
       "      <th>prior_entropy</th>\n",
       "      <th>set</th>\n",
       "      <th>keep</th>\n",
       "      <th>posterior_entropy</th>\n",
       "      <th>posterior_rank</th>\n",
       "      <th>position_in_mask</th>\n",
       "      <th>kl_flat_to_prior</th>\n",
       "      <th>kl_flat_to_posterior</th>\n",
       "      <th>...</th>\n",
       "      <th>highest_prior_probabilities</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>lambda_value</th>\n",
       "      <th>model</th>\n",
       "      <th>likelihood_type</th>\n",
       "      <th>beta_value</th>\n",
       "      <th>prior_rank</th>\n",
       "      <th>prior_prob</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_tokens_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>yyy</td>\n",
       "      <td>289682.0</td>\n",
       "      <td>5.837648</td>\n",
       "      <td>failure</td>\n",
       "      <td>True</td>\n",
       "      <td>2.420235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04249687198055286 0.032549581544440515 0.027...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>CHILDES Unigram</td>\n",
       "      <td>wfst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>yyy</td>\n",
       "      <td>289682.0</td>\n",
       "      <td>5.837648</td>\n",
       "      <td>failure</td>\n",
       "      <td>True</td>\n",
       "      <td>3.620203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04249687198055286 0.032549581544440515 0.027...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>CHILDES Unigram</td>\n",
       "      <td>levdist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289682.0</td>\n",
       "      <td>5.641387</td>\n",
       "      <td>failure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.157460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13319147 0.0419459 0.03884089 0.02615074 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>CHILDES BERT with tags, , +-20 utts context</td>\n",
       "      <td>wfst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.138803</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289682.0</td>\n",
       "      <td>5.641387</td>\n",
       "      <td>failure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.459025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13319147 0.0419459 0.03884089 0.02615074 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>CHILDES BERT with tags, , +-20 utts context</td>\n",
       "      <td>levdist</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.138803</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289682.0</td>\n",
       "      <td>3.551628</td>\n",
       "      <td>failure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.181117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2485145 0.24318402 0.04469067 0.033207614 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Adult BERT without tags, , +-20 utts context</td>\n",
       "      <td>wfst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.123916</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289682.0</td>\n",
       "      <td>3.551628</td>\n",
       "      <td>failure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.794463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2485145 0.24318402 0.04469067 0.033207614 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Adult BERT without tags, , +-20 utts context</td>\n",
       "      <td>levdist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.123916</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>yyy</td>\n",
       "      <td>289682.0</td>\n",
       "      <td>8.986822</td>\n",
       "      <td>failure</td>\n",
       "      <td>True</td>\n",
       "      <td>3.503627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00012504689258471927 0.00012504689258471927 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Flat Unigram</td>\n",
       "      <td>wfst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>yyy</td>\n",
       "      <td>289682.0</td>\n",
       "      <td>8.986822</td>\n",
       "      <td>failure</td>\n",
       "      <td>True</td>\n",
       "      <td>4.516821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00012504689258471927 0.00012504689258471927 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Flat Unigram</td>\n",
       "      <td>levdist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  bert_token_id  prior_entropy      set  keep  posterior_entropy  \\\n",
       "289682   yyy       289682.0       5.837648  failure  True           2.420235   \n",
       "289682   yyy       289682.0       5.837648  failure  True           3.620203   \n",
       "289682   NaN       289682.0       5.641387  failure   NaN           2.157460   \n",
       "289682   NaN       289682.0       5.641387  failure   NaN           3.459025   \n",
       "289682   NaN       289682.0       3.551628  failure   NaN           2.181117   \n",
       "289682   NaN       289682.0       3.551628  failure   NaN           2.794463   \n",
       "289682   yyy       289682.0       8.986822  failure  True           3.503627   \n",
       "289682   yyy       289682.0       8.986822  failure  True           4.516821   \n",
       "\n",
       "        posterior_rank  position_in_mask  kl_flat_to_prior  \\\n",
       "289682             NaN               NaN               NaN   \n",
       "289682             NaN               NaN               NaN   \n",
       "289682             NaN               NaN               NaN   \n",
       "289682             NaN               NaN               NaN   \n",
       "289682             NaN               NaN               NaN   \n",
       "289682             NaN               NaN               NaN   \n",
       "289682             NaN               NaN               NaN   \n",
       "289682             NaN               NaN               NaN   \n",
       "\n",
       "        kl_flat_to_posterior  ...  \\\n",
       "289682                   NaN  ...   \n",
       "289682                   NaN  ...   \n",
       "289682                   NaN  ...   \n",
       "289682                   NaN  ...   \n",
       "289682                   NaN  ...   \n",
       "289682                   NaN  ...   \n",
       "289682                   NaN  ...   \n",
       "289682                   NaN  ...   \n",
       "\n",
       "                              highest_prior_probabilities  sample_index  \\\n",
       "289682  0.04249687198055286 0.032549581544440515 0.027...             0   \n",
       "289682  0.04249687198055286 0.032549581544440515 0.027...             0   \n",
       "289682  0.13319147 0.0419459 0.03884089 0.02615074 0.0...             0   \n",
       "289682  0.13319147 0.0419459 0.03884089 0.02615074 0.0...             0   \n",
       "289682  0.2485145 0.24318402 0.04469067 0.033207614 0....             0   \n",
       "289682  0.2485145 0.24318402 0.04469067 0.033207614 0....             0   \n",
       "289682  0.00012504689258471927 0.00012504689258471927 ...             0   \n",
       "289682  0.00012504689258471927 0.00012504689258471927 ...             0   \n",
       "\n",
       "        lambda_value                                         model  \\\n",
       "289682           1.1                               CHILDES Unigram   \n",
       "289682           1.1                               CHILDES Unigram   \n",
       "289682           1.1   CHILDES BERT with tags, , +-20 utts context   \n",
       "289682           1.1   CHILDES BERT with tags, , +-20 utts context   \n",
       "289682           1.1  Adult BERT without tags, , +-20 utts context   \n",
       "289682           1.1  Adult BERT without tags, , +-20 utts context   \n",
       "289682           1.3                                  Flat Unigram   \n",
       "289682           1.3                                  Flat Unigram   \n",
       "\n",
       "       likelihood_type beta_value prior_rank  prior_prob   entropy  \\\n",
       "289682            wfst        NaN        NaN         NaN       NaN   \n",
       "289682         levdist        3.5        NaN         NaN       NaN   \n",
       "289682            wfst        NaN        NaN         NaN  8.138803   \n",
       "289682         levdist        3.2        NaN         NaN  8.138803   \n",
       "289682            wfst        NaN        NaN         NaN  5.123916   \n",
       "289682         levdist        3.5        NaN         NaN  5.123916   \n",
       "289682            wfst        NaN        NaN         NaN       NaN   \n",
       "289682         levdist        3.7        NaN         NaN       NaN   \n",
       "\n",
       "       num_tokens_in_context  \n",
       "289682                   NaN  \n",
       "289682                   NaN  \n",
       "289682                  16.0  \n",
       "289682                  16.0  \n",
       "289682                  13.0  \n",
       "289682                  13.0  \n",
       "289682                   NaN  \n",
       "289682                   NaN  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.2 ms (started: 2022-02-14 05:43:26 -08:00)\n"
     ]
    }
   ],
   "source": [
    "scores_across_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>highest_posterior_words</th>\n",
       "      <th>highest_posterior_probabilities</th>\n",
       "      <th>highest_prior_words</th>\n",
       "      <th>highest_prior_probabilities</th>\n",
       "      <th>prior_probability</th>\n",
       "      <th>token</th>\n",
       "      <th>likelihood_type</th>\n",
       "      <th>posterior_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289682</th>\n",
       "      <td>CHILDES BERT with tags, , +-20 utts context</td>\n",
       "      <td>favorite first fort face front feet foot fit f...</td>\n",
       "      <td>0.39497616697125876 0.20496920327398618 0.1135...</td>\n",
       "      <td>own house bed dinner face mouth name tower hea...</td>\n",
       "      <td>0.13319147 0.0419459 0.03884089 0.02615074 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wfst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model  \\\n",
       "289682  CHILDES BERT with tags, , +-20 utts context   \n",
       "\n",
       "                                  highest_posterior_words  \\\n",
       "289682  favorite first fort face front feet foot fit f...   \n",
       "\n",
       "                          highest_posterior_probabilities  \\\n",
       "289682  0.39497616697125876 0.20496920327398618 0.1135...   \n",
       "\n",
       "                                      highest_prior_words  \\\n",
       "289682  own house bed dinner face mouth name tower hea...   \n",
       "\n",
       "                              highest_prior_probabilities  prior_probability  \\\n",
       "289682  0.13319147 0.0419459 0.03884089 0.02615074 0.0...                NaN   \n",
       "\n",
       "       token likelihood_type  posterior_rank  \n",
       "289682   NaN            wfst             NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.7 ms (started: 2022-02-14 05:43:42 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == childes_all_title) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token','likelihood_type','posterior_rank']]\n",
    "yyy_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'own (0.13) house (0.04) bed (0.04) dinner (0.03) face (0.02) mouth (0.02) name (0.01) tower (0.01) head (0.01) nose (0.01)'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.2 ms (started: 2022-02-14 05:43:43 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'favorite (0.39) first (0.2) fort (0.11) face (0.05) front (0.05) feet (0.05) foot (0.04) fit (0.01) fist (0.01) effort (0.01)'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.6 ms (started: 2022-02-14 05:43:44 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'own (0.25) choice (0.24) point (0.04) bed (0.03) call (0.03) guess (0.03) wish (0.02) choices (0.02) move (0.02) mistake (0.02)'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.9 ms (started: 2022-02-14 05:43:44 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == adult_all_title ) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'favorite (0.34) first (0.26) effort (0.14) fort (0.06) offer (0.03) threat (0.02) fist (0.01) fate (0.01) fit (0.01) freighter (0.01)'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.3 ms (started: 2022-02-14 05:43:45 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i (0.04) a (0.03) the (0.03) yeah (0.03) no (0.03) it (0.03) you (0.02) and (0.02) that (0.02) this (0.01)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.5 ms (started: 2022-02-14 05:43:46 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == unigram_title) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for (0.41) fit (0.13) first (0.11) front (0.06) foot (0.05) different (0.03) feet (0.03) favorite (0.02) fruit (0.01) forty (0.01)'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.6 ms (started: 2022-02-14 05:43:47 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stalks (0.0) rarely (0.0) harbor (0.0) dust (0.0) josh (0.0) milk (0.0) leon (0.0) pitch (0.0) blake (0.0) girlfriend (0.0)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.9 ms (started: 2022-02-14 05:43:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "yyy_example = scores_across_models.loc[(scores_across_models.model == flat_title) & (scores_across_models.likelihood_type == 'wfst')][['model','highest_posterior_words','highest_posterior_probabilities',\n",
    "    'highest_prior_words','highest_prior_probabilities', 'prior_probability','token']]\n",
    "yyy_example\n",
    "\n",
    "words = yyy_example.iloc[0].highest_prior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_prior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'freight (0.2) freighter (0.09) fort (0.09) flirt (0.08) front (0.04) fit (0.04) effort (0.03) fate (0.03) favorite (0.02) foot (0.02)'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-02-14 05:43:49 -08:00)\n"
     ]
    }
   ],
   "source": [
    "words = yyy_example.iloc[0].highest_posterior_words.split(' ')\n",
    "probs = [float(x) for x in yyy_example.iloc[0].highest_posterior_probabilities.split(' ')]\n",
    "' '.join([words[i]+' ('+str(np.round(probs[i],2))+')' for i in range(len(words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50658</th>\n",
       "      <td>then we won't be able to put them back into th...</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813459</td>\n",
       "      <td>109</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50679</th>\n",
       "      <td>do you want ta put some beans in your eggs and...</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813482</td>\n",
       "      <td>110</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50697</th>\n",
       "      <td>no</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813501</td>\n",
       "      <td>111</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50710</th>\n",
       "      <td>you make your yyy</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813515</td>\n",
       "      <td>112</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CHI</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50723</th>\n",
       "      <td>can I make one</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813529</td>\n",
       "      <td>113</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50745</th>\n",
       "      <td>no</td>\n",
       "      <td>42253</td>\n",
       "      <td>16813554</td>\n",
       "      <td>114</td>\n",
       "      <td>Alex</td>\n",
       "      <td>MOT</td>\n",
       "      <td>declarative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   gloss  transcript_id  \\\n",
       "50658  then we won't be able to put them back into th...          42253   \n",
       "50679  do you want ta put some beans in your eggs and...          42253   \n",
       "50697                                                 no          42253   \n",
       "50710                                  you make your yyy          42253   \n",
       "50723                                     can I make one          42253   \n",
       "50745                                                 no          42253   \n",
       "\n",
       "             id  utterance_order target_child_name speaker_code         type  \n",
       "50658  16813459              109              Alex          MOT  declarative  \n",
       "50679  16813482              110              Alex          MOT     question  \n",
       "50697  16813501              111              Alex          CHI  declarative  \n",
       "50710  16813515              112              Alex          CHI  declarative  \n",
       "50723  16813529              113              Alex          MOT     question  \n",
       "50745  16813554              114              Alex          MOT  declarative  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.4 ms (started: 2022-02-14 05:43:50 -08:00)\n"
     ]
    }
   ],
   "source": [
    "# Get the surrounding context\n",
    "utt_glosses.loc[(utt_glosses.transcript_id == 42253) &\n",
    "                (utt_glosses.utterance_order.isin(range(112-3, 112+3)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "child-directed-listening",
   "language": "python",
   "name": "child-directed-listening"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
